#!/usr/bin/env python3
"""
æµ‹è¯•ESæœç´¢çš„åŸå§‹è¿”å›ç»“æœï¼ŒæŸ¥çœ‹æ‰€æœ‰å­—æ®µ
"""

import asyncio
import json
import sys
import os
from pprint import pprint

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'src'))

from doc_agent.core.config import settings
from doc_agent.tools.es_search import ESSearchTool
from doc_agent.llm_clients.providers import EmbeddingClient
from doc_agent.core.logging_config import get_logger

logger = get_logger(__name__)


async def test_es_raw_response():
    """æµ‹è¯•ESæœç´¢çš„åŸå§‹è¿”å›ç»“æœ"""
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•ESæœç´¢åŸå§‹è¿”å›ç»“æœ")

    try:
        # 1. åˆå§‹åŒ–ESæœç´¢å·¥å…·
        logger.info("ğŸ“¡ åˆå§‹åŒ–ESæœç´¢å·¥å…·...")
        es_config = settings.elasticsearch_config
        es_hosts = es_config.hosts
        es_username = es_config.username
        es_password = es_config.password

        es_search_tool = ESSearchTool(hosts=es_hosts,
                                      username=es_username,
                                      password=es_password)
        logger.info("âœ… ESæœç´¢å·¥å…·åˆå§‹åŒ–æˆåŠŸ")

        # 2. åˆå§‹åŒ–Embeddingå®¢æˆ·ç«¯
        logger.info("ğŸ§  åˆå§‹åŒ–Embeddingå®¢æˆ·ç«¯...")
        embedding_config = settings.supported_models.get("gte_qwen")
        if embedding_config:
            embedding_client = EmbeddingClient(
                base_url=embedding_config.url,
                api_key=embedding_config.api_key)
            logger.info("âœ… Embeddingå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        else:
            embedding_client = None
            logger.warning("âš ï¸ æœªæ‰¾åˆ°Embeddingé…ç½®ï¼Œå°†ä½¿ç”¨æ–‡æœ¬æœç´¢")

        # 3. æµ‹è¯•å‚æ•°
        test_query = "æ°´ç”µç«™"

        logger.info(f"ğŸ” æµ‹è¯•æŸ¥è¯¢: {test_query}")

        # 4. ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_vector = None
        if embedding_client:
            try:
                logger.info("ğŸ§  ç”ŸæˆæŸ¥è¯¢å‘é‡...")
                embedding_response = embedding_client.invoke(test_query)
                embedding_data = json.loads(embedding_response)

                if isinstance(embedding_data, list):
                    if len(embedding_data) > 0 and isinstance(
                            embedding_data[0], list):
                        query_vector = embedding_data[0]
                    else:
                        query_vector = embedding_data
                elif isinstance(embedding_data,
                                dict) and 'data' in embedding_data:
                    query_vector = embedding_data['data']

                logger.info(
                    f"âœ… æŸ¥è¯¢å‘é‡ç”ŸæˆæˆåŠŸï¼Œç»´åº¦: {len(query_vector) if query_vector else 0}"
                )
            except Exception as e:
                logger.error(f"âŒ æŸ¥è¯¢å‘é‡ç”Ÿæˆå¤±è´¥: {str(e)}")
                query_vector = None

        # 5. æ‰§è¡ŒESæœç´¢å¹¶è·å–åŸå§‹ç»“æœ
        logger.info("ğŸ” æ‰§è¡ŒESæœç´¢...")
        try:
            # ç›´æ¥è°ƒç”¨ESæœåŠ¡è·å–åŸå§‹ç»“æœ
            await es_search_tool._ensure_initialized()
            domain_index_map = {
                "documentUploadAnswer": "personal_knowledge_base",
                "standard": "standard_index_prod",
                "thesis": "thesis_index_prod",
                "book": "book_index_prod",
                "other": "other_index_prod",
                "internal": "internal_index_prod_v2",
                "policy": "hdy_knowledge_prod_v2",
                "executivevoice": "hdy_knowledge_prod_v2",
                "corporatenews": "hdy_knowledge_prod_v2",
                "announcement": "hdy_knowledge_prod_v2"
            }
            index_aliases = {}
            augmented_index_domain_map = {}
            valid_indeces = []

            # è·å– aliases
            aliases_info = await es_search_tool._es_service._client.indices.get_alias(
                index="*")
            # æ„å»ºç´¢å¼•åˆ°åˆ«åçš„æ˜ å°„
            for index_name, info in aliases_info.items():
                if 'aliases' in info:
                    index_aliases[index_name] = list(info['aliases'].keys())
                else:
                    index_aliases[index_name] = []

            index_aliases = index_aliases
            logger.info(f"æˆåŠŸè·å–ç´¢å¼•åˆ«åæ˜ å°„ï¼Œå…± {len(index_aliases)} ä¸ªç´¢å¼•")

            for idx, alias_list in index_aliases.items():
                if idx == "personal_knowledge_base" or "personal_knowledge_base" in alias_list:
                    logger.info(f"ğŸ” ä¸ªäººçŸ¥è¯†åº“ç´¢å¼•: {idx}")
                    logger.info(f"ğŸ” ä¸ªäººçŸ¥è¯†åº“åˆ«å: {alias_list}")
                for domain_id, domain_idx in domain_index_map.items():
                    if (domain_idx == idx or domain_idx in alias_list):
                        if idx == "personal_knowledge_base" or "personal_knowledge_base" in alias_list:
                            logger.info(f"ğŸ” ä¸ªäººçŸ¥è¯†åº“ç´¢å¼•: {idx}")
                            logger.info(f"ğŸ” ä¸ªäººçŸ¥è¯†åº“åˆ«å: {alias_list}")
                        augmented_index_domain_map[idx] = domain_id
                        for alias_idx in alias_list:
                            augmented_index_domain_map[alias_idx] = domain_id
                        valid_indeces.append(idx)
                        valid_indeces.extend(alias_list)

            # æ‰“å°
            # index_aliases
            # augmented_index_domain_map
            # valid_indeces
            logger.info(f"ğŸ” ç´¢å¼•åˆ«å: {index_aliases}")
            logger.info(f"æ‰©å±•æ˜ å°„è¡¨: {augmented_index_domain_map}")
            logger.info(f"æœ‰æ•ˆç´¢å¼•: {valid_indeces}")

            # è·å–åŸå§‹ESå“åº”
            if es_search_tool._indices_list:
                index_to_use = es_search_tool._current_index or es_search_tool._indices_list[
                    0]
                logger.info(f"ğŸ” ä½¿ç”¨ç´¢å¼•: {index_to_use}")

                # æ„å»ºæœç´¢æŸ¥è¯¢
                search_body = es_search_tool._es_service._build_search_body(
                    test_query, query_vector, None, 3)
                logger.info(
                    f"ğŸ” æœç´¢æŸ¥è¯¢ä½“: {json.dumps(search_body, indent=2, ensure_ascii=False)}"
                )

                # æ‰§è¡ŒåŸå§‹æœç´¢
                raw_response = await es_search_tool._es_service._client.search(
                    index=index_to_use, body=search_body)

                logger.info(f"âœ… åŸå§‹ESå“åº”è·å–æˆåŠŸ")
                logger.info(f"ğŸ“Š åŸå§‹å“åº”ç»“æ„: {list(raw_response.keys())}")

                # åˆ†æåŸå§‹å“åº”
                hits = raw_response.get('hits', {})
                total_hits = hits.get('total', {})
                logger.info(f"ğŸ“Š æ€»å‘½ä¸­æ•°: {total_hits}")

                # åˆ†æå‰3ä¸ªåŸå§‹ç»“æœ
                for i, hit in enumerate(hits.get('hits', [])[:3], 1):
                    logger.info(f"\n{'='*80}")
                    logger.info(f"åŸå§‹ç»“æœ {i}:")
                    logger.info(f"{'='*80}")

                    # æ˜¾ç¤ºå®Œæ•´çš„åŸå§‹hitç»“æ„
                    logger.info(f"ğŸ“‹ å®Œæ•´åŸå§‹hitç»“æ„:")
                    logger.info(json.dumps(hit, indent=2, ensure_ascii=False))

                    # åˆ†æ_sourceå­—æ®µ
                    source = hit.get('_source', {})
                    logger.info(f"\nğŸ” _sourceå­—æ®µåˆ†æ:")
                    logger.info(f"  - _sourceå­—æ®µæ•°é‡: {len(source)}")
                    logger.info(f"  - _sourceå­—æ®µåˆ—è¡¨: {list(source.keys())}")

                    # æ£€æŸ¥æ˜¯å¦æœ‰domainIdå’ŒfileFrom
                    logger.info(f"\nğŸ” ç‰¹æ®Šå­—æ®µæ£€æŸ¥:")
                    if 'domainId' in source:
                        logger.info(f"  âœ… æ‰¾åˆ° domainId: {source['domainId']}")
                    else:
                        logger.info(f"  âŒ æœªæ‰¾åˆ° domainId")

                    if 'fileFrom' in source:
                        logger.info(f"  âœ… æ‰¾åˆ° fileFrom: {source['fileFrom']}")
                    else:
                        logger.info(f"  âŒ æœªæ‰¾åˆ° fileFrom")

                    # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„å­—æ®µå˜ä½“
                    domain_variants = [
                        'domainId', 'domain_id', 'domain', 'DomainId',
                        'domainId', 'domainName'
                    ]
                    file_variants = [
                        'fileFrom', 'file_from', 'fileFrom', 'FileFrom',
                        'source_type', 'file_source'
                    ]

                    for variant in domain_variants:
                        if variant in source:
                            logger.info(
                                f"  âœ… æ‰¾åˆ° domain å˜ä½“ '{variant}': {source[variant]}"
                            )

                    for variant in file_variants:
                        if variant in source:
                            logger.info(
                                f"  âœ… æ‰¾åˆ° file å˜ä½“ '{variant}': {source[variant]}"
                            )

                    # æ˜¾ç¤ºæ‰€æœ‰å­—æ®µçš„è¯¦ç»†ä¿¡æ¯
                    logger.info(f"\nğŸ“„ æ‰€æœ‰å­—æ®µè¯¦ç»†ä¿¡æ¯:")
                    for key, value in source.items():
                        if isinstance(value, str) and len(value) > 100:
                            display_value = value[:100] + "..."
                        else:
                            display_value = value
                        logger.info(f"  * {key}: {display_value}")

                # ç°åœ¨ä¹Ÿæµ‹è¯•ESSearchResultå¤„ç†åçš„ç»“æœè¿›è¡Œå¯¹æ¯”
                logger.info(f"\n{'='*80}")
                logger.info(f"å¯¹æ¯”ï¼šESSearchResultå¤„ç†åçš„ç»“æœ")
                logger.info(f"{'='*80}")

                es_results = await es_search_tool.search(
                    query=test_query,
                    query_vector=query_vector,
                    top_k=3,
                    use_multiple_indices=True,
                    config={'min_score': 0.1})

                for i, result in enumerate(es_results, 1):
                    logger.info(f"\nå¤„ç†åçš„ç»“æœ {i}:")
                    logger.info(f"  - ID: {result.id}")
                    logger.info(f"  - æ–‡æ¡£ID: {result.doc_id}")
                    logger.info(f"  - æ–‡ä»¶Token: {result.file_token}")
                    logger.info(f"  - æ¥æº: {result.source}")
                    logger.info(f"  - åˆ†æ•°: {result.score}")
                    logger.info(f"  - åˆ«å: {result.alias_name}")
                    logger.info(
                        f"  - å…ƒæ•°æ®å­—æ®µæ•°: {len(result.metadata) if result.metadata else 0}"
                    )
                    if result.metadata:
                        logger.info(
                            f"  - å…ƒæ•°æ®å­—æ®µ: {list(result.metadata.keys())}")
            else:
                logger.warning("âš ï¸ æ²¡æœ‰å¯ç”¨çš„ç´¢å¼•")
                return False

            logger.info(f"âœ… ESæœç´¢å®Œæˆï¼Œç»“æœæ•°é‡: {len(es_results)}")

            if not es_results:
                logger.warning("âš ï¸ æ²¡æœ‰æ‰¾åˆ°æœç´¢ç»“æœï¼Œå°è¯•é™ä½åˆ†æ•°é˜ˆå€¼...")
                # å°è¯•ä¸è®¾ç½®åˆ†æ•°é˜ˆå€¼
                es_results = await es_search_tool.search(
                    query=test_query,
                    query_vector=query_vector,
                    top_k=3,
                    use_multiple_indices=True)
                logger.info(f"âœ… é‡æ–°æœç´¢å®Œæˆï¼Œç»“æœæ•°é‡: {len(es_results)}")

            # 6. åˆ†ææ¯ä¸ªç»“æœçš„å­—æ®µ
            for i, result in enumerate(es_results, 1):
                logger.info(f"\n{'='*60}")
                logger.info(f"ç»“æœ {i}:")
                logger.info(f"{'='*60}")

                # åŸºæœ¬ä¿¡æ¯
                logger.info(f"ğŸ“‹ åŸºæœ¬ä¿¡æ¯:")
                logger.info(f"  - ID: {result.id}")
                logger.info(f"  - æ–‡æ¡£ID: {result.doc_id}")
                logger.info(f"  - æ–‡ä»¶Token: {result.file_token}")
                logger.info(f"  - æ¥æº: {result.source}")
                logger.info(f"  - åˆ†æ•°: {result.score}")
                logger.info(f"  - åˆ«å: {result.alias_name}")

                # å†…å®¹ä¿¡æ¯
                logger.info(f"ğŸ“„ å†…å®¹ä¿¡æ¯:")
                logger.info(f"  - åŸå§‹å†…å®¹é•¿åº¦: {len(result.original_content)}")
                logger.info(f"  - åˆ‡åˆ†å†…å®¹é•¿åº¦: {len(result.div_content)}")
                logger.info(f"  - åŸå§‹å†…å®¹é¢„è§ˆ: {result.original_content[:200]}...")

                # å…ƒæ•°æ®ä¿¡æ¯
                logger.info(f"ğŸ” å…ƒæ•°æ®ä¿¡æ¯:")
                if result.metadata:
                    logger.info(f"  - å…ƒæ•°æ®å­—æ®µæ•°é‡: {len(result.metadata)}")
                    logger.info(f"  - å…ƒæ•°æ®å­—æ®µåˆ—è¡¨:")
                    for key, value in result.metadata.items():
                        # é™åˆ¶é•¿å€¼çš„æ˜¾ç¤º
                        if isinstance(value, str) and len(value) > 100:
                            display_value = value[:100] + "..."
                        else:
                            display_value = value
                        logger.info(f"    * {key}: {display_value}")

                    # ç‰¹åˆ«æ£€æŸ¥domainIdå’ŒfileFromå­—æ®µ
                    logger.info(f"ğŸ” ç‰¹æ®Šå­—æ®µæ£€æŸ¥:")
                    if 'domainId' in result.metadata:
                        logger.info(
                            f"  âœ… æ‰¾åˆ° domainId: {result.metadata['domainId']}")
                    else:
                        logger.info(f"  âŒ æœªæ‰¾åˆ° domainId")

                    if 'fileFrom' in result.metadata:
                        logger.info(
                            f"  âœ… æ‰¾åˆ° fileFrom: {result.metadata['fileFrom']}")
                    else:
                        logger.info(f"  âŒ æœªæ‰¾åˆ° fileFrom")

                    # æ£€æŸ¥æ‰€æœ‰å¯èƒ½çš„å­—æ®µåå˜ä½“
                    domain_id_variants = [
                        'domainId', 'domain_id', 'domain', 'domainId',
                        'DomainId'
                    ]
                    file_from_variants = [
                        'fileFrom', 'file_from', 'fileFrom', 'FileFrom',
                        'source_type'
                    ]

                    for variant in domain_id_variants:
                        if variant in result.metadata:
                            logger.info(
                                f"  âœ… æ‰¾åˆ° domainId å˜ä½“ '{variant}': {result.metadata[variant]}"
                            )

                    for variant in file_from_variants:
                        if variant in result.metadata:
                            logger.info(
                                f"  âœ… æ‰¾åˆ° fileFrom å˜ä½“ '{variant}': {result.metadata[variant]}"
                            )
                else:
                    logger.info(f"  - æ— å…ƒæ•°æ®")

                logger.info(f"{'='*60}")

            # 7. æ€»ç»“åˆ†æ
            logger.info(f"\nğŸ“Š å­—æ®µåˆ†ææ€»ç»“:")
            if es_results:
                # æ”¶é›†æ‰€æœ‰å…ƒæ•°æ®å­—æ®µ
                all_metadata_fields = set()
                for result in es_results:
                    if result.metadata:
                        all_metadata_fields.update(result.metadata.keys())

                logger.info(f"  - å‘ç°çš„æ€»å…ƒæ•°æ®å­—æ®µæ•°: {len(all_metadata_fields)}")
                logger.info(
                    f"  - æ‰€æœ‰å…ƒæ•°æ®å­—æ®µ: {sorted(list(all_metadata_fields))}")

                # æ£€æŸ¥æ˜¯å¦æœ‰ç±»ä¼¼domainIdå’ŒfileFromçš„å­—æ®µ
                domain_related_fields = [
                    f for f in all_metadata_fields if 'domain' in f.lower()
                ]
                file_related_fields = [
                    f for f in all_metadata_fields
                    if 'file' in f.lower() or 'from' in f.lower()
                ]

                if domain_related_fields:
                    logger.info(f"  - å¯èƒ½çš„domainç›¸å…³å­—æ®µ: {domain_related_fields}")
                else:
                    logger.info(f"  - æœªå‘ç°domainç›¸å…³å­—æ®µ")

                if file_related_fields:
                    logger.info(f"  - å¯èƒ½çš„fileç›¸å…³å­—æ®µ: {file_related_fields}")
                else:
                    logger.info(f"  - æœªå‘ç°fileç›¸å…³å­—æ®µ")
            else:
                logger.warning("  - æ²¡æœ‰æœç´¢ç»“æœï¼Œæ— æ³•åˆ†æå­—æ®µ")

        except Exception as e:
            logger.error(f"âŒ ESæœç´¢å¤±è´¥: {str(e)}")
            return False

        logger.info("ğŸ‰ ESæœç´¢åŸå§‹è¿”å›ç»“æœåˆ†æå®Œæˆï¼")
        return True

    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
        return False


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 60)
    logger.info("ğŸ§ª ESæœç´¢åŸå§‹è¿”å›ç»“æœåˆ†æ")
    logger.info("=" * 60)

    success = await test_es_raw_response()

    if success:
        logger.info("âœ… åˆ†æå®Œæˆï¼")
    else:
        logger.error("âŒ åˆ†æå¤±è´¥ï¼")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
