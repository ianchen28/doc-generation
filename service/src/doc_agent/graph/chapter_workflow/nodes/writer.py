"""
å†™ä½œèŠ‚ç‚¹æ¨¡å—

è´Ÿè´£åŸºäºç ”ç©¶æ•°æ®ç”Ÿæˆç« èŠ‚å†…å®¹
"""

import re
from pprint import pformat as pprint
from typing import Any

from doc_agent.core.logging_config import get_logger
from doc_agent.graph.callbacks import publish_event

logger = get_logger(__name__)

from doc_agent.common.prompt_selector import PromptSelector
from doc_agent.core.config import settings
from doc_agent.graph.callbacks import TokenStreamCallbackHandler
from doc_agent.graph.common import (
    format_requirements_to_text as _format_requirements_to_text, )
from doc_agent.graph.common import format_sources_to_text as _format_sources_to_text
from doc_agent.graph.common import (
    get_or_create_source_id, )
from doc_agent.graph.state import ResearchState
from doc_agent.llm_clients.base import LLMClient
from doc_agent.schemas import Source


def writer_node(state: ResearchState,
                llm_client: LLMClient,
                prompt_selector: PromptSelector,
                genre: str = "default",
                prompt_version: str = "v3_context_aware") -> dict[str, Any]:
    """
    ç« èŠ‚å†™ä½œèŠ‚ç‚¹
    åŸºäºå½“å‰ç« èŠ‚çš„ç ”ç©¶æ•°æ®å’Œå·²å®Œæˆç« èŠ‚çš„ä¸Šä¸‹æ–‡ï¼Œç”Ÿæˆå½“å‰ç« èŠ‚çš„å†…å®¹
    æ”¯æŒå¼•ç”¨å·¥ä½œæµï¼Œè‡ªåŠ¨å¤„ç†å¼•ç”¨æ ‡è®°å’Œæºè¿½è¸ªï¼Œæ”¯æŒ token çº§åˆ«æµå¼è¾“å‡ºåˆ° Redis
    
    Args:
        state: ç ”ç©¶çŠ¶æ€ï¼ŒåŒ…å«ç« èŠ‚ä¿¡æ¯ã€ç ”ç©¶æ•°æ®å’Œå·²å®Œæˆç« èŠ‚
        llm_client: LLMå®¢æˆ·ç«¯å®ä¾‹
        prompt_selector: PromptSelectorå®ä¾‹ï¼Œç”¨äºè·å–promptæ¨¡æ¿
        genre: genreç±»å‹ï¼Œé»˜è®¤ä¸º"default"
        prompt_version: promptç‰ˆæœ¬ï¼Œé»˜è®¤ä¸º"v3_context_aware"
        
    Returns:
        dict: åŒ…å«å½“å‰ç« èŠ‚å†…å®¹å’Œå¼•ç”¨æºçš„å­—å…¸
    """
    logger.info("--- WRITER NODE ---")
    logger.info(f"writer state keys: {list(state.keys())}")
    job_id = state.get("job_id")
    if not job_id:
        logger.error("Writer node: job_id not found in state.")
        # å³ä½¿æ²¡æœ‰ job_id ä¹Ÿå¯ä»¥ç»§ç»­ï¼Œä½†æ— æ³•å‘å¸ƒäº‹ä»¶
        job_id = "unknown_job"

    # è·å–åŸºæœ¬ä¿¡æ¯
    topic = state.get("topic", "")
    current_chapter_index = state.get("current_chapter_index", 0)
    chapters_to_process = state.get("chapters_to_process", [])
    completed_chapters_content = state.get("completed_chapters_content", [])
    completed_chapters = state.get("completed_chapters", [])

    # éªŒè¯å½“å‰ç« èŠ‚ç´¢å¼•
    if current_chapter_index >= len(chapters_to_process):
        raise ValueError(f"ç« èŠ‚ç´¢å¼• {current_chapter_index} è¶…å‡ºèŒƒå›´")

    # è·å–å½“å‰ç« èŠ‚ä¿¡æ¯
    current_chapter = chapters_to_process[current_chapter_index]
    chapter_title = current_chapter.get("chapter_title", "")
    chapter_description = current_chapter.get("description", "")
    chapter_word_count = current_chapter.get("chapter_word_count", 0)
    sub_sections = current_chapter.get("sub_sections", [])  # è·å–å­èŠ‚ä¿¡æ¯

    publish_event(
        job_id, "ç« èŠ‚å†™ä½œ", "document_generation", "RUNNING",
        {"description": f"å¼€å§‹å†™ä½œç« èŠ‚{current_chapter_index + 1}ï¼š{chapter_title}"})

    if not chapter_title:
        raise ValueError("ç« èŠ‚æ ‡é¢˜ä¸èƒ½ä¸ºç©º")

    # è·å–å¤æ‚åº¦é…ç½®
    complexity_config = settings.get_complexity_config()
    logger.info(f"ğŸ”§ ä½¿ç”¨å¤æ‚åº¦çº§åˆ«: {complexity_config['level']}")
    logger.info(f"ğŸ“Š å½“å‰ç« èŠ‚å­èŠ‚æ•°é‡: {len(sub_sections)}")

    # ä»çŠ¶æ€ä¸­è·å–ç ”ç©¶æ•°æ®
    gathered_sources = state.get("gathered_sources", [])
    user_requirement_sources = state.get("user_requirement_sources", [])
    user_style_guide_sources = state.get("user_style_guide_sources", [])
    logger.info(f"ğŸ” ç”¨æˆ·è¦æ±‚å†…å®¹: {user_requirement_sources}")
    logger.info(f"ğŸ” æ ·å¼æŒ‡å—å†…å®¹: {user_style_guide_sources}")

    # æ·»åŠ è°ƒè¯•æ—¥å¿—
    logger.info(f"ğŸ“š gathered_sources æ•°é‡: {len(gathered_sources)}")
    logger.info(
        f"ğŸ¨ user_style_guide_sources æ•°é‡: {len(user_style_guide_sources)}")
    logger.info(
        f"ğŸ“‹ user_requirement_sources æ•°é‡: {len(user_requirement_sources)}")

    # æ„å»ºä¸Šä¸‹æ–‡
    context_for_writing = _build_writing_context(completed_chapters)
    previous_chapters_context = _build_previous_chapters_context(
        completed_chapters_content)

    # è·å–æ–‡æ¡£ç”Ÿæˆå™¨é…ç½®
    document_writer_config = settings.get_agent_component_config(
        "document_writer")
    if document_writer_config:
        temperature = document_writer_config.temperature
        max_tokens = document_writer_config.max_tokens
        extra_params = document_writer_config.extra_params
    else:
        temperature = 0.7
        max_tokens = 4000
        extra_params = {}

    # è·å–æ ·å¼æŒ‡å—å†…å®¹
    style_guide_content = state.get("style_guide_content", "")

    # è·å–åˆé€‚çš„æç¤ºè¯æ¨¡æ¿
    prompt_template = _get_prompt_template(prompt_selector, prompt_version,
                                           genre, style_guide_content,
                                           complexity_config)

    # æ„å»ºæç¤ºè¯
    prompt = _build_prompt(prompt_template, topic, chapter_title,
                           chapter_description, current_chapter_index,
                           chapters_to_process, previous_chapters_context,
                           gathered_sources, user_requirement_sources,
                           user_style_guide_sources, chapter_word_count,
                           context_for_writing,
                           style_guide_content, sub_sections,
                           state.get("current_citation_index", 1))

    logger.debug(f"Invoking LLM with writer prompt:\n{pprint(prompt)}")

    try:
        # åˆ›å»ºæµå¼å›è°ƒå¤„ç†å™¨
        streaming_handler = TokenStreamCallbackHandler(
            job_id=job_id,
            chapter_title=chapter_title,
            chapter_index=current_chapter_index)

        logger.info(f"å¼€å§‹ä¸ºç« èŠ‚ '{chapter_title}' æµå¼è°ƒç”¨ LLM...")

        # ä½¿ç”¨åŒæ­¥æµå¼è°ƒç”¨ LLM
        response_list = []
        # ä»…ç›‘å¬ç¬¬ä¸€æ¬¡æµå¼è¾“å‡º
        enable_listen_logger = True
        for chunk in llm_client.stream(prompt,
                                       temperature=temperature,
                                       max_tokens=max_tokens,
                                       **extra_params):
            # ç´¯åŠ  token å†…å®¹
            response_list.append(chunk)
            # ä½¿ç”¨ TokenStreamCallbackHandler å‘é€æ¯ä¸ª token
            streaming_handler.on_llm_new_token(
                chunk, enable_listen_logger=enable_listen_logger)
            enable_listen_logger = False

        # åœ¨ä¸€ç« ç”Ÿæˆç»“æŸæ—¶é¢å¤–æ·»åŠ ä¸€ä¸ªæ¢è¡Œç¬¦
        streaming_handler.on_llm_new_token(
            "\n", enable_listen_logger=enable_listen_logger)
        logger.success(f"ç« èŠ‚ '{chapter_title}' å†…å®¹æµå¼ç”Ÿæˆå®Œæ¯•ã€‚")

        # å‘é€å‰©ä½™ç¼“å†²
        try:
            streaming_handler.flush()
        except Exception:
            pass

        # ä½¿ç”¨æµå¼ç”Ÿæˆçš„å®Œæ•´å“åº”
        response = "".join(response_list)
        logger.info(f"chapter raw response: {response}")

        logger.info(f"å®é™…ç”Ÿæˆ {len(response)} å­—ï¼Œç›®æ ‡ {chapter_word_count} å­—")
        # è·å–ç« èŠ‚ç¼–å·ä¿¡æ¯
        current_chapter_index = state.get("current_chapter_index", 0)
        chapters_to_process = state.get("chapters_to_process", [])
        chapter_number = current_chapter_index + 1

        # ç¡®ä¿å“åº”æ ¼å¼æ­£ç¡®
        # if not response.strip():
        #     response = f"## {chapter_number}. {chapter_title}\n\næ— æ³•ç”Ÿæˆç« èŠ‚å†…å®¹ã€‚"
        # elif not response.startswith("##"):
        #     # å¦‚æœæ²¡æœ‰äºŒçº§æ ‡é¢˜ï¼Œæ·»åŠ ç« èŠ‚æ ‡é¢˜
        #     response = f"## {chapter_number}. {chapter_title}\n\n{response}"
        # else:
        #     # å¦‚æœå·²ç»æœ‰äºŒçº§æ ‡é¢˜ï¼Œç¡®ä¿æ ¼å¼æ­£ç¡®
        #     lines = response.split('\n')
        #     if lines and lines[0].startswith(
        #             '## ') and not lines[0].startswith('### '):
        #         # è¿™æ˜¯ç« èŠ‚æ ‡é¢˜ï¼Œç¡®ä¿åŒ…å«ç¼–å·
        #         if not lines[0].strip().startswith(f"## {chapter_number}."):
        #             lines[0] = f"## {chapter_number}. {chapter_title}"
        #             response = '\n'.join(lines)

        # å¤„ç†å¼•ç”¨æ ‡è®°
        # å¤„ç†å¼•ç”¨æ ‡è®°
        _update_cited_sources_inplace(response, gathered_sources)

        # åå¤„ç†
        final_document = _response_postprocess(response)

        # æ ¹æ®å¼•ç”¨æ ‡è®°ï¼Œå¯¹ç›¸å…³æ–‡çŒ®è¿›è¡Œæ ‡è®°ï¼Œå¹¶æ›´æ–°çŠ¶æ€
        cited_sources = [source for source in gathered_sources if source.cited]
        logger.info(f"âœ… ç« èŠ‚ç”Ÿæˆå®Œæˆï¼Œå¼•ç”¨äº† {len(cited_sources)} ä¸ªä¿¡æ¯æº")

        previous_document = state.get("final_document", "")

        # è¿”å›å½“å‰ç« èŠ‚çš„å†…å®¹å’Œå¼•ç”¨æº
        return {
            "final_document": previous_document + response,
            "cited_sources_in_chapter": cited_sources
        }

    except Exception as e:
        # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯
        logger.error(f"Writer node error: {str(e)}")
        current_chapter_index = state.get("current_chapter_index", 0)
        chapter_number = current_chapter_index + 1

        error_content = f"""## {chapter_number}. {chapter_title}

### ç« èŠ‚ç”Ÿæˆé”™è¯¯

ç”±äºæŠ€æœ¯åŸå› ï¼Œæ— æ³•ç”Ÿæˆæœ¬ç« èŠ‚çš„å†…å®¹ã€‚

**é”™è¯¯ä¿¡æ¯:** {str(e)}

**ç« èŠ‚æè¿°:** {chapter_description}

è¯·æ£€æŸ¥ç³»ç»Ÿé…ç½®æˆ–ç¨åé‡è¯•ã€‚
"""
        return {
            "final_document": error_content,
            "cited_sources_in_chapter": []
        }


def _build_writing_context(completed_chapters: list) -> str:
    """æ„å»ºæ»‘åŠ¨çª—å£ + å…¨å±€æ‘˜è¦ä¸Šä¸‹æ–‡"""
    context_for_writing = ""

    if completed_chapters:
        # è·å–æœ€åä¸€ç« çš„å®Œæ•´å†…å®¹ï¼ˆæ»‘åŠ¨çª—å£ï¼‰
        last_chapter = completed_chapters[-1]
        if isinstance(last_chapter, dict) and "content" in last_chapter:
            context_for_writing += f"**Context from the previous chapter (Full Text):**\n{last_chapter['content']}\n\n"
            logger.info(
                f"ğŸ“– æ·»åŠ å‰ä¸€ç« å®Œæ•´å†…å®¹åˆ°ä¸Šä¸‹æ–‡ï¼Œé•¿åº¦: {len(last_chapter['content'])} å­—ç¬¦")

        # å¦‚æœæœ‰æ›´å¤šç« èŠ‚ï¼Œè·å–æ—©æœŸç« èŠ‚çš„æ‘˜è¦ï¼ˆå…¨å±€æ‘˜è¦ï¼‰
        if len(completed_chapters) > 1:
            earlier_summaries = []
            for chapter in completed_chapters[:-1]:  # é™¤äº†æœ€åä¸€ç« çš„æ‰€æœ‰ç« èŠ‚
                if isinstance(chapter, dict) and "summary" in chapter:
                    earlier_summaries.append(chapter["summary"])
                elif isinstance(chapter, dict) and "content" in chapter:
                    # å¦‚æœæ²¡æœ‰æ‘˜è¦ï¼Œä½¿ç”¨å†…å®¹çš„å‰200å­—ç¬¦ä½œä¸ºæ‘˜è¦
                    content = chapter["content"]
                    summary = content[:200] + "..." if len(
                        content) > 200 else content
                    earlier_summaries.append(summary)

            if earlier_summaries:
                context_for_writing += "**Context from earlier chapters (Summaries):**\n" + "\n\n".join(
                    earlier_summaries)
                logger.info(f"ğŸ“š æ·»åŠ  {len(earlier_summaries)} ä¸ªæ—©æœŸç« èŠ‚æ‘˜è¦åˆ°ä¸Šä¸‹æ–‡")

    if not context_for_writing:
        context_for_writing = "è¿™æ˜¯ç¬¬ä¸€ç« ï¼Œæ²¡æœ‰å‰ç½®å†…å®¹ã€‚"
        logger.info("ğŸ“ è¿™æ˜¯ç¬¬ä¸€ç« ï¼Œä½¿ç”¨é»˜è®¤ä¸Šä¸‹æ–‡")

    return context_for_writing


def _build_previous_chapters_context(completed_chapters_content: list) -> str:
    """æ„å»ºå·²å®Œæˆç« èŠ‚çš„ä¸Šä¸‹æ–‡æ‘˜è¦"""
    if not completed_chapters_content:
        return ""

    return "\n\n".join([
        f"ç¬¬{i+1}ç« æ‘˜è¦:\n{content[:500]}..."
        if len(content) > 500 else f"ç¬¬{i+1}ç« :\n{content}"
        for i, content in enumerate(completed_chapters_content)
    ])


def _get_prompt_template(prompt_selector, prompt_version, genre,
                         style_guide_content, complexity_config):
    """è·å–åˆé€‚çš„æç¤ºè¯æ¨¡æ¿"""
    try:
        # æ ¹æ®å¤æ‚åº¦å†³å®šæ˜¯å¦ä½¿ç”¨ç®€åŒ–æç¤ºè¯
        if complexity_config['use_simplified_prompts']:
            # ä½¿ç”¨å¿«é€Ÿæç¤ºè¯ - ç°åœ¨ä»promptsæ¨¡å—è·å–
            from doc_agent.prompts.writer import V4_FAST
            return V4_FAST

        # æ ¹æ®æŒ‡å®šçš„ prompt_version è·å–æ¨¡æ¿
        from doc_agent.prompts.writer import PROMPTS

        # å¦‚æœæœ‰æ ·å¼æŒ‡å—ï¼Œä¼˜å…ˆä½¿ç”¨ v4_with_style_guide ç‰ˆæœ¬
        if style_guide_content and style_guide_content.strip():
            if "v4_with_style_guide" in PROMPTS:
                logger.info("âœ… ä½¿ç”¨ v4_with_style_guide ç‰ˆæœ¬ï¼Œæ£€æµ‹åˆ°æ ·å¼æŒ‡å—")
                return PROMPTS["v4_with_style_guide"]

        # ä½¿ç”¨æŒ‡å®šç‰ˆæœ¬
        if prompt_version in PROMPTS:
            logger.debug(f"âœ… æˆåŠŸè·å– writer {prompt_version} prompt æ¨¡æ¿")
            return PROMPTS[prompt_version]

        # å›é€€ç‰ˆæœ¬
        if "v3_context_aware" in PROMPTS:
            logger.debug("âœ… å›é€€åˆ° writer v3_context_aware prompt æ¨¡æ¿")
            return PROMPTS["v3_context_aware"]

        if "v2_with_citations" in PROMPTS:
            logger.debug("âœ… å›é€€åˆ° writer v2_with_citations prompt æ¨¡æ¿")
            return PROMPTS["v2_with_citations"]

    except Exception as e:
        logger.warning(f"âš ï¸  è·å– prompt å¤±è´¥: {e}")

    # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
    return _get_fallback_prompt_template()


def _get_fallback_prompt_template() -> str:
    """è·å–å¤‡ç”¨çš„æç¤ºè¯æ¨¡æ¿"""
    return """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£å†™ä½œä¸“å®¶ã€‚è¯·åŸºäºæä¾›çš„ç ”ç©¶æ•°æ®ï¼Œä¸ºæŒ‡å®šç« èŠ‚æ’°å†™å†…å®¹ã€‚

**æ–‡æ¡£ä¸»é¢˜:** {topic}
**ç« èŠ‚æ ‡é¢˜:** {chapter_title}
**ç« èŠ‚æè¿°:** {chapter_description}
**ç« èŠ‚ç¼–å·:** {chapter_number}/{total_chapters}

**å¯ç”¨ä¿¡æ¯æº:**
{available_sources}

**å†™ä½œè¦æ±‚:**
1. åŸºäºç ”ç©¶æ•°æ®æ’°å†™å†…å®¹ï¼Œç¡®ä¿ä¿¡æ¯å‡†ç¡®æ€§å’Œå®Œæ•´æ€§
2. ä¿æŒç« èŠ‚ç»“æ„æ¸…æ™°ï¼Œé€»è¾‘è¿è´¯
3. ä½¿ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€
4. åœ¨å†™ä½œæ—¶ï¼Œå¦‚æœä½¿ç”¨äº†æŸä¸ªä¿¡æ¯æºçš„å†…å®¹ï¼Œè¯·ä½¿ç”¨ç‰¹æ®Šæ ‡è®°ï¼š<sources>[æºID]</sources>
5. ä¾‹å¦‚ï¼š<sources>[1]</sources> è¿™é‡Œä½¿ç”¨äº†æº1çš„ä¿¡æ¯
6. å¦‚æœæ˜¯è‡ªå·±çš„ç»¼åˆæ€»ç»“ï¼Œä½¿ç”¨ï¼š<sources>[]</sources>

è¯·ç«‹å³å¼€å§‹æ’°å†™ç« èŠ‚å†…å®¹ã€‚
"""


def _build_prompt(prompt_template,
                  topic,
                  chapter_title,
                  chapter_description,
                  current_chapter_index,
                  chapters_to_process,
                  previous_chapters_context,
                  gathered_sources,
                  user_requirement_sources,
                  user_style_guide_sources,
                  chapter_word_count,
                  context_for_writing,
                  style_guide_content,
                  sub_sections,
                  source_begin_idx=1,
                  max_length=30000):
    """æ„å»ºå®Œæ•´çš„æç¤ºè¯ï¼Œæ™ºèƒ½æ§åˆ¶é•¿åº¦"""

    # åˆå§‹åŒ–å„éƒ¨åˆ†å†…å®¹
    available_sources_text = ""
    prompt_requirements = ""
    style_requirements = ""

    # è®¡ç®—åŸºç¡€å†…å®¹çš„é•¿åº¦ï¼ˆä¸åŒ…æ‹¬å¯å˜éƒ¨åˆ†ï¼‰
    base_content = f"""
topic={topic}
chapter_title={chapter_title}
chapter_description={chapter_description}
chapter_number={current_chapter_index + 1}
total_chapters={len(chapters_to_process)}
previous_chapters_context={previous_chapters_context or "è¿™æ˜¯ç¬¬ä¸€ç« ï¼Œæ²¡æœ‰å‰ç½®å†…å®¹ã€‚"}
context_for_writing={context_for_writing}
"""

    # æ ¼å¼åŒ–å­èŠ‚ä¿¡æ¯
    sub_sections_text = ""
    if sub_sections:
        sub_sections_text = "\n\nå½“å‰ç« èŠ‚çš„å­èŠ‚ç»“æ„ï¼š\n"
        for sub_section in sub_sections:
            section_number = sub_section.get("section_number", "?")
            section_title = sub_section.get("section_title", "æœªå‘½åå­èŠ‚")
            section_description = sub_section.get("section_description", "")
            key_points = sub_section.get("key_points", [])

            sub_sections_text += f"\n{section_number} {section_title}\n"
            if section_description:
                sub_sections_text += f"æè¿°: {section_description}\n"
            if key_points:
                sub_sections_text += f"è¦ç‚¹: {', '.join(key_points)}\n"

    # è®¡ç®—å·²ç”¨é•¿åº¦
    used_length = len(base_content) + len(sub_sections_text)
    remaining_length = max_length - used_length

    # æ™ºèƒ½åˆ†é…å‰©ä½™é•¿åº¦
    # ä¼˜å…ˆçº§ï¼šå¯ç”¨ä¿¡æ¯æº > ç”¨æˆ·è¦æ±‚ > æ ·å¼æŒ‡å—
    sources_ratio = 0.6  # 60% ç»™ä¿¡æ¯æº
    requirements_ratio = 0.25  # 25% ç»™ç”¨æˆ·è¦æ±‚
    style_ratio = 0.15  # 15% ç»™æ ·å¼æŒ‡å—

    sources_max_length = int(remaining_length * sources_ratio)
    requirements_max_length = int(remaining_length * requirements_ratio)
    style_max_length = int(remaining_length * style_ratio)

    # 1. å¤„ç†å¯ç”¨ä¿¡æ¯æº
    if gathered_sources:
        available_sources_text = _format_sources_to_text(
            gathered_sources, source_begin_idx)

        # å¦‚æœä¿¡æ¯æºå†…å®¹è¿‡é•¿ï¼Œè¿›è¡Œæ™ºèƒ½æˆªæ–­
        if len(available_sources_text) > sources_max_length:
            available_sources_text = _truncate_sources_text(
                gathered_sources, sources_max_length)
            logger.info(f"ğŸ“š ä¿¡æ¯æºå†…å®¹å·²æˆªæ–­è‡³ {len(available_sources_text)} å­—ç¬¦")

    # 2. å¤„ç†ç”¨æˆ·è¦æ±‚å†…å®¹
    if user_requirement_sources:
        # ç›´æ¥å¤„ç†å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä¸ä¾èµ– _format_requirements_to_text
        prompt_requirements = _sample_format_source_list(
            user_requirement_sources, requirements_max_length)
        logger.info(f"ğŸ“ ç”¨æˆ·è¦æ±‚å†…å®¹: {prompt_requirements}")

    # 3. å¤„ç†æ ·å¼æŒ‡å—å†…å®¹
    if user_style_guide_sources:
        # ç›´æ¥å¤„ç†å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œä¸ä¾èµ– _format_requirements_to_text
        style_requirements = _sample_format_source_list(
            user_style_guide_sources, style_max_length)
        logger.info(f"ğŸ“ æ ·å¼æŒ‡å—å†…å®¹: {style_requirements}")

    # 4. å¤„ç†æ ·å¼æŒ‡å—å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
    formatted_style_guide = ""
    if style_guide_content and style_guide_content.strip():
        # ä¸ºæ ·å¼æŒ‡å—é¢„ç•™ä¸€äº›ç©ºé—´
        style_guide_max_length = style_max_length - len(style_requirements)
        if len(style_guide_content) > style_guide_max_length:
            formatted_style_guide = _sample_format_source_list(
                [style_guide_content], style_guide_max_length)
        else:
            formatted_style_guide = f"\n{style_guide_content}\n"

        logger.info(f"ğŸ“ æ ·å¼æŒ‡å—é•¿åº¦: {len(formatted_style_guide)} å­—ç¬¦")

    # æ„å»ºæœ€ç»ˆprompt
    final_prompt = prompt_template.format(
        topic=topic,
        chapter_title=chapter_title,
        chapter_description=chapter_description,
        chapter_number=current_chapter_index + 1,
        total_chapters=len(chapters_to_process),
        previous_chapters_context=previous_chapters_context or "è¿™æ˜¯ç¬¬ä¸€ç« ï¼Œæ²¡æœ‰å‰ç½®å†…å®¹ã€‚",
        available_sources_text=available_sources_text,
        chapter_word_count=chapter_word_count,
        prompt_requirements=prompt_requirements,
        style_requirements=style_requirements,
        context_for_writing=context_for_writing,
        style_guide_content=formatted_style_guide,
        sub_sections_info=sub_sections_text)

    logger.info(f"ğŸ“ æœ€ç»ˆprompté•¿åº¦: {len(final_prompt)} å­—ç¬¦ (é™åˆ¶: {max_length})")
    return final_prompt


def _update_cited_sources_inplace(raw_text: str,
                                  available_sources: list[Source]) -> None:
    """ æ ¹æ® raw_text ä¸­çš„å†…å®¹ï¼Œè¯†åˆ«å¤šç§å¼•ç”¨æ ‡è®°æ ¼å¼ï¼Œå¹¶æ›´æ–° available_sources ä¸­ id ä¸º n çš„ cited å­—æ®µ

    Args:
        raw_text: LLMçš„åŸå§‹è¾“å‡ºæ–‡æœ¬
        available_sources: å¯ç”¨çš„ä¿¡æ¯æºåˆ—è¡¨
    """
    # åˆ›å»ºæºIDæ˜ å°„
    source_map = {source.id: source for source in available_sources}

    # è¯†åˆ«å¤šç§å¼•ç”¨æ ¼å¼
    cited_source_ids = set()

    # 1. è¯†åˆ« <[n]> æ ¼å¼
    pattern1 = r'<\[(\d+)\]>'
    matches1 = re.findall(pattern1, raw_text)
    for source_id in matches1:
        cited_source_ids.add(int(source_id))

    # 2. è¯†åˆ« **<ä¿¡æ¯æº n>** æ ¼å¼
    pattern2 = r'\*\*<ä¿¡æ¯æº\s*(\d+)>\*\*'
    matches2 = re.findall(pattern2, raw_text)
    for source_id in matches2:
        cited_source_ids.add(int(source_id))

    # 3. è¯†åˆ« <[n], [m]> æ ¼å¼
    pattern3 = r'<\[(\d+)\],\s*\[(\d+)\]>'
    matches3 = re.findall(pattern3, raw_text)
    for match in matches3:
        for source_id in match:
            cited_source_ids.add(int(source_id))

    # 4. è¯†åˆ« [n] æ ¼å¼ï¼ˆæ ‡å‡†å¼•ç”¨æ ¼å¼ï¼‰
    pattern4 = r'\[(\d+)\]'
    matches4 = re.findall(pattern4, raw_text)
    for source_id in matches4:
        cited_source_ids.add(int(source_id))

    # 5. è¯†åˆ« <ä¿¡æ¯æº n> æ ¼å¼
    pattern5 = r'<ä¿¡æ¯æº\s*(\d+)>'
    matches5 = re.findall(pattern5, raw_text)
    for source_id in matches5:
        cited_source_ids.add(int(source_id))

    # æ›´æ–°å¼•ç”¨çŠ¶æ€
    for source_id in cited_source_ids:
        if source_id in source_map:
            source_map[source_id].cited = True
            logger.debug(f"âœ… æ ‡è®°æº [{source_id}] ä¸ºå·²å¼•ç”¨")
        else:
            logger.warning(f"âš ï¸  æœªæ‰¾åˆ°æºID: {source_id}")

    logger.info(f"ğŸ“š è¯†åˆ«åˆ° {len(cited_source_ids)} ä¸ªå¼•ç”¨æº")


def _response_postprocess(response: str) -> str:
    """ å¯¹ LLM çš„åŸå§‹è¾“å‡ºè¿›è¡Œåå¤„ç†ï¼ŒåŒ…æ‹¬ï¼š
    1. åˆ é™¤å‰åçš„ ``` æ ‡è®°
    2. æ ‡å‡†åŒ–å¼•ç”¨æ ¼å¼
    3. å…¶ä»–åå¤„ç†
    """
    # åˆ é™¤å‰åçš„ ``` æ ‡è®°
    response = re.sub(r'```.*?```', '', response, flags=re.DOTALL)

    # æ ‡å‡†åŒ–å¼•ç”¨æ ¼å¼
    response = _standardize_citation_formats(response)

    return response


def _standardize_citation_formats(text: str) -> str:
    """æ ‡å‡†åŒ–å¼•ç”¨æ ¼å¼ï¼Œå°†å„ç§å¼•ç”¨æ ¼å¼ç»Ÿä¸€è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼"""

    # 1. å°† **<ä¿¡æ¯æº n>** è½¬æ¢ä¸º [n]
    text = re.sub(r'\*\*<ä¿¡æ¯æº\s*(\d+)>\*\*', r'[\1]', text)

    # 2. å°† <ä¿¡æ¯æº n> è½¬æ¢ä¸º [n]
    text = re.sub(r'<ä¿¡æ¯æº\s*(\d+)>', r'[\1]', text)

    # 3. å°† <[n], [m]> è½¬æ¢ä¸º [n][m]
    text = re.sub(r'<\[(\d+)\],\s*\[(\d+)\]>', r'[\1][\2]', text)

    # 4. å°† <[n]> è½¬æ¢ä¸º [n]
    text = re.sub(r'<\[(\d+)\]>', r'[\1]', text)

    # 5. å¤„ç†è¿ç»­çš„å¼•ç”¨ï¼Œå¦‚ [1][2][3] ä¿æŒåŸæ ·
    # è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼å·²ç»èƒ½æ­£ç¡®å¤„ç†

    logger.debug(f"ğŸ“ å¼•ç”¨æ ¼å¼æ ‡å‡†åŒ–å®Œæˆ")
    return text


def _truncate_sources_text(sources: list[Source], max_length: int) -> str:
    """æ™ºèƒ½æˆªæ–­ä¿¡æ¯æºæ–‡æœ¬ï¼Œä¼˜å…ˆä¿ç•™é‡è¦ä¿¡æ¯æº"""
    if not sources:
        return ""

    # æŒ‰é‡è¦æ€§æ’åºï¼šå·²å¼•ç”¨çš„ > æœ‰URLçš„ > æœ‰ä½œè€…çš„ > å…¶ä»–
    def source_priority(source):
        priority = 0
        if source.cited:
            priority += 1000
        if source.url:
            priority += 100
        if source.author:
            priority += 10
        return priority

    sorted_sources = sorted(sources, key=source_priority, reverse=True)

    truncated_text = "å¯ç”¨ä¿¡æ¯æºåˆ—è¡¨:\n\n"
    current_length = len(truncated_text)

    for source in sorted_sources:
        source_text = f"[Source {source.id}] {source.title}\n"
        source_text += f"  ç±»å‹: {source.source_type}\n"
        if source.url:
            source_text += f"  URL: {source.url}\n"
        if source.author:
            source_text += f"  ä½œè€…: {source.author}\n"
        if source.date:
            source_text += f"  æ—¥æœŸ: {source.date}\n"
        if source.page_number is not None:
            source_text += f"  é¡µç : {source.page_number}\n"
        if source.file_token:
            source_text += f"  æ–‡ä»¶Token: {source.file_token}\n"

        # æ™ºèƒ½æˆªæ–­å†…å®¹
        content_preview = source.content[:150] + "..." if len(
            source.content) > 150 else source.content
        source_text += f"  å†…å®¹: {content_preview}\n\n"

        if current_length + len(source_text) > max_length:
            truncated_text += f"... (è¿˜æœ‰ {len(sorted_sources) - len(truncated_text.split('[Source')) + 1} ä¸ªä¿¡æ¯æºæœªæ˜¾ç¤º)\n"
            break

        truncated_text += source_text
        current_length += len(source_text)

    return truncated_text


def _summarize_requirements(requirements_content: list,
                            max_length: int) -> str:
    """æç‚¼ç”¨æˆ·è¦æ±‚çš„è¦ç‚¹"""
    if not requirements_content:
        return ""

    # ç®€å•çš„å…³é”®è¯æå–å’Œæ€»ç»“
    summary = "ç”¨æˆ·è¦æ±‚è¦ç‚¹:\n"

    for i, requirement in enumerate(requirements_content, 1):
        if isinstance(requirement, str):
            # æå–å‰50ä¸ªå­—ç¬¦ä½œä¸ºè¦ç‚¹
            key_point = requirement[:50] + "..." if len(
                requirement) > 50 else requirement
            summary += f"{i}. {key_point}\n"
        elif isinstance(requirement, dict):
            # å¦‚æœæ˜¯å­—å…¸ï¼Œæå–å…³é”®å­—æ®µ
            title = requirement.get('title', 'æœªå‘½åè¦æ±‚')
            content = requirement.get('content', '')
            key_point = content[:30] + "..." if len(content) > 30 else content
            summary += f"{i}. {title}: {key_point}\n"

    # å¦‚æœè¿˜æ˜¯å¤ªé•¿ï¼Œè¿›ä¸€æ­¥æˆªæ–­
    if len(summary) > max_length:
        summary = summary[:max_length - 20] + "...\n"

    return summary


def _sample_format_source_list(requirements_content: list[Source],
                               max_length: int) -> str:
    """æ ¼å¼åŒ–è¦æ±‚åˆ—è¡¨ä¸ºæ–‡æœ¬"""
    if not requirements_content:
        return ""

    whole_content = "".join(
        [source.content for source in requirements_content])
    if len(whole_content) <= max_length:
        return whole_content

    sample_rate = max_length / len(whole_content)
    sample_count = max(1, int(sample_rate * len(requirements_content)))

    # éšæœºæŠ½å–ä½†ä¿æŒé¡ºåº
    if sample_rate < 1:
        import random
        # ç”Ÿæˆæ‰€æœ‰ç´¢å¼•ï¼Œç„¶åéšæœºé€‰æ‹© sample_count ä¸ªï¼Œä¿æŒé¡ºåº
        all_indices = list(range(len(requirements_content)))
        selected_indices = sorted(random.sample(all_indices, sample_count))
        sampled_sources = [requirements_content[i] for i in selected_indices]
        sampled_content = "... ".join(
            [source.content for source in sampled_sources])
    else:
        sampled_content = whole_content

    return sampled_content
