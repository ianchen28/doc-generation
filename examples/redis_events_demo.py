#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Redisäº‹ä»¶æµæ¼”ç¤ºè„šæœ¬
å±•ç¤ºå¦‚ä½•ç›‘å¬å’Œå¤„ç†LangGraphæ‰§è¡Œè¿‡ç¨‹ä¸­çš„å®æ—¶äº‹ä»¶
"""

import asyncio
import aioredis
import json
import aiohttp
from doc_agent.core.logger import logger
from datetime import datetime


class RedisEventsListener:
    """Redisäº‹ä»¶ç›‘å¬å™¨"""

    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.redis_url = redis_url
        self.redis_client = None
        self.is_listening = False

    async def connect(self):
        """è¿æ¥åˆ°Redis"""
        try:
            self.redis_client = aioredis.from_url(self.redis_url,
                                                  encoding="utf-8",
                                                  decode_responses=True)
            await self.redis_client.ping()
            logger.info("âœ… Redisè¿æ¥æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"âŒ Redisè¿æ¥å¤±è´¥: {e}")
            return False

    async def listen_to_job_events(self, job_id: str, timeout: int = 300):
        """
        ç›‘å¬æŒ‡å®šä½œä¸šçš„äº‹ä»¶æµ
        
        Args:
            job_id: ä½œä¸šID
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        channel_name = f"job:{job_id}:events"
        logger.info(f"ğŸ§ å¼€å§‹ç›‘å¬ä½œä¸šäº‹ä»¶: {channel_name}")

        try:
            # åˆ›å»ºè®¢é˜…
            pubsub = self.redis_client.pubsub()
            await pubsub.subscribe(channel_name)

            self.is_listening = True
            start_time = asyncio.get_event_loop().time()

            logger.info(f"ğŸ“¡ ç­‰å¾…äº‹ä»¶... (è¶…æ—¶: {timeout}ç§’)")

            async for message in pubsub.listen():
                # æ£€æŸ¥è¶…æ—¶
                if asyncio.get_event_loop().time() - start_time > timeout:
                    logger.warning(f"â° ç›‘å¬è¶…æ—¶ ({timeout}ç§’)")
                    break

                # è·³è¿‡è®¢é˜…ç¡®è®¤æ¶ˆæ¯
                if message['type'] != 'message':
                    continue

                try:
                    # è§£æäº‹ä»¶æ•°æ®
                    event_data = json.loads(message['data'])
                    await self._handle_event(event_data)

                    # æ£€æŸ¥æ˜¯å¦ä¸ºå®Œæˆäº‹ä»¶
                    if (event_data.get('event') == 'done' and event_data.get(
                            'data', {}).get('task') == 'main_workflow'):
                        logger.info("ğŸ‰ ä¸»å·¥ä½œæµå®Œæˆï¼Œåœæ­¢ç›‘å¬")
                        break

                except json.JSONDecodeError as e:
                    logger.error(f"âŒ äº‹ä»¶æ•°æ®è§£æå¤±è´¥: {e}")
                except Exception as e:
                    logger.error(f"âŒ å¤„ç†äº‹ä»¶æ—¶å‡ºé”™: {e}")

            await pubsub.unsubscribe(channel_name)
            logger.info("ğŸ“´ äº‹ä»¶ç›‘å¬ç»“æŸ")

        except Exception as e:
            logger.error(f"âŒ äº‹ä»¶ç›‘å¬å¤±è´¥: {e}")
        finally:
            self.is_listening = False

    async def _handle_event(self, event_data: dict):
        """å¤„ç†å•ä¸ªäº‹ä»¶"""
        event_type = event_data.get('event', 'unknown')
        data = event_data.get('data', {})
        timestamp = event_data.get('timestamp', '')

        # æ ¼å¼åŒ–æ—¶é—´æˆ³
        try:
            if timestamp:
                dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                time_str = dt.strftime('%H:%M:%S')
            else:
                time_str = datetime.now().strftime('%H:%M:%S')
        except:
            time_str = "??:??:??"

        # æ ¹æ®äº‹ä»¶ç±»å‹å¤„ç†
        if event_type == 'phase_update':
            phase = data.get('phase', 'UNKNOWN')
            message = data.get('message', '')
            logger.info(f"ğŸ”„ [{time_str}] é˜¶æ®µæ›´æ–°: {phase} - {message}")

        elif event_type == 'thought':
            text = data.get('text', '')[:100] + ('...' if len(
                data.get('text', '')) > 100 else '')
            model = data.get('model_name', 'LLM')
            logger.info(f"ğŸ’­ [{time_str}] {model} æ€è€ƒ: {text}")

        elif event_type == 'tool_call':
            tool_name = data.get('tool_name', 'Unknown')
            status = data.get('status', 'UNKNOWN')
            if status == 'START':
                input_text = data.get('input', '')[:50] + ('...' if len(
                    data.get('input', '')) > 50 else '')
                logger.info(
                    f"ğŸ”§ [{time_str}] å·¥å…·è°ƒç”¨: {tool_name} - è¾“å…¥: {input_text}")
            else:
                output_len = data.get('output_length', 0)
                logger.info(
                    f"âœ… [{time_str}] å·¥å…·å®Œæˆ: {tool_name} - è¾“å‡ºé•¿åº¦: {output_len}")

        elif event_type == 'source_found':
            source_type = data.get('source_type', 'unknown')
            title = data.get('title', 'Unknown Source')
            snippet = data.get('snippet', '')[:80] + ('...' if len(
                data.get('snippet', '')) > 80 else '')
            logger.info(
                f"ğŸ“š [{time_str}] å‘ç°èµ„æº: {title} ({source_type}) - {snippet}")

        elif event_type == 'error':
            code = data.get('code', 'N/A')
            message = data.get('message', 'Unknown error')
            logger.error(f"âŒ [{time_str}] é”™è¯¯ ({code}): {message}")

        elif event_type == 'done':
            task = data.get('task', 'unknown')
            message = data.get('message', 'Task completed')
            logger.success(f"âœ… [{time_str}] å®Œæˆ: {task} - {message}")

        else:
            logger.debug(f"ğŸ“ [{time_str}] å…¶ä»–äº‹ä»¶: {event_type} - {data}")

    async def close(self):
        """å…³é—­è¿æ¥"""
        if self.redis_client:
            await self.redis_client.close()
            logger.info("ğŸ”Œ Redisè¿æ¥å·²å…³é—­")


class APIClient:
    """APIå®¢æˆ·ç«¯"""

    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.session = None

    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()

    async def create_job(self, task_prompt: str) -> str:
        """åˆ›å»ºä½œä¸š"""
        data = {"task_prompt": task_prompt}
        async with self.session.post(f"{self.base_url}/api/v1/jobs",
                                     json=data) as response:
            if response.status == 201:
                result = await response.json()
                return result["job_id"]
            else:
                error = await response.text()
                raise Exception(f"åˆ›å»ºä½œä¸šå¤±è´¥: {error}")

    async def generate_outline(self, job_id: str):
        """ç”Ÿæˆå¤§çº²"""
        async with self.session.post(
                f"{self.base_url}/api/v1/jobs/{job_id}/outline") as response:
            if response.status != 202:
                error = await response.text()
                raise Exception(f"å¤§çº²ç”Ÿæˆå¤±è´¥: {error}")

    async def wait_for_outline(self, job_id: str, max_attempts: int = 30):
        """ç­‰å¾…å¤§çº²å®Œæˆ"""
        for _ in range(max_attempts):
            async with self.session.get(
                    f"{self.base_url}/api/v1/jobs/{job_id}/outline"
            ) as response:
                if response.status == 200:
                    result = await response.json()
                    if result["outline_status"] == "READY":
                        return result["outline"]
                    elif result["outline_status"] == "FAILED":
                        raise Exception("å¤§çº²ç”Ÿæˆå¤±è´¥")
            await asyncio.sleep(2)
        raise Exception("å¤§çº²ç”Ÿæˆè¶…æ—¶")

    async def update_outline_and_start_generation(self, job_id: str,
                                                  outline: dict):
        """æ›´æ–°å¤§çº²å¹¶å¼€å§‹æœ€ç»ˆç”Ÿæˆ"""
        data = {"outline": outline}
        async with self.session.put(
                f"{self.base_url}/api/v1/jobs/{job_id}/outline",
                json=data) as response:
            if response.status != 200:
                error = await response.text()
                raise Exception(f"å¤§çº²æ›´æ–°å¤±è´¥: {error}")


async def run_complete_demo():
    """è¿è¡Œå®Œæ•´çš„æ¼”ç¤º"""
    logger.info("ğŸš€ å¼€å§‹Redisäº‹ä»¶æµå®Œæ•´æ¼”ç¤º")

    # åˆ›å»ºäº‹ä»¶ç›‘å¬å™¨
    listener = RedisEventsListener()
    if not await listener.connect():
        return

    try:
        async with APIClient() as api:
            # 1. åˆ›å»ºä½œä¸š
            logger.info("ğŸ“ åˆ›å»ºæ–°ä½œä¸š...")
            task_prompt = "ç¼–å†™ä¸€ä»½å…³äºæ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ä¸­åº”ç”¨çš„æŠ€æœ¯æŠ¥å‘Š"
            job_id = await api.create_job(task_prompt)
            logger.info(f"âœ… ä½œä¸šåˆ›å»ºæˆåŠŸ: {job_id}")

            # 2. ç”Ÿæˆå¤§çº²
            logger.info("ğŸ“‹ å¼€å§‹ç”Ÿæˆå¤§çº²...")
            await api.generate_outline(job_id)

            # 3. ç­‰å¾…å¤§çº²å®Œæˆ
            logger.info("â³ ç­‰å¾…å¤§çº²ç”Ÿæˆå®Œæˆ...")
            outline = await api.wait_for_outline(job_id)
            logger.info(f"âœ… å¤§çº²ç”Ÿæˆå®Œæˆ: {outline['title']}")

            # 4. å¯åŠ¨äº‹ä»¶ç›‘å¬ï¼ˆå¼‚æ­¥ï¼‰
            logger.info("ğŸ§ å¯åŠ¨äº‹ä»¶ç›‘å¬...")
            listen_task = asyncio.create_task(
                listener.listen_to_job_events(job_id, timeout=600)  # 10åˆ†é’Ÿè¶…æ—¶
            )

            # 5. ç¨ç­‰ä¸€ä¸‹ç¡®ä¿ç›‘å¬å™¨å‡†å¤‡å¥½
            await asyncio.sleep(2)

            # 6. æ›´æ–°å¤§çº²å¹¶è§¦å‘æœ€ç»ˆç”Ÿæˆï¼ˆè¿™å°†äº§ç”Ÿå¤§é‡äº‹ä»¶ï¼‰
            logger.info("ğŸš€ æ›´æ–°å¤§çº²å¹¶å¼€å§‹æœ€ç»ˆæ–‡æ¡£ç”Ÿæˆ...")
            await api.update_outline_and_start_generation(job_id, outline)

            # 7. ç­‰å¾…äº‹ä»¶ç›‘å¬å®Œæˆ
            logger.info("â³ ç­‰å¾…å·¥ä½œæµå®Œæˆ...")
            await listen_task

            logger.info("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")

    except Exception as e:
        logger.error(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        await listener.close()


async def run_simple_demo():
    """è¿è¡Œç®€å•çš„äº‹ä»¶ç›‘å¬æ¼”ç¤º"""
    logger.info("ğŸ§ ç®€å•äº‹ä»¶ç›‘å¬æ¼”ç¤º")
    logger.info("ğŸ’¡ è¯·åœ¨å¦ä¸€ä¸ªç»ˆç«¯ä¸­åˆ›å»ºå’Œè¿è¡Œä½œä¸šï¼Œç„¶åè¾“å…¥ä½œä¸šID")

    job_id = input("è¯·è¾“å…¥è¦ç›‘å¬çš„ä½œä¸šID: ").strip()
    if not job_id:
        logger.error("âŒ ä½œä¸šIDä¸èƒ½ä¸ºç©º")
        return

    listener = RedisEventsListener()
    if not await listener.connect():
        return

    try:
        await listener.listen_to_job_events(job_id, timeout=600)
    except KeyboardInterrupt:
        logger.info("ğŸ›‘ ç”¨æˆ·ä¸­æ–­ç›‘å¬")
    finally:
        await listener.close()


if __name__ == "__main__":
    import sys

    # é…ç½®æ—¥å¿—
    logger.add("logs/redis_events_demo.log", rotation="1 day", level="INFO")

    if len(sys.argv) > 1 and sys.argv[1] == "simple":
        # ç®€å•æ¨¡å¼ï¼šåªç›‘å¬äº‹ä»¶
        asyncio.run(run_simple_demo())
    else:
        # å®Œæ•´æ¼”ç¤ºï¼šåˆ›å»ºä½œä¸šå¹¶ç›‘å¬äº‹ä»¶
        asyncio.run(run_complete_demo())
