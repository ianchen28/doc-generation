"""
ç”ŸæˆèŠ‚ç‚¹æ¨¡å—

è´Ÿè´£å¤§çº²ç”Ÿæˆã€ç« èŠ‚æ‹†åˆ†ã€å‚è€ƒæ–‡çŒ®ç”Ÿæˆç­‰åŠŸèƒ½
"""

import json
import os
import re
import tempfile

from doc_agent.common.prompt_selector import PromptSelector
from doc_agent.core.config import settings
from doc_agent.core.logger import logger
from doc_agent.graph.callbacks import publish_event
from doc_agent.graph.common import format_sources_to_text
from doc_agent.graph.state import ResearchState
from doc_agent.llm_clients.base import LLMClient
from doc_agent.schemas import Source
from doc_agent.tools.file_module import FileProcessor


def outline_generation_node(state: ResearchState,
                            llm_client: LLMClient,
                            prompt_selector: PromptSelector = None,
                            genre: str = "default") -> dict:
    """
    å¤§çº²ç”ŸæˆèŠ‚ç‚¹ - ç»Ÿä¸€ç‰ˆæœ¬
    æ ¹æ®åˆå§‹ç ”ç©¶æ•°æ®ç”Ÿæˆæ–‡æ¡£å¤§çº²
    æ”¯æŒåŸºäºé…ç½®çš„è¡Œä¸ºè°ƒæ•´

    Args:
        state: ç ”ç©¶çŠ¶æ€
        llm_client: LLMå®¢æˆ·ç«¯
        prompt_selector: æç¤ºè¯é€‰æ‹©å™¨
        genre: æ–‡æ¡£ç±»å‹

    Returns:
        dict: åŒ…å« document_outline çš„å­—å…¸
    """
    topic = state.get("topic", "")
    initial_sources = state.get("initial_sources", [])
    job_id = state.get("job_id", "")
    word_count = state.get("word_count", -1)
    prompt_requirements = state.get("prompt_requirements", "")

    if not topic:
        raise ValueError("ä¸»é¢˜ä¸èƒ½ä¸ºç©º")

    # è·å–å¤æ‚åº¦é…ç½®
    complexity_config = settings.get_complexity_config()
    logger.info(f"ğŸ“‹ å¼€å§‹ç”Ÿæˆå¤§çº² (æ¨¡å¼: {complexity_config['level']}): {topic}")

    # æ ¼å¼åŒ–æ•°æ®
    if initial_sources:
        initial_gathered_data = format_sources_to_text(initial_sources)
    else:
        initial_gathered_data = state.get("initial_gathered_data", "")

    if not initial_gathered_data and not prompt_requirements:
        logger.warning("æ²¡æœ‰åˆå§‹ç ”ç©¶æ•°æ®ï¼Œä¹Ÿæ²¡æœ‰ç”¨æˆ·è¦æ±‚")
        # return _generate_default_outline(topic, complexity_config)

    # è·å–æç¤ºè¯æ¨¡æ¿
    prompt_template = _get_outline_prompt_template(complexity_config,
                                                   prompt_selector, genre)

    # æ„å»ºæç¤ºè¯
    prompt = prompt_template.format(
        topic=topic,
        prompt_requirements=prompt_requirements,
        word_count=word_count,
        initial_gathered_data=initial_gathered_data[:10000]  # é™åˆ¶é•¿åº¦
    )

    try:
        # æ ¹æ®å¤æ‚åº¦è°ƒæ•´å‚æ•°
        temperature = 0.7
        max_tokens = 2000

        response = llm_client.invoke(prompt,
                                     temperature=temperature,
                                     max_tokens=max_tokens)

        # è§£æå“åº”
        outline = _parse_outline_response(response, complexity_config)
        if word_count > 0:
            outline["estimated_total_words"] = word_count

        logger.info(
            f"âœ… Job {job_id} å¤§çº²ç”Ÿæˆå®Œæˆï¼ŒåŒ…å« {len(outline.get('chapters', []))} ä¸ªç« èŠ‚")
        logger.info(f"ç”Ÿæˆå¤§çº²å†…å®¹ï¼š {outline}")

        # å°†å¤§çº²ä¿å­˜ä¸ºæ–‡ä»¶å¹¶ä¸Šä¼ åˆ°å­˜å‚¨æœåŠ¡
        file_token = None
        try:
            # åˆå§‹åŒ–æ–‡ä»¶å¤„ç†å™¨
            file_processor = FileProcessor()

            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(mode='w',
                                             suffix='.json',
                                             delete=False,
                                             encoding='utf-8') as temp_file:
                json.dump(outline, temp_file, ensure_ascii=False, indent=2)
                temp_file_path = temp_file.name

            # ä¸Šä¼ æ–‡ä»¶
            file_token = file_processor.upload_file(temp_file_path)
            logger.info(f"ğŸ“ å¤§çº²æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼ŒToken: {file_token}")

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_file_path)

        except Exception as e:
            logger.error(f"å¤§çº²æ–‡ä»¶ä¸Šä¼ å¤±è´¥: {str(e)}")
            file_token = None

        publish_event(
            job_id,
            "å¤§çº²ç”Ÿæˆ",
            "outline_generation",
            "SUCCESS", {
                "outline": outline,
                "file_token": file_token,
                "description":
                f"å¤§çº²ç”Ÿæˆå®Œæˆï¼ŒåŒ…å« {len(outline.get('chapters', []))} ä¸ªç« èŠ‚"
            },
            task_finished=True)

        return {"document_outline": outline}

    except Exception as e:
        logger.error(f"å¤§çº²ç”Ÿæˆå¤±è´¥: {str(e)}")
        return _generate_default_outline(topic, complexity_config)


def split_chapters_node(state: ResearchState, llm_client: LLMClient) -> dict:
    """
    ç« èŠ‚æ‹†åˆ†èŠ‚ç‚¹ - ç»Ÿä¸€ç‰ˆæœ¬
    å°†æ–‡æ¡£å¤§çº²æ‹†åˆ†ä¸ºç‹¬ç«‹çš„ç« èŠ‚ä»»åŠ¡åˆ—è¡¨
    æ ¹æ®é…ç½®é™åˆ¶ç« èŠ‚æ•°é‡
    """

    document_outline = state.get("document_outline", {})

    if not document_outline or "chapters" not in document_outline:
        raise ValueError("æ–‡æ¡£å¤§çº²ä¸å­˜åœ¨æˆ–æ ¼å¼æ— æ•ˆ")

    # è·å–å¤æ‚åº¦é…ç½®
    complexity_config = settings.get_complexity_config()
    max_chapters = complexity_config.get('max_chapters', -1)

    chapters_to_process = []
    chapters = document_outline['chapters']

    # é™åˆ¶ç« èŠ‚æ•°é‡
    # if max_chapters > 0:
    #     chapters = chapters[:max_chapters]

    publish_event(
        state.get("job_id", ""), "å¤§çº²è§£æ", "document_generation", "RUNNING", {
            "description": "å¼€å§‹è§£æç°æœ‰å¤§çº²...",
            "documentTitle": document_outline.get("title", "")
        })

    for chapter in chapters:
        # å…¼å®¹æ–°æ—§æ ¼å¼
        chapter_title = chapter.get('title', chapter.get('chapter_title', ''))
        chapter_number = chapter.get('number',
                                     chapter.get('chapter_number', 0))
        description = chapter.get('description', '')

        # å…¼å®¹æ–°æ—§æ ¼å¼ï¼šsections vs sub_sections
        sections = chapter.get('sections', chapter.get('sub_sections', []))

        # è½¬æ¢å­èŠ‚æ ¼å¼
        sub_sections = []
        for section in sections:
            # å…¼å®¹æ–°æ—§æ ¼å¼
            section_title = section.get('title',
                                        section.get('section_title', ''))
            section_number = section.get('number',
                                         section.get('section_number', 0))
            section_description = section.get(
                'description', section.get('section_description', ''))
            key_points = section.get('key_points', [])

            sub_sections.append({
                "section_number": section_number,
                "section_title": section_title,
                "section_description": section_description,
                "key_points": key_points
            })

        chapters_to_process.append({
            "chapter_number": chapter_number,
            "chapter_title": chapter_title,
            "description": description,
            "key_points": [],
            "estimated_sections": len(sub_sections),
            "sub_sections": sub_sections,
            "research_data": ""
        })

    # è·å–ä¸€å¥è¯ç ”ç©¶è®¡åˆ’å‘ŠçŸ¥
    plan_prompt1 = """
ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„æ€»ç¼–è¾‘å’Œå†™ä½œè§„åˆ’å¸ˆã€‚

ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„æ–‡ç« æ ‡é¢˜ã€ä»»åŠ¡è¦æ±‚ã€æ–‡ç« å¤§çº²å’Œæ€»å­—æ•°ï¼Œåˆ¶å®šä¸€ä¸ªæ¸…æ™°çš„ç« èŠ‚å†™ä½œè®¡åˆ’ã€‚
**è¾“å…¥å†…å®¹**
- ã€æ–‡ç« æ ‡é¢˜ã€‘
- ã€ä»»åŠ¡è¦æ±‚ã€‘
- ã€æ–‡ç« å¤§çº²ã€‘
- ã€å…¨æ–‡å­—æ•°ã€‘

**æ ¸å¿ƒæŒ‡ä»¤:**

1.  **ç”Ÿæˆä»»åŠ¡æ¦‚è¿° (Overview)**: ç»“åˆã€æ–‡ç« æ ‡é¢˜ã€‘å’Œã€ä»»åŠ¡è¦æ±‚ã€‘ï¼Œç”¨ä¸€å¥è¯ç²¾ç‚¼åœ°æ€»ç»“å‡ºæœ¬æ¬¡å†™ä½œä»»åŠ¡çš„æ ¸å¿ƒç›®æ ‡ä»¥åŠä½ è®¡åˆ’è¦åšçš„äº‹æƒ…ã€‚
2.  **åˆ†é…ç« èŠ‚å­—æ•° (Allocate Word Count)**:
    * **æ™ºèƒ½åŠ æƒåˆ†é…**: ä½ å¿…é¡»å°†ã€å…¨æ–‡å­—æ•°ã€‘æ™ºèƒ½åœ°åˆ†é…åˆ°ã€æ–‡ç« å¤§çº²ã€‘çš„æ¯ä¸€ä¸ªä¸»è¦ç« èŠ‚ï¼ˆé€šå¸¸æ˜¯äºŒçº§æ ‡é¢˜ï¼‰ã€‚**åˆ‡å‹¿å¹³å‡åˆ†é…**ã€‚
    * **åˆ†é…ä¾æ®**: åˆ†é…å­—æ•°æ—¶ï¼Œå¿…é¡»ç»¼åˆè€ƒè™‘ä»¥ä¸‹å› ç´ ï¼š
        * **å†…å®¹é‡è¦æ€§**: å¤§çº²ä¸­åŒ…å«æ›´å¤šå­è¦ç‚¹ã€æè¿°æ›´è¯¦ç»†ã€æˆ–ä¸ã€ä»»åŠ¡è¦æ±‚ã€‘ç›´æ¥ç›¸å…³çš„æ ¸å¿ƒç« èŠ‚ï¼Œåº”åˆ†é…æ›´å¤šå­—æ•°ã€‚
        * **ç« èŠ‚ç±»å‹**: é€šå¸¸ï¼Œâ€œå¼•è¨€â€å’Œâ€œç»“è®ºâ€éƒ¨åˆ†å æ¯”è¾ƒå°ï¼ˆä¾‹å¦‚ï¼Œå„è‡ªå æ€»å­—æ•°çš„ 10-15%ï¼‰ï¼Œè€Œä¸»ä½“åˆ†æã€è®ºè¯ç« èŠ‚å æ¯”è¾ƒå¤§ã€‚
    * **æ•°å­¦çº¦æŸ**: æ‰€æœ‰ `chapter_word_counts` åˆ—è¡¨ä¸­çš„ `word_count` ä¹‹å’Œï¼Œ**å¿…é¡»ä¸¥æ ¼ç­‰äº**ã€å…¨æ–‡å­—æ•°ã€‘ã€‚è¿™æ˜¯ä¸€ä¸ªç¡¬æ€§è¦æ±‚ã€‚
3.  **æ ¼å¼åŒ–è¾“å‡º**: ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªå•ä¸€ã€æœ‰æ•ˆçš„ JSON å¯¹è±¡ã€‚é™¤äº†è¿™ä¸ª JSON å¯¹è±¡ï¼Œä¸è¦è¿”å›ä»»ä½•é¢å¤–çš„è§£é‡Šã€æ³¨é‡Šæˆ–æ–‡å­—ã€‚

**JSON è¾“å‡ºæ ¼å¼:**
```json
{
  "overview": "ä¸€å¥è¯æ€»ç»“ä¸€ä¸‹è¦å®Œæˆä»»åŠ¡è¦åšçš„äº‹æƒ…ã€‚",
  "chapter_word_counts": [
    {
      "title": "ç« èŠ‚æ ‡é¢˜",
      "word_count": "åˆ†é…ç»™è¯¥ç« èŠ‚çš„å­—æ•°ï¼ˆæ•°å­—ï¼‰"
    }
  ]
}
```

ç¤ºä¾‹å­¦ä¹ ï¼š

è¾“å…¥ï¼š
- ã€æ–‡ç« æ ‡é¢˜ã€‘: "äººå·¥æ™ºèƒ½åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨ä¸æŒ‘æˆ˜"
- ã€ä»»åŠ¡è¦æ±‚ã€‘: "å¸®æˆ‘å†™ä¸€ç¯‡ 5000 å­—çš„æ·±åº¦ç ”ç©¶æŠ¥å‘Šæ¥ç ”ç©¶äººå·¥æ™ºèƒ½åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨è¿›å±•ï¼Œéœ€è¦æœ‰å…·ä½“çš„æ¡ˆä¾‹åˆ†æï¼Œå¹¶å¯¹æœªæ¥çš„å‘å±•è¶‹åŠ¿æå‡ºè‡ªå·±çš„çœ‹æ³•ã€‚"
- ã€æ–‡ç« å¤§çº²ã€‘:
{'title': 'äººå·¥æ™ºèƒ½æŠ€æœ¯å‘å±•è¶‹åŠ¿', 'word_count': 0, 'chapters': [{'number': 1, 'title': 'äººå·¥æ™ºèƒ½æŠ€æœ¯æ¦‚è¿°', 'description': 'ä»‹ç»äººå·¥æ™ºèƒ½çš„åŸºæœ¬æ¦‚å¿µã€å‘å±•å†ç¨‹å’Œå½“å‰æŠ€æœ¯ç°çŠ¶ï¼Œä¸ºåç»­ç« èŠ‚çš„æ·±å…¥åˆ†æå¥ å®šåŸºç¡€ã€‚', 'sections': [{'number': 1.1, 'title': 'äººå·¥æ™ºèƒ½çš„åŸºæœ¬æ¦‚å¿µ', 'description': 'å®šä¹‰äººå·¥æ™ºèƒ½ï¼Œä»‹ç»å…¶æ ¸å¿ƒæŠ€æœ¯å’Œå·¥ä½œåŸç†ã€‚', 'key_points': ['äººå·¥æ™ºèƒ½çš„å®šä¹‰', 'æ ¸å¿ƒæŠ€æœ¯å’Œå·¥ä½œåŸç†', 'ä¸ç›¸å…³é¢†åŸŸçš„è”ç³»']}, {'number': 1.2, 'title': 'äººå·¥æ™ºèƒ½çš„å‘å±•å†ç¨‹', 'description': 'å›é¡¾äººå·¥æ™ºèƒ½ä»è¯ç”Ÿåˆ°ç°åœ¨çš„å…³é”®å‘å±•é˜¶æ®µï¼Œåˆ†æå„é˜¶æ®µçš„ä¸»è¦æˆå°±å’ŒæŒ‘æˆ˜ã€‚', 'key_points': ['20ä¸–çºª50å¹´ä»£çš„å…´èµ·ä¸å†·è½', '20ä¸–çºª60å¹´ä»£æœ«åˆ°70å¹´ä»£çš„ä¸“å®¶ç³»ç»Ÿ', '21ä¸–çºªçš„å¿«é€Ÿå‘å±•']}, {'number': 1.3, 'title': 'å½“å‰æŠ€æœ¯ç°çŠ¶', 'description': 'æ¦‚è¿°å½“å‰äººå·¥æ™ºèƒ½æŠ€æœ¯çš„ä¸»è¦ç‰¹ç‚¹å’Œå‘å±•æ°´å¹³ï¼Œæ¢è®¨å…¶åœ¨å…¨çƒèŒƒå›´å†…çš„åº”ç”¨æƒ…å†µã€‚', 'key_points': ['æŠ€æœ¯ç‰¹ç‚¹æ¦‚è¿°', 'å…¨çƒåº”ç”¨æƒ…å†µ', 'ä¸»è¦æŒ‘æˆ˜ä¸æœºé‡']}]}, {'number': 2, 'title': 'æœºå™¨å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ ', 'description': 'æ·±å…¥æ¢è®¨æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„åŸºæœ¬ç†è®ºã€æŠ€æœ¯ç‰¹ç‚¹åŠå…¶åœ¨å®é™…åº”ç”¨ä¸­çš„è¡¨ç°ã€‚', 'sections': [{'number': 2.1, 'title': 'æœºå™¨å­¦ä¹ çš„åŸºç¡€ç†è®º', 'description': 'ä»‹ç»æœºå™¨å­¦ä¹ çš„åŸºæœ¬åŸç†ã€ä¸»è¦ç®—æ³•å’Œåº”ç”¨åœºæ™¯ã€‚', 'key_points': ['æœºå™¨å­¦ä¹ çš„å®šä¹‰ä¸åŸç†', 'ä¸»è¦ç®—æ³•ç±»å‹', 'å…¸å‹åº”ç”¨åœºæ™¯']}, {'number': 2.2, 'title': 'æ·±åº¦å­¦ä¹ çš„æŠ€æœ¯ç‰¹ç‚¹', 'description': 'æ¢è®¨æ·±åº¦å­¦ä¹ çš„æŠ€æœ¯ç‰¹ç‚¹ã€æ¶æ„å’Œä¼˜åŠ¿ï¼Œåˆ†æå…¶åœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸçš„åº”ç”¨ã€‚', 'key_points': ['æ·±åº¦å­¦ä¹ çš„å®šä¹‰ä¸ç‰¹ç‚¹', 'å¤šå±‚ç¥ç»ç½‘ç»œæ¶æ„', 'åº”ç”¨æ¡ˆä¾‹åˆ†æ']}, {'number': 2.3, 'title': 'æœºå™¨å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ çš„å¯¹æ¯”', 'description': 'å¯¹æ¯”åˆ†ææœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ çš„ä¸»è¦å¼‚åŒï¼Œæ¢è®¨å…¶åœ¨ä¸åŒåº”ç”¨åœºæ™¯ä¸­çš„é€‰æ‹©ç­–ç•¥ã€‚', 'key_points': ['æŠ€æœ¯ä¸Šçš„å¼‚åŒç‚¹', 'åº”ç”¨åœºæ™¯çš„å·®å¼‚', 'é€‰æ‹©ç­–ç•¥ä¸æœªæ¥è¶‹åŠ¿']}]}]}

- ã€å…¨æ–‡å­—æ•°ã€‘: 5000

è¾“å‡ºï¼š
```json
{
  "overview": "æˆ‘å°†ä¸ºæ‚¨æ’°å†™ä¸€ç¯‡æ–‡ç« æ¥åˆ†æäººå·¥æ™ºèƒ½æŠ€æœ¯çš„å‘å±•è¶‹åŠ¿ï¼ŒåŒ…æ‹¬åŸºæœ¬æ¦‚å¿µã€å‘å±•å†ç¨‹ã€æŠ€æœ¯ç°çŠ¶ã€æœºå™¨å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ ã€åº”ç”¨åœºæ™¯ç­‰ï¼Œä¸ºåç»­ç« èŠ‚çš„æ·±å…¥åˆ†æå¥ å®šåŸºç¡€ã€‚",
  "chapter_word_counts": [
    {
      "title": "äººå·¥æ™ºèƒ½æŠ€æœ¯æ¦‚è¿°",
      "word_count": 2500
    },
    {
      "title": "æœºå™¨å­¦ä¹ ä¸æ·±åº¦å­¦ä¹ ",
      "word_count": 2500
    }
  ]
}
```

"""

    plan_prompt_template2 = """
ä»»åŠ¡å¼€å§‹
è¯·æ ¹æ®ä¸‹é¢çš„è¾“å…¥ï¼Œç”Ÿæˆå†™ä½œè®¡åˆ’ï¼Œå¹¶è¾“å‡ºjsonæ ¼å¼

è¾“å…¥ï¼š
- ã€æ–‡ç« æ ‡é¢˜ã€‘ï¼š{topic}
- ã€ä»»åŠ¡è¦æ±‚ã€‘: {task_prompt}
- ã€æ–‡ç« å¤§çº²ã€‘: {document_outline_str}
- ã€å…¨æ–‡å­—æ•°ã€‘: {word_count}

è¾“å‡ºï¼š
"""
    logger.info(f"outline_from_fe: {document_outline}")
    plan_prompt2 = plan_prompt_template2.format(
        topic=state.get("topic", ""),
        task_prompt=state.get("task_prompt", ""),
        document_outline_str=json.dumps(document_outline, ensure_ascii=False),
        word_count=state.get("word_count", 0))

    plan_prompt = plan_prompt1 + plan_prompt2
    response = llm_client.invoke(plan_prompt, temperature=0.5, max_tokens=2000)

    logger.info(f"plan_prompt: {plan_prompt}")
    logger.info(f"response: {response}")
    # æå– json å†…å®¹
    json_patterns = [
        r'```json\s*(.*?)\s*```',  # ```json ... ```
        r'```\s*(.*?)\s*```',  # ``` ... ``` r'\{.*\}',  # ä»»ä½•JSONå¯¹è±¡
    ]

    for pattern in json_patterns:
        json_match = re.search(pattern, response, re.DOTALL)
        if json_match:
            try:
                json_str = json_match.group(
                    1) if pattern != r'\{.*\}' else json_match.group(0)
                plan_json = json.loads(json_str)
                logger.info(f"âœ… ä½¿ç”¨æ¨¡å¼ {pattern} æˆåŠŸè§£æJSON")
                break
            except json.JSONDecodeError:
                logger.error(f"âŒ ä½¿ç”¨æ¨¡å¼ {pattern} è§£æJSONå¤±è´¥: {json_str}")
                continue

    if not plan_json:
        logger.error("âŒ æ— æ³•è§£æLLMå“åº”ä¸ºJSON")
        raise ValueError("æ— æ³•è§£æLLMå“åº”ä¸ºJSON")

    plan_str = plan_json.get("overview", "")

    logger.info(f"ä¸€å¥è¯ç ”ç©¶è®¡åˆ’ï¼š{plan_str}")

    publish_event(state.get("job_id", ""), "ä¸€å¥è¯ç ”ç©¶è®¡åˆ’", "document_generation",
                  "SUCCESS", {"description": plan_str})

    chapter_word_counts = plan_json.get("chapter_word_counts", [])
    if len(chapter_word_counts) != len(chapters_to_process):
        logger.error(
            f"ç« èŠ‚å­—æ•°åˆ†é…ä¸ä¸€è‡´ï¼Œç« èŠ‚æ•°ä¸ä¸€è‡´, {len(chapter_word_counts)} != {len(chapters_to_process)}"
        )
        # é»˜è®¤åˆ†é…80%çš„å­—æ•°ï¼Œå› ä¸ºæ€»å­—æ•°ä¸€èˆ¬éƒ½è¶…
        chapter_word_counts = [{
            "title":
            chapter["chapter_title"],
            "word_count":
            int(state.get("word_count", 0) / len(chapters_to_process) * 0.8)
        } for chapter in chapters_to_process]
    else:
        for (word_count, chapter) in zip(chapter_word_counts,
                                         chapters_to_process):
            chapter["chapter_word_count"] = word_count.get("word_count", 0)

    logger.info(f"âœ… ç« èŠ‚æ‹†åˆ†å®Œæˆï¼Œå…± {len(chapters_to_process)} ä¸ªç« èŠ‚")
    publish_event(
        state.get("job_id", ""), "å¤§çº²è§£æ", "document_generation", "SUCCESS", {
            "chapters": chapters_to_process,
            "description": f"å¤§çº²è§£æå®Œæˆï¼Œå…±éœ€ç¼–å†™{len(chapters_to_process)}ä¸ªç« èŠ‚"
        })

    for i, chapter in enumerate(chapters_to_process):
        logger.info(
            f"  ğŸ“– ç¬¬{i+1}ç« : {chapter['chapter_title']} ({len(chapter['sub_sections'])} å­èŠ‚)"
        )

    return {
        "chapters_to_process": chapters_to_process,
        "current_chapter_index": 0,
        "completed_chapters": [],
        "user_data_reference_files": state.get("user_data_reference_files",
                                               []),
        "user_style_guide_content": state.get("user_style_guide_content", []),
        "user_requirements_content": state.get("user_requirements_content",
                                               []),
        "is_online": state.get("is_online", True),
        "is_es_search": state.get("is_es_search", True),
        "ai_demo": state.get("ai_demo", False)
    }


def bibliography_node(state: ResearchState) -> dict:
    """
    å‚è€ƒæ–‡çŒ®ç”ŸæˆèŠ‚ç‚¹
    æ ¹æ®å…¨å±€å¼•ç”¨æºç”Ÿæˆå‚è€ƒæ–‡çŒ®åˆ—è¡¨
    """
    cited_sources = state.get("cited_sources", [])  # ğŸ”§ ä¿®å¤ï¼šæ”¹ä¸ºåˆ—è¡¨è€Œä¸æ˜¯å­—å…¸

    logger.info(f"ğŸ“š å¼€å§‹ç”Ÿæˆå‚è€ƒæ–‡çŒ®ï¼Œå…± {len(cited_sources)} ä¸ªå¼•ç”¨æº")

    # ä½¿ç”¨æ–°çš„ Source ç±»æ–¹æ³•è¿›è¡Œæ‰¹é‡è½¬æ¢
    answer_origins, webs = Source.batch_to_redis_fe(cited_sources)

    publish_event(
        state.get("job_id", ""), "å‚è€ƒæ–‡çŒ®ç”Ÿæˆ", "document_generation", "RUNNING", {
            "answerOrigins": answer_origins,
            "webs": webs,
            "description": f"å¼€å§‹ç”Ÿæˆå‚è€ƒæ–‡çŒ®ï¼Œå…± {len(cited_sources)} ä¸ªå¼•ç”¨æº"
        })

    if not cited_sources:
        logger.warning("æ²¡æœ‰å¼•ç”¨æºï¼Œç”Ÿæˆç©ºçš„å‚è€ƒæ–‡çŒ®")
        bibliography = "\n## å‚è€ƒæ–‡çŒ®\n\næš‚æ— å‚è€ƒæ–‡çŒ®ã€‚\n"
    else:
        # ç”Ÿæˆå‚è€ƒæ–‡çŒ®
        bibliography_lines = ["\n## å‚è€ƒæ–‡çŒ®\n"]

        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ source.id ä½œä¸ºå¼•ç”¨ç¼–å·ï¼Œä¿æŒä¸æ–‡æ¡£å†…å®¹ä¸€è‡´
        for source in cited_sources:
            citation = _format_citation(source.id, source)
            bibliography_lines.append(citation)

        bibliography = "\n".join(bibliography_lines)

        logger.info(f"âœ… å‚è€ƒæ–‡çŒ®ç”Ÿæˆå®Œæˆï¼ŒåŒ…å« {len(cited_sources)} æ¡å¼•ç”¨")

    # è·å–ç°æœ‰çš„ final_document
    final_document = state.get("final_document", "")

    # æ£€æŸ¥ completed_chapters çŠ¶æ€
    completed_chapters = state.get("completed_chapters", [])
    logger.info(f"ğŸ“Š completed_chapters æ•°é‡: {len(completed_chapters)}")

    for i, chapter in enumerate(completed_chapters):
        if isinstance(chapter, dict):
            content = chapter.get("content", "")
            title = chapter.get("title", f"ç¬¬{i+1}ç« ")
            logger.info(f"ğŸ“– ç¬¬{i+1}ç«  '{title}' å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
            if len(content) < 50:
                logger.warning(f"âš ï¸ ç¬¬{i+1}ç« å†…å®¹è¿‡çŸ­: {content[:100]}...")
        else:
            logger.warning(f"âš ï¸ ç¬¬{i+1}ç« æ ¼å¼å¼‚å¸¸: {type(chapter)}")

    # æ£€æŸ¥ cited_sources çŠ¶æ€
    cited_sources = state.get("cited_sources", [])
    logger.info(f"ğŸ“š bibliography_node: cited_sources æ•°é‡: {len(cited_sources)}")

    if cited_sources:
        for i, source in enumerate(cited_sources[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
            logger.info(
                f"ğŸ“š å¼•ç”¨æº {i+1}: {getattr(source, 'title', 'æ— æ ‡é¢˜')} (ID: {getattr(source, 'id', 'æ— ID')})"
            )
        if len(cited_sources) > 5:
            logger.info(f"ğŸ“š ... è¿˜æœ‰ {len(cited_sources) - 5} ä¸ªå¼•ç”¨æº")
    else:
        logger.warning("âš ï¸ bibliography_node: cited_sources ä¸ºç©ºï¼")

    # æ£€æŸ¥ final_document æ˜¯å¦ä¸ºç©ºæˆ–å†…å®¹ä¸å®Œæ•´
    if not final_document or len(final_document.strip()) < 100:
        logger.warning(
            f"âš ï¸ final_document å†…å®¹å¯èƒ½ä¸å®Œæ•´ï¼Œé•¿åº¦: {len(final_document)} å­—ç¬¦")
        logger.warning(f"final_document å‰100å­—ç¬¦: {final_document[:100]}")
    else:
        logger.info(f"âœ… final_document å†…å®¹å®Œæ•´ï¼Œé•¿åº¦: {len(final_document)} å­—ç¬¦")

    # å°†å‚è€ƒæ–‡çŒ®æ·»åŠ åˆ°æœ€ç»ˆæ–‡æ¡£ä¸­
    updated_final_document = final_document + bibliography

    logger.info(f"ğŸ“š å·²å°†å‚è€ƒæ–‡çŒ®æ·»åŠ åˆ°æœ€ç»ˆæ–‡æ¡£ä¸­ï¼Œæ€»é•¿åº¦: {len(updated_final_document)} å­—ç¬¦")

    # æ£€æŸ¥ updated_final_document çš„å†…å®¹
    if len(updated_final_document) < 200:
        logger.error(
            f"âŒ updated_final_document å†…å®¹è¿‡çŸ­ï¼Œå¯èƒ½æœ‰é—®é¢˜ï¼Œé•¿åº¦: {len(updated_final_document)} å­—ç¬¦"
        )
        logger.error(f"updated_final_document å†…å®¹: {updated_final_document}")
    else:
        logger.info(
            f"âœ… updated_final_document å†…å®¹æ­£å¸¸ï¼Œé•¿åº¦: {len(updated_final_document)} å­—ç¬¦"
        )
        # æ˜¾ç¤ºæ–‡æ¡£çš„å‰200å­—ç¬¦å’Œå200å­—ç¬¦ç”¨äºè°ƒè¯•
        logger.info(f"æ–‡æ¡£å¼€å¤´: {updated_final_document[:200]}...")
        logger.info(f"æ–‡æ¡£ç»“å°¾: ...{updated_final_document[-200:]}")

    # ä¿å­˜æ–‡æ¡£åˆ°æ ¹ç›®å½•çš„ test.md æ–‡ä»¶
    try:
        import os

        # è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆservice ç›®å½•çš„ä¸Šçº§ç›®å½•ï¼‰
        current_dir = os.getcwd()
        if current_dir.endswith('service'):
            # å¦‚æœåœ¨ service ç›®å½•ä¸­ï¼Œå›åˆ°ä¸Šçº§ç›®å½•
            root_dir = os.path.dirname(current_dir)
        else:
            # å¦‚æœå·²ç»åœ¨æ ¹ç›®å½•ï¼Œç›´æ¥ä½¿ç”¨
            root_dir = current_dir

        # ä¿å­˜åˆ°æ ¹ç›®å½•çš„ test.md
        test_md_path = os.path.join(root_dir, "test.md")

        # ä¿å­˜æ–‡æ¡£
        with open(test_md_path, "w", encoding="utf-8") as f:
            f.write(updated_final_document)

        logger.info(f"ğŸ’¾ æ–‡æ¡£å·²ä¿å­˜åˆ°æ ¹ç›®å½•: {test_md_path}")
        logger.info(f"ğŸ“„ æ–‡ä»¶å¤§å°: {len(updated_final_document)} å­—ç¬¦")

    except Exception as e:
        logger.error(f"ä¿å­˜æ–‡æ¡£åˆ° test.md å¤±è´¥: {e}")
        # å°è¯•ä¿å­˜åˆ°å½“å‰ç›®å½•ä½œä¸ºå¤‡ç”¨
        try:
            with open("test.md", "w", encoding="utf-8") as f:
                f.write(updated_final_document)
            logger.info(f"ğŸ’¾ å¤‡ç”¨ä¿å­˜æˆåŠŸ: test.md")
        except Exception as e2:
            logger.error(f"å¤‡ç”¨ä¿å­˜ä¹Ÿå¤±è´¥: {e2}")

    # è¿”å›æ›´æ–°åçš„ final_document
    return {"final_document": updated_final_document}


def _get_outline_prompt_template(complexity_config, prompt_selector, genre):
    """è·å–å¤§çº²ç”Ÿæˆçš„æç¤ºè¯æ¨¡æ¿"""
    try:
        if complexity_config['use_simplified_prompts']:
            # å¿«é€Ÿæ¨¡å¼ä½¿ç”¨ç®€åŒ–æç¤ºè¯ - ç°åœ¨ä»promptsæ¨¡å—è·å–
            from doc_agent.prompts.outline_generation import V4_FAST
            return V4_FAST

        # æ ‡å‡†æ¨¡å¼ä½¿ç”¨å®Œæ•´æç¤ºè¯
        if prompt_selector:
            # ä¼˜å…ˆä½¿ç”¨ä¸‰çº§å¤§çº²ç»“æ„ç‰ˆæœ¬
            try:
                return prompt_selector.get_prompt("main_orchestrator",
                                                  "outline",
                                                  "v3_with_subsections")
            except Exception:
                # å¦‚æœä¸‰çº§ç‰ˆæœ¬ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤ç‰ˆæœ¬
                return prompt_selector.get_prompt("main_orchestrator",
                                                  "outline", genre)

    except Exception as e:
        logger.error("è·å–æç¤ºè¯æ¨¡æ¿å¤±è´¥: {}", e)

    # å¤‡ç”¨æ¨¡æ¿ - ä½¿ç”¨ä¸‰çº§å¤§çº²ç»“æ„
    return """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡æ¡£ç»“æ„è®¾è®¡ä¸“å®¶ã€‚åŸºäºæä¾›çš„åˆå§‹ç ”ç©¶æ•°æ®ï¼Œä¸ºä¸»é¢˜ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„æ–‡æ¡£å¤§çº²ã€‚

**æ–‡æ¡£ä¸»é¢˜:** {topic}

**ç ”ç©¶æ•°æ®æ‘˜è¦:**
{initial_gathered_data}

**ä»»åŠ¡è¦æ±‚:**
1. åˆ†æç ”ç©¶æ•°æ®ï¼Œè¯†åˆ«ä¸»è¦ä¸»é¢˜
2. åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„æ–‡æ¡£ç»“æ„
3. æ¯ä¸ªç« èŠ‚åº”è¯¥æœ‰æ˜ç¡®çš„ç„¦ç‚¹
4. ç¡®ä¿è¦†ç›–ä¸»é¢˜çš„æ ¸å¿ƒè¦ç‚¹
5. **å¿…é¡»ç”Ÿæˆä¸‰çº§å¤§çº²ç»“æ„**ï¼šç« èŠ‚ -> å­èŠ‚ -> è¦ç‚¹

**è¾“å‡ºæ ¼å¼è¦æ±‚:**
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–å†…å®¹ï¼š

{{
    "title": "æ–‡æ¡£æ ‡é¢˜",
    "summary": "æ–‡æ¡£çš„ç®€çŸ­æ‘˜è¦ï¼ˆ50-100å­—ï¼‰",
    "chapters": [
        {{
            "chapter_number": 1,
            "chapter_title": "ç¬¬ä¸€ç« æ ‡é¢˜",
            "description": "æœ¬ç« çš„ç®€è¦æè¿°",
            "sub_sections": [
                {{
                    "section_number": 1.1,
                    "section_title": "ç¬¬ä¸€èŠ‚æ ‡é¢˜",
                    "section_description": "æœ¬èŠ‚çš„ç®€è¦æè¿°",
                    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
                }},
                {{
                    "section_number": 1.2,
                    "section_title": "ç¬¬äºŒèŠ‚æ ‡é¢˜",
                    "section_description": "æœ¬èŠ‚çš„ç®€è¦æè¿°",
                    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
                }},
                {{
                    "section_number": 1.3,
                    "section_title": "ç¬¬ä¸‰èŠ‚æ ‡é¢˜",
                    "section_description": "æœ¬èŠ‚çš„ç®€è¦æè¿°",
                    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
                }}
            ]
        }},
        {{
            "chapter_number": 2,
            "chapter_title": "ç¬¬äºŒç« æ ‡é¢˜",
            "description": "æœ¬ç« çš„ç®€è¦æè¿°",
            "sub_sections": [
                {{
                    "section_number": 2.1,
                    "section_title": "ç¬¬ä¸€èŠ‚æ ‡é¢˜",
                    "section_description": "æœ¬èŠ‚çš„ç®€è¦æè¿°",
                    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
                }},
                {{
                    "section_number": 2.2,
                    "section_title": "ç¬¬äºŒèŠ‚æ ‡é¢˜",
                    "section_description": "æœ¬èŠ‚çš„ç®€è¦æè¿°",
                    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
                }},
                {{
                    "section_number": 2.3,
                    "section_title": "ç¬¬ä¸‰èŠ‚æ ‡é¢˜",
                    "section_description": "æœ¬èŠ‚çš„ç®€è¦æè¿°",
                    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
                }}
            ]
        }},
        {{
            "chapter_number": 3,
            "chapter_title": "ç¬¬ä¸‰ç« æ ‡é¢˜",
            "description": "æœ¬ç« çš„ç®€è¦æè¿°",
            "sub_sections": [
                {{
                    "section_number": 3.1,
                    "section_title": "ç¬¬ä¸€èŠ‚æ ‡é¢˜",
                    "section_description": "æœ¬èŠ‚çš„ç®€è¦æè¿°",
                    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
                }},
                {{
                    "section_number": 3.2,
                    "section_title": "ç¬¬äºŒèŠ‚æ ‡é¢˜",
                    "section_description": "æœ¬èŠ‚çš„ç®€è¦æè¿°",
                    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
                }},
                {{
                    "section_number": 3.3,
                    "section_title": "ç¬¬ä¸‰èŠ‚æ ‡é¢˜",
                    "section_description": "æœ¬èŠ‚çš„ç®€è¦æè¿°",
                    "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
                }}
            ]
        }}
    ],
    "total_chapters": 3,
    "estimated_total_words": 5000
}}

**é‡è¦æç¤º:**
- **å¿…é¡»ç”Ÿæˆæ°å¥½3ä¸ªç« èŠ‚**
- **æ¯ä¸ªç« èŠ‚å¿…é¡»åŒ…å«3ä¸ªå­èŠ‚**
- **æ¯ä¸ªå­èŠ‚å¿…é¡»åŒ…å«3ä¸ªè¦ç‚¹**
- è¦ç”Ÿæˆå®Œæ•´çš„ä¸‰çº§å¤§çº²ç»“æ„
- ç« èŠ‚æ ‡é¢˜åº”è¯¥ç®€æ´æ˜äº†
- æè¿°åº”è¯¥ç®€çŸ­ä½†æ¸…æ™°
- å¿…é¡»è¾“å‡ºæœ‰æ•ˆçš„JSONæ ¼å¼
- ç›®æ ‡æ€»å­—æ•°æ§åˆ¶åœ¨5000å­—å·¦å³
"""


def _parse_outline_response(response: str, complexity_config) -> dict:
    """è§£æå¤§çº²ç”Ÿæˆå“åº”"""
    # æ¸…é™¤æ”¶å°¾çš„ ```json å’Œ ```
    response = response.replace('```json', '').replace('```', '').strip()

    try:
        # å°è¯•è§£æJSON
        import re
        json_match = re.search(r'\{.*\}', response, re.DOTALL)
        if json_match:
            outline = json.loads(json_match.group(0))

            # éªŒè¯å’Œä¿®å¤å¤§çº²ç»“æ„
            # outline = _validate_and_fix_outline_structure(
            #     outline, complexity_config)

            # æ ¹æ®å¤æ‚åº¦é™åˆ¶ç« èŠ‚æ•°é‡
            # max_chapters = complexity_config.get('max_chapters', -1)
            # if max_chapters > 0 and 'chapters' in outline:
            #     outline['chapters'] = outline['chapters'][:max_chapters]

            return outline
    except Exception as e:
        logger.error(f"è§£æå¤§çº²å“åº”å¤±è´¥: {e}")

    # è¿”å›é»˜è®¤å¤§çº²
    return _generate_default_outline("æœªçŸ¥ä¸»é¢˜", complexity_config)


def _validate_and_fix_outline_structure(outline: dict,
                                        complexity_config: dict) -> dict:
    """éªŒè¯å’Œä¿®å¤å¤§çº²ç»“æ„ï¼Œç¡®ä¿ä¸‰çº§ç»“æ„å®Œæ•´ï¼Œæ”¯æŒæ–°æ—§æ ¼å¼"""

    if 'chapters' not in outline:
        logger.warning("å¤§çº²ç¼ºå°‘chapterså­—æ®µï¼Œä½¿ç”¨é»˜è®¤å¤§çº²")
        return _generate_default_outline("æœªçŸ¥ä¸»é¢˜", complexity_config)

    chapters = outline['chapters']
    fixed_chapters = []

    for i, chapter in enumerate(chapters):
        # å…¼å®¹æ–°æ—§æ ¼å¼ï¼šchapter_title -> title
        if 'title' not in chapter and 'chapter_title' in chapter:
            chapter['title'] = chapter['chapter_title']
        elif 'title' not in chapter:
            chapter['title'] = f"ç¬¬{i+1}ç« "

        # å…¼å®¹æ–°æ—§æ ¼å¼ï¼šchapter_number -> number
        if 'number' not in chapter and 'chapter_number' in chapter:
            chapter['number'] = chapter['chapter_number']
        elif 'number' not in chapter:
            chapter['number'] = i + 1

        if 'description' not in chapter:
            chapter['description'] = f"ç¬¬{i+1}ç« çš„å†…å®¹æè¿°"

        # å…¼å®¹æ–°æ—§æ ¼å¼ï¼šsections -> sub_sections
        sections_key = 'sections' if 'sections' in chapter else 'sub_sections'
        if sections_key not in chapter or not chapter[sections_key]:
            logger.info(f"ç« èŠ‚ {chapter['title']} ç¼ºå°‘å­èŠ‚ï¼Œæ·»åŠ é»˜è®¤å­èŠ‚")
            chapter[sections_key] = [{
                "number": float(f"{i+1}.1"),
                "title": f"{chapter['title']}æ¦‚è¿°",
                "description": f"{chapter['title']}çš„åŸºæœ¬æ¦‚è¿°",
                "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
            }, {
                "number": float(f"{i+1}.2"),
                "title": f"{chapter['title']}åˆ†æ",
                "description": f"{chapter['title']}çš„æ·±å…¥åˆ†æ",
                "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
            }, {
                "number": float(f"{i+1}.3"),
                "title": f"{chapter['title']}æ€»ç»“",
                "description": f"{chapter['title']}çš„æ€»ç»“å’Œå±•æœ›",
                "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
            }]
        else:
            # éªŒè¯å­èŠ‚ç»“æ„ï¼Œå…¼å®¹æ–°æ—§æ ¼å¼
            for j, section in enumerate(chapter[sections_key]):
                # å…¼å®¹æ–°æ—§æ ¼å¼ï¼šsection_title -> title
                if 'title' not in section and 'section_title' in section:
                    section['title'] = section['section_title']
                elif 'title' not in section:
                    section['title'] = f"ç¬¬{i+1}.{j+1}èŠ‚"

                # å…¼å®¹æ–°æ—§æ ¼å¼ï¼šsection_description -> description
                if 'description' not in section and 'section_description' in section:
                    section['description'] = section['section_description']
                elif 'description' not in section:
                    section['description'] = f"ç¬¬{i+1}.{j+1}èŠ‚çš„æè¿°"

                # å…¼å®¹æ–°æ—§æ ¼å¼ï¼šsection_number -> number
                if 'number' not in section and 'section_number' in section:
                    section['number'] = section['section_number']
                elif 'number' not in section:
                    section['number'] = float(f"{i+1}.{j+1}")

                if 'key_points' not in section or not section['key_points']:
                    section['key_points'] = ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]

        # ç»Ÿä¸€ä½¿ç”¨æ–°æ ¼å¼
        if 'sections' not in chapter and sections_key in chapter:
            chapter['sections'] = chapter[sections_key]
            del chapter[sections_key]

        fixed_chapters.append(chapter)

    # ç¡®ä¿è‡³å°‘æœ‰3ä¸ªç« èŠ‚
    while len(fixed_chapters) < 3:
        chapter_num = len(fixed_chapters) + 1
        fixed_chapters.append({
            "number":
            chapter_num,
            "title":
            f"ç¬¬{chapter_num}ç« ",
            "description":
            f"ç¬¬{chapter_num}ç« çš„å†…å®¹æè¿°",
            "sections": [{
                "number": float(f"{chapter_num}.1"),
                "title": f"ç¬¬{chapter_num}ç« æ¦‚è¿°",
                "description": f"ç¬¬{chapter_num}ç« çš„åŸºæœ¬æ¦‚è¿°",
                "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
            }, {
                "number": float(f"{chapter_num}.2"),
                "title": f"ç¬¬{chapter_num}ç« åˆ†æ",
                "description": f"ç¬¬{chapter_num}ç« çš„æ·±å…¥åˆ†æ",
                "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
            }, {
                "number": float(f"{chapter_num}.3"),
                "title": f"ç¬¬{chapter_num}ç« æ€»ç»“",
                "description": f"ç¬¬{chapter_num}ç« çš„æ€»ç»“å’Œå±•æœ›",
                "key_points": ["è¦ç‚¹1", "è¦ç‚¹2", "è¦ç‚¹3"]
            }]
        })

    outline['chapters'] = fixed_chapters
    logger.info(f"âœ… å¤§çº²ç»“æ„éªŒè¯å®Œæˆï¼Œ åŒ…å« {len(fixed_chapters)} ä¸ªç« èŠ‚ï¼Œæ¯ä¸ªç« èŠ‚åŒ…å«å­èŠ‚")

    return outline


def _generate_default_outline(topic: str, complexity_config) -> dict:
    """ç”Ÿæˆé»˜è®¤å¤§çº²"""
    max_chapters = complexity_config.get('max_chapters', 3)
    if max_chapters <= 0:
        max_chapters = 3

    # æ ¹æ®ä¸»é¢˜ç”Ÿæˆé€šç”¨å¤§çº²
    chapters = []
    for i in range(min(max_chapters, 3)):
        chapters.append({
            "number":
            i + 1,
            "title":
            f"{topic} - ç¬¬{i + 1}éƒ¨åˆ†",
            "description":
            f"å…³äº{topic}çš„ç¬¬{i + 1}éƒ¨åˆ†å†…å®¹",
            "sections": [{
                "number":
                float(f"{i+1}.1"),
                "title":
                f"ç¬¬{i+1}éƒ¨åˆ†æ¦‚è¿°",
                "description":
                f"ç¬¬{i+1}éƒ¨åˆ†çš„åŸºæœ¬æ¦‚è¿°",
                "key_points":
                [f"{topic}æ¦‚è¿°è¦ç‚¹1", f"{topic}æ¦‚è¿°è¦ç‚¹2", f"{topic}æ¦‚è¿°è¦ç‚¹3"]
            }, {
                "number":
                float(f"{i+1}.2"),
                "title":
                f"ç¬¬{i+1}éƒ¨åˆ†åˆ†æ",
                "description":
                f"ç¬¬{i+1}éƒ¨åˆ†çš„æ·±å…¥åˆ†æ",
                "key_points":
                [f"{topic}åˆ†æè¦ç‚¹1", f"{topic}åˆ†æè¦ç‚¹2", f"{topic}åˆ†æè¦ç‚¹3"]
            }, {
                "number":
                float(f"{i+1}.3"),
                "title":
                f"ç¬¬{i+1}éƒ¨åˆ†æ€»ç»“",
                "description":
                f"ç¬¬{i+1}éƒ¨åˆ†çš„æ€»ç»“å’Œå±•æœ›",
                "key_points":
                [f"{topic}æ€»ç»“è¦ç‚¹1", f"{topic}æ€»ç»“è¦ç‚¹2", f"{topic}æ€»ç»“è¦ç‚¹3"]
            }]
        })

    return {
        "title": f"{topic} ç ”ç©¶æŠ¥å‘Š",
        "summary": f"æœ¬æ–‡æ¡£æ·±å…¥æ¢è®¨äº†{topic}çš„ç›¸å…³å†…å®¹ï¼ŒåŒ…æ‹¬é—®é¢˜åˆ†æå’Œè§£å†³æ–¹æ¡ˆã€‚",
        "chapters": chapters[:max_chapters]  # ç¡®ä¿ä¸è¶…è¿‡æœ€å¤§ç« èŠ‚æ•°
    }


def _format_citation(source_id: int, source: Source) -> str:
    """æ ¼å¼åŒ–å•ä¸ªå¼•ç”¨"""
    citation = f"[{source_id}] {source.title}"

    # æ·»åŠ ä½œè€…ä¿¡æ¯
    if source.author:
        citation += f", {source.author}"

    # æ·»åŠ æ—¥æœŸä¿¡æ¯
    if source.date:
        citation += f", {source.date}"

    # æ·»åŠ URLä¿¡æ¯
    if source.url:
        citation += f" - {source.url}"

    # æ·»åŠ é¡µç ä¿¡æ¯
    if source.page_number is not None:
        citation += f" (ç¬¬{source.page_number}é¡µ)"

    citation += f" ({source.source_type})"

    return citation