#!/usr/bin/env python3
"""
ç½‘ç»œæœç´¢æœåŠ¡ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•åœ¨AIæ–‡æ¡£ç”Ÿæˆç³»ç»Ÿä¸­ä½¿ç”¨ç½‘ç»œæœç´¢åŠŸèƒ½
"""

import asyncio
import sys
from typing import List, Dict, Any

from loguru import logger

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append("../src")

from doc_agent.tools.web_search import WebSearchTool


async def example_basic_search():
    """åŸºæœ¬æœç´¢ç¤ºä¾‹"""
    logger.info("=== åŸºæœ¬æœç´¢ç¤ºä¾‹ ===")
    
    # åˆ›å»ºç½‘ç»œæœç´¢å·¥å…·å®ä¾‹
    web_search = WebSearchTool()
    
    # æ‰§è¡Œæœç´¢
    query = "æ°´ç”µç«™å»ºé€ è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„é—®é¢˜"
    logger.info(f"æœç´¢æŸ¥è¯¢: {query}")
    
    try:
        # è·å–æœç´¢ç»“æœ
        docs = await web_search.get_web_docs(query)
        
        if docs:
            logger.info(f"æ‰¾åˆ° {len(docs)} ä¸ªç›¸å…³æ–‡æ¡£")
            
            # æ˜¾ç¤ºæœç´¢ç»“æœ
            for i, doc in enumerate(docs[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                logger.info(f"\næ–‡æ¡£ {i+1}:")
                logger.info(f"  æ ‡é¢˜: {doc.get('meta_data', {}).get('docName', 'Unknown')}")
                logger.info(f"  URL: {doc.get('url', 'N/A')}")
                logger.info(f"  å†…å®¹é•¿åº¦: {len(doc.get('text', ''))} å­—ç¬¦")
                
                # æ˜¾ç¤ºå†…å®¹æ‘˜è¦
                content = doc.get('text', '')
                summary = content[:300] + "..." if len(content) > 300 else content
                logger.info(f"  å†…å®¹æ‘˜è¦: {summary}")
        else:
            logger.warning("æœªæ‰¾åˆ°ç›¸å…³æ–‡æ¡£")
            
    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")


async def example_async_search():
    """å¼‚æ­¥æœç´¢ç¤ºä¾‹"""
    logger.info("=== å¼‚æ­¥æœç´¢ç¤ºä¾‹ ===")
    
    web_search = WebSearchTool()
    
    # å¤šä¸ªæŸ¥è¯¢
    queries = [
        "æ°´ç”µç«™æ–½å·¥å®‰å…¨",
        "æ°´åˆ©å·¥ç¨‹è´¨é‡æ§åˆ¶",
        "æ°´è½®æœºç»´æŠ¤ä¿å…»"
    ]
    
    for query in queries:
        logger.info(f"\næœç´¢: {query}")
        try:
            result = await web_search.search_async(query)
            logger.info(f"æœç´¢ç»“æœ: {len(result)} ä¸ªæ–‡æ¡£")
        except Exception as e:
            logger.error(f"æœç´¢å¤±è´¥: {e}")


async def example_integration_with_doc_generation():
    """ä¸æ–‡æ¡£ç”Ÿæˆç³»ç»Ÿé›†æˆçš„ç¤ºä¾‹"""
    logger.info("=== æ–‡æ¡£ç”Ÿæˆé›†æˆç¤ºä¾‹ ===")
    
    web_search = WebSearchTool()
    
    # æ¨¡æ‹Ÿæ–‡æ¡£ç”Ÿæˆæµç¨‹
    topic = "æ°´ç”µç«™å»ºé€ è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ"
    
    logger.info(f"å¼€å§‹ç”Ÿæˆæ–‡æ¡£: {topic}")
    
    # 1. æ”¶é›†ç›¸å…³ä¿¡æ¯
    logger.info("1. æ”¶é›†ç›¸å…³ä¿¡æ¯...")
    search_queries = [
        "æ°´ç”µç«™å»ºé€ é—®é¢˜",
        "æ°´åˆ©å·¥ç¨‹æ–½å·¥éš¾ç‚¹",
        "æ°´ç”µç«™è´¨é‡æ§åˆ¶",
        "æ°´ç”µç«™å®‰å…¨æ–½å·¥"
    ]
    
    all_docs = []
    for query in search_queries:
        try:
            docs = await web_search.get_web_docs(query)
            all_docs.extend(docs)
            logger.info(f"  ä» '{query}' æ”¶é›†åˆ° {len(docs)} ä¸ªæ–‡æ¡£")
        except Exception as e:
            logger.error(f"  æœç´¢ '{query}' å¤±è´¥: {e}")
    
    # 2. åˆ†ææ”¶é›†åˆ°çš„ä¿¡æ¯
    logger.info(f"2. åˆ†ææ”¶é›†åˆ°çš„ä¿¡æ¯...")
    logger.info(f"   æ€»å…±æ”¶é›†åˆ° {len(all_docs)} ä¸ªæ–‡æ¡£")
    
    # 3. æå–å…³é”®ä¿¡æ¯
    logger.info("3. æå–å…³é”®ä¿¡æ¯...")
    key_topics = set()
    for doc in all_docs:
        content = doc.get('text', '')
        # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„NLPæŠ€æœ¯ï¼‰
        if 'é—®é¢˜' in content or 'å›°éš¾' in content or 'é£é™©' in content:
            key_topics.add('æ–½å·¥é—®é¢˜')
        if 'å®‰å…¨' in content or 'é˜²æŠ¤' in content:
            key_topics.add('å®‰å…¨æªæ–½')
        if 'è´¨é‡' in content or 'æ ‡å‡†' in content:
            key_topics.add('è´¨é‡æ§åˆ¶')
    
    logger.info(f"   è¯†åˆ«åˆ°å…³é”®ä¸»é¢˜: {list(key_topics)}")
    
    # 4. ç”Ÿæˆæ–‡æ¡£å¤§çº²
    logger.info("4. ç”Ÿæˆæ–‡æ¡£å¤§çº²...")
    outline = [
        "æ°´ç”µç«™å»ºé€ è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ",
        "  1. æ–½å·¥å‡†å¤‡é˜¶æ®µçš„é—®é¢˜",
        "  2. æ–½å·¥è¿‡ç¨‹ä¸­çš„æŠ€æœ¯éš¾ç‚¹",
        "  3. è´¨é‡æ§åˆ¶ä¸å®‰å…¨ç®¡ç†",
        "  4. å¸¸è§é—®é¢˜çš„è§£å†³æ–¹æ¡ˆ"
    ]
    
    for item in outline:
        logger.info(f"   {item}")
    
    logger.info("æ–‡æ¡£ç”Ÿæˆæµç¨‹å®Œæˆï¼")


async def main():
    """ä¸»å‡½æ•°"""
    logger.info("ğŸš€ ç½‘ç»œæœç´¢æœåŠ¡ä½¿ç”¨ç¤ºä¾‹")
    logger.info("=" * 60)
    
    # è®¾ç½®æ—¥å¿—
    logger.add("logs/web_search_example.log", 
              rotation="1 day", 
              retention="7 days",
              level="INFO")
    
    try:
        # è¿è¡Œç¤ºä¾‹
        await example_basic_search()
        await example_async_search()
        await example_integration_with_doc_generation()
        
        logger.info("\nâœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        
    except Exception as e:
        logger.error(f"ç¤ºä¾‹è¿è¡Œå¤±è´¥: {e}")


if __name__ == "__main__":
    asyncio.run(main()) 