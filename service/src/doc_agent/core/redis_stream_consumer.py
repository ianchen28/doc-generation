"""
Redis Streams æ¶ˆè´¹è€…ç»„å®ç°

æ”¯æŒå¤šæ¶ˆè´¹è€…è´Ÿè½½å‡è¡¡ã€æ•…éšœæ¢å¤å’Œæ¶ˆæ¯ç¡®è®¤æœºåˆ¶ã€‚
"""

import asyncio
import json
from typing import Any, Callable, Union

import redis.asyncio as redis
from doc_agent.core.logger import logger


class RedisStreamConsumer:
    """
    Redis Streams æ¶ˆè´¹è€…
    
    æ”¯æŒæ¶ˆè´¹è€…ç»„æ¨¡å¼ï¼Œæä¾›è´Ÿè½½å‡è¡¡å’Œæ•…éšœæ¢å¤åŠŸèƒ½ã€‚
    """

    def __init__(self, redis_url: str, group_name: str, consumer_name: str):
        """
        åˆå§‹åŒ–æ¶ˆè´¹è€…
        
        Args:
            redis_url: Redis è¿æ¥ URL
            group_name: æ¶ˆè´¹è€…ç»„åç§°
            consumer_name: æ¶ˆè´¹è€…åç§°ï¼ˆåœ¨ç»„å†…å”¯ä¸€ï¼‰
        """
        self.redis_url = redis_url
        self.group_name = group_name
        self.consumer_name = consumer_name
        self.redis_client = None
        self.is_running = False
        self.handlers: dict[str, Callable] = {}

    async def connect(self):
        """è¿æ¥åˆ° Redis"""
        try:
            self.redis_client = redis.from_url(self.redis_url,
                                               encoding="utf-8",
                                               decode_responses=True)
            await self.redis_client.ping()
            logger.info(f"âœ… Redis æ¶ˆè´¹è€…è¿æ¥æˆåŠŸ: {self.consumer_name}")
            return True
        except Exception as e:
            logger.error(f"âŒ Redis æ¶ˆè´¹è€…è¿æ¥å¤±è´¥: {e}")
            return False

    async def create_consumer_group(self,
                                    stream_name: str,
                                    start_id: str = "0"):
        """
        åˆ›å»ºæ¶ˆè´¹è€…ç»„
        
        Args:
            stream_name: Stream åç§°
            start_id: èµ·å§‹æ¶ˆæ¯ IDï¼Œé»˜è®¤ä¸º "0"ï¼ˆä»å¼€å§‹è¯»å–ï¼‰
        """
        try:
            # æ£€æŸ¥ Stream æ˜¯å¦å­˜åœ¨
            stream_exists = await self.redis_client.exists(stream_name)

            if not stream_exists:
                # å¦‚æœ Stream ä¸å­˜åœ¨ï¼Œå…ˆåˆ›å»ºä¸€ä¸ªç©ºæ¶ˆæ¯
                await self.redis_client.xadd(stream_name, {"init": "true"})
                logger.info(f"ğŸ“ åˆ›å»º Stream: {stream_name}")

            # åˆ›å»ºæ¶ˆè´¹è€…ç»„
            await self.redis_client.xgroup_create(stream_name,
                                                  self.group_name,
                                                  id=start_id,
                                                  mkstream=True)
            logger.info(f"âœ… æ¶ˆè´¹è€…ç»„åˆ›å»ºæˆåŠŸ: {self.group_name} -> {stream_name}")

        except Exception as e:
            if "BUSYGROUP" in str(e):
                logger.info(f"â„¹ï¸ æ¶ˆè´¹è€…ç»„å·²å­˜åœ¨: {self.group_name}")
            else:
                logger.error(f"âŒ åˆ›å»ºæ¶ˆè´¹è€…ç»„å¤±è´¥: {e}")
                raise

    async def register_handler(self, event_type: str, handler: Callable):
        """
        æ³¨å†Œäº‹ä»¶å¤„ç†å™¨
        
        Args:
            event_type: äº‹ä»¶ç±»å‹
            handler: å¤„ç†å‡½æ•°ï¼Œæ¥æ”¶ (job_id, event_data) å‚æ•°
        """
        self.handlers[event_type] = handler
        logger.info(f"ğŸ“ æ³¨å†Œäº‹ä»¶å¤„ç†å™¨: {event_type}")

    async def start_consuming(self, stream_name: str, block_ms: int = 5000):
        """
        å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯
        
        Args:
            stream_name: Stream åç§°
            block_ms: é˜»å¡ç­‰å¾…æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
        """
        if not self.redis_client:
            raise Exception("Redis å®¢æˆ·ç«¯æœªè¿æ¥")

        self.is_running = True
        logger.info(f"ğŸš€ å¼€å§‹æ¶ˆè´¹æ¶ˆæ¯: {self.consumer_name} -> {stream_name}")

        try:
            while self.is_running:
                try:
                    # ä»æ¶ˆè´¹è€…ç»„è¯»å–æ¶ˆæ¯
                    messages = await self.redis_client.xreadgroup(
                        self.group_name,
                        self.consumer_name, {stream_name: ">"},
                        count=10,
                        block=block_ms)

                    for stream, stream_messages in messages:
                        for message_id, fields in stream_messages:
                            await self._process_message(
                                stream, message_id, fields)

                except asyncio.CancelledError:
                    logger.info(f"ğŸ›‘ æ¶ˆè´¹è€…è¢«å–æ¶ˆ: {self.consumer_name}")
                    break
                except Exception as e:
                    logger.error(f"âŒ æ¶ˆè´¹æ¶ˆæ¯æ—¶å‡ºé”™: {e}")
                    await asyncio.sleep(1)  # çŸ­æš‚ç­‰å¾…åé‡è¯•

        finally:
            self.is_running = False
            logger.info(f"ğŸ”š æ¶ˆè´¹è€…åœæ­¢: {self.consumer_name}")

    async def _process_message(self, stream: str, message_id: str,
                               fields: dict[str, Any]):
        """
        å¤„ç†å•ä¸ªæ¶ˆæ¯
        
        Args:
            stream: Stream åç§°
            message_id: æ¶ˆæ¯ ID
            fields: æ¶ˆæ¯å­—æ®µ
        """
        try:
            # è§£æäº‹ä»¶æ•°æ®
            event_data = json.loads(fields.get("data", "{}"))
            # å…¼å®¹ä¸¤ç§äº‹ä»¶ç±»å‹é”®å
            event_type = event_data.get(
                "eventType", event_data.get("event_type", "unknown"))

            # ä» Stream åç§°æå– job_id - ç°åœ¨streamåç§°å°±æ˜¯job_id
            job_id = stream

            logger.debug(
                f"ğŸ“¨ æ”¶åˆ°æ¶ˆæ¯: {message_id} -> {event_type} (job_id: {job_id})")

            # è°ƒç”¨å¯¹åº”çš„å¤„ç†å™¨
            if event_type in self.handlers:
                await self.handlers[event_type](job_id, event_data)
            else:
                logger.warning(f"âš ï¸ æœªæ‰¾åˆ°äº‹ä»¶å¤„ç†å™¨: {event_type}")

            # ç¡®è®¤æ¶ˆæ¯å·²å¤„ç†
            await self.redis_client.xack(stream, self.group_name, message_id)
            logger.debug(f"âœ… æ¶ˆæ¯å·²ç¡®è®¤: {message_id}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç†æ¶ˆæ¯å¤±è´¥ {message_id}: {e}")
            # æ³¨æ„ï¼šè¿™é‡Œå¯ä»¥é€‰æ‹©æ˜¯å¦ç¡®è®¤æ¶ˆæ¯ï¼Œå–å†³äºé”™è¯¯ç±»å‹

    async def stop(self):
        """åœæ­¢æ¶ˆè´¹è€…"""
        self.is_running = False
        logger.info(f"ğŸ›‘ åœæ­¢æ¶ˆè´¹è€…: {self.consumer_name}")

    async def close(self):
        """å…³é—­è¿æ¥"""
        await self.stop()
        if self.redis_client:
            await self.redis_client.close()
            logger.info(f"ğŸ”Œ Redis æ¶ˆè´¹è€…è¿æ¥å·²å…³é—­: {self.consumer_name}")


class RedisStreamConsumerGroup:
    """
    Redis Streams æ¶ˆè´¹è€…ç»„ç®¡ç†å™¨
    
    ç®¡ç†å¤šä¸ªæ¶ˆè´¹è€…å®ä¾‹ï¼Œæä¾›è´Ÿè½½å‡è¡¡å’Œæ•…éšœæ¢å¤ã€‚
    """

    def __init__(self,
                 redis_url: str,
                 group_name: str,
                 consumer_count: int = 3):
        """
        åˆå§‹åŒ–æ¶ˆè´¹è€…ç»„ç®¡ç†å™¨
        
        Args:
            redis_url: Redis è¿æ¥ URL
            group_name: æ¶ˆè´¹è€…ç»„åç§°
            consumer_count: æ¶ˆè´¹è€…æ•°é‡
        """
        self.redis_url = redis_url
        self.group_name = group_name
        self.consumer_count = consumer_count
        self.consumers: dict[str, RedisStreamConsumer] = {}
        self.tasks: dict[str, asyncio.Task] = {}
        self.handlers: dict[str, Callable] = {}
        self.is_running = False

    async def start(self, stream_name: str):
        """
        å¯åŠ¨æ¶ˆè´¹è€…ç»„
        
        Args:
            stream_name: Stream åç§°
        """
        if self.is_running:
            logger.warning("âš ï¸ æ¶ˆè´¹è€…ç»„å·²åœ¨è¿è¡Œ")
            return

        self.is_running = True
        logger.info(
            f"ğŸš€ å¯åŠ¨æ¶ˆè´¹è€…ç»„: {self.group_name} (æ¶ˆè´¹è€…æ•°é‡: {self.consumer_count})")

        # åˆ›å»ºæ¶ˆè´¹è€…ç»„
        temp_consumer = RedisStreamConsumer(self.redis_url, self.group_name,
                                            "temp")
        await temp_consumer.connect()
        await temp_consumer.create_consumer_group(stream_name)
        await temp_consumer.close()

        # å¯åŠ¨å¤šä¸ªæ¶ˆè´¹è€…
        for i in range(self.consumer_count):
            consumer_name = f"{self.group_name}-consumer-{i+1}"
            consumer = RedisStreamConsumer(self.redis_url, self.group_name,
                                           consumer_name)

            # æ³¨å†Œå¤„ç†å™¨
            for event_type, handler in self.handlers.items():
                await consumer.register_handler(event_type, handler)

            # å¯åŠ¨æ¶ˆè´¹è€…
            await consumer.connect()
            task = asyncio.create_task(consumer.start_consuming(stream_name))

            self.consumers[consumer_name] = consumer
            self.tasks[consumer_name] = task

            logger.info(f"âœ… æ¶ˆè´¹è€…å¯åŠ¨: {consumer_name}")

    async def stop(self):
        """åœæ­¢æ¶ˆè´¹è€…ç»„"""
        if not self.is_running:
            return

        self.is_running = False
        logger.info(f"ğŸ›‘ åœæ­¢æ¶ˆè´¹è€…ç»„: {self.group_name}")

        # åœæ­¢æ‰€æœ‰æ¶ˆè´¹è€…
        for _consumer_name, consumer in self.consumers.items():
            await consumer.stop()

        # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        for task_name, task in self.tasks.items():
            try:
                await task
            except asyncio.CancelledError:
                pass
            logger.info(f"âœ… æ¶ˆè´¹è€…ä»»åŠ¡å®Œæˆ: {task_name}")

        # å…³é—­æ‰€æœ‰è¿æ¥
        for consumer in self.consumers.values():
            await consumer.close()

        self.consumers.clear()
        self.tasks.clear()

    def register_handler(self, event_type: str, handler: Callable):
        """
        æ³¨å†Œäº‹ä»¶å¤„ç†å™¨
        
        Args:
            event_type: äº‹ä»¶ç±»å‹
            handler: å¤„ç†å‡½æ•°
        """
        self.handlers[event_type] = handler
        logger.info(f"ğŸ“ æ³¨å†Œå…¨å±€äº‹ä»¶å¤„ç†å™¨: {event_type}")

    async def get_consumer_status(self) -> dict[str, Any]:
        """
        è·å–æ¶ˆè´¹è€…ç»„çŠ¶æ€
        
        Returns:
            dict: çŠ¶æ€ä¿¡æ¯
        """
        status = {
            "group_name": self.group_name,
            "is_running": self.is_running,
            "consumer_count": len(self.consumers),
            "consumers": {}
        }

        for consumer_name, consumer in self.consumers.items():
            status["consumers"][consumer_name] = {
                "is_running": consumer.is_running
            }

        return status


# é¢„å®šä¹‰çš„äº‹ä»¶å¤„ç†å™¨
async def default_task_started_handler(job_id: Union[str, int],
                                       event_data: dict):
    """é»˜è®¤çš„ä»»åŠ¡å¼€å§‹å¤„ç†å™¨"""
    task_type = event_data.get("task_type", "unknown")
    logger.info(f"ğŸš€ ä»»åŠ¡å¼€å§‹: {job_id} -> {task_type}")


async def default_task_progress_handler(job_id: Union[str, int],
                                        event_data: dict):
    """é»˜è®¤çš„ä»»åŠ¡è¿›åº¦å¤„ç†å™¨"""
    task_type = event_data.get("task_type", "unknown")
    progress = event_data.get("progress", "")
    logger.info(f"ğŸ”„ ä»»åŠ¡è¿›åº¦: {job_id} -> {task_type} - {progress}")


async def default_task_completed_handler(job_id: Union[str, int],
                                         event_data: dict):
    """é»˜è®¤çš„ä»»åŠ¡å®Œæˆå¤„ç†å™¨"""
    task_type = event_data.get("task_type", "unknown")
    logger.info(f"âœ… ä»»åŠ¡å®Œæˆ: {job_id} -> {task_type}")


async def default_task_failed_handler(job_id: Union[str, int],
                                      event_data: dict):
    """é»˜è®¤çš„ä»»åŠ¡å¤±è´¥å¤„ç†å™¨"""
    task_type = event_data.get("task_type", "unknown")
    error = event_data.get("error", "")
    logger.error(f"âŒ ä»»åŠ¡å¤±è´¥: {job_id} -> {task_type} - {error}")


async def default_outline_generated_handler(job_id: Union[str, int],
                                            event_data: dict):
    """é»˜è®¤çš„å¤§çº²ç”Ÿæˆå®Œæˆå¤„ç†å™¨"""
    outline = event_data.get("outline", {})
    title = outline.get("title", "Unknown")
    logger.info(f"ğŸ“‹ å¤§çº²ç”Ÿæˆå®Œæˆ: {job_id} -> {title}")


async def default_document_generated_handler(job_id: Union[str, int],
                                             event_data: dict):
    """é»˜è®¤çš„æ–‡æ¡£ç”Ÿæˆå®Œæˆå¤„ç†å™¨"""
    document = event_data.get("document", {})
    title = document.get("title", "Unknown")
    logger.info(f"ğŸ“„ æ–‡æ¡£ç”Ÿæˆå®Œæˆ: {job_id} -> {title}")


def create_default_consumer_group(
        redis_url: str,
        group_name: str = "doc_gen_consumers") -> RedisStreamConsumerGroup:
    """
    åˆ›å»ºé»˜è®¤çš„æ¶ˆè´¹è€…ç»„
    
    Args:
        redis_url: Redis è¿æ¥ URL
        group_name: æ¶ˆè´¹è€…ç»„åç§°
        
    Returns:
        RedisStreamConsumerGroup: é…ç½®å¥½çš„æ¶ˆè´¹è€…ç»„
    """
    consumer_group = RedisStreamConsumerGroup(redis_url, group_name)

    # æ³¨å†Œé»˜è®¤å¤„ç†å™¨
    consumer_group.register_handler("task_started",
                                    default_task_started_handler)
    consumer_group.register_handler("task_progress",
                                    default_task_progress_handler)
    consumer_group.register_handler("task_completed",
                                    default_task_completed_handler)
    consumer_group.register_handler("task_failed", default_task_failed_handler)
    consumer_group.register_handler("outline_generated",
                                    default_outline_generated_handler)
    consumer_group.register_handler("document_generated",
                                    default_document_generated_handler)

    return consumer_group
