#!/usr/bin/env python3
"""
Redis Stream æ¶ˆè´¹è€…ç»„æµ‹è¯•è„šæœ¬

æµ‹è¯•æ¶ˆè´¹è€…ç»„çš„è´Ÿè½½å‡è¡¡ã€æ•…éšœæ¢å¤å’Œæ¶ˆæ¯å¤„ç†åŠŸèƒ½ã€‚
"""

import asyncio
import json
from datetime import datetime

import redis.asyncio as redis
from loguru import logger

# å¯¼å…¥æˆ‘ä»¬çš„æ¶ˆè´¹è€…ç»„å®ç°
from doc_agent.core.redis_stream_consumer import (
    RedisStreamConsumerGroup,
    create_default_consumer_group,
)
from doc_agent.core.redis_stream_publisher import RedisStreamPublisher


class RedisStreamTester:
    """Redis Stream æµ‹è¯•å™¨"""

    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.redis_url = redis_url
        self.publisher = None
        self.consumer_group = None

    async def setup(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        # åˆ›å»ºå‘å¸ƒå™¨
        redis_client = redis.from_url(self.redis_url, decode_responses=True)
        await redis_client.ping()
        self.publisher = RedisStreamPublisher(redis_client)

        # åˆ›å»ºæ¶ˆè´¹è€…ç»„
        self.consumer_group = create_default_consumer_group(self.redis_url)

        logger.info("âœ… æµ‹è¯•ç¯å¢ƒè®¾ç½®å®Œæˆ")

    async def test_single_consumer(self):
        """æµ‹è¯•å•ä¸ªæ¶ˆè´¹è€…"""
        logger.info("ğŸ§ª æµ‹è¯•å•ä¸ªæ¶ˆè´¹è€…...")

        # åˆ›å»ºå•ä¸ªæ¶ˆè´¹è€…
        from doc_agent.core.redis_stream_consumer import RedisStreamConsumer
        consumer = RedisStreamConsumer(self.redis_url, "test_group",
                                       "test_consumer")
        await consumer.connect()

        # æ³¨å†Œæµ‹è¯•å¤„ç†å™¨
        async def test_handler(job_id: str, event_data: dict):
            logger.info(
                f"ğŸ“¨ æ”¶åˆ°æ¶ˆæ¯: {job_id} -> {event_data.get('event_type', 'unknown')}"
            )

        await consumer.register_handler("test_event", test_handler)

        # åˆ›å»ºæ¶ˆè´¹è€…ç»„
        stream_name = "test_stream"
        await consumer.create_consumer_group(stream_name)

        # å‘å¸ƒæµ‹è¯•æ¶ˆæ¯
        await self.publisher.publish_event(
            "test_job", {
                "event_type": "test_event",
                "message": "Hello from publisher",
                "timestamp": datetime.now().isoformat()
            })

        # å¯åŠ¨æ¶ˆè´¹è€…ï¼ˆè¿è¡Œ5ç§’ï¼‰
        logger.info("ğŸš€ å¯åŠ¨æ¶ˆè´¹è€…...")
        consumer_task = asyncio.create_task(
            consumer.start_consuming(stream_name))

        try:
            await asyncio.wait_for(consumer_task, timeout=5.0)
        except asyncio.TimeoutError:
            logger.info("â° æ¶ˆè´¹è€…æµ‹è¯•å®Œæˆ")

        await consumer.stop()
        await consumer.close()

    async def test_consumer_group(self):
        """æµ‹è¯•æ¶ˆè´¹è€…ç»„"""
        logger.info("ğŸ§ª æµ‹è¯•æ¶ˆè´¹è€…ç»„...")

        # å¯åŠ¨æ¶ˆè´¹è€…ç»„
        stream_name = "job_events:test_group_job"
        await self.consumer_group.start(stream_name)

        # å‘å¸ƒå¤šä¸ªæµ‹è¯•æ¶ˆæ¯
        for i in range(10):
            await self.publisher.publish_event(
                "test_group_job", {
                    "event_type": "task_progress",
                    "task_type": "test_task",
                    "progress": f"æ­¥éª¤ {i+1}/10",
                    "timestamp": datetime.now().isoformat()
                })
            await asyncio.sleep(0.1)  # çŸ­æš‚é—´éš”

        # ç­‰å¾…æ¶ˆæ¯å¤„ç†
        logger.info("â³ ç­‰å¾…æ¶ˆæ¯å¤„ç†...")
        await asyncio.sleep(3)

        # è·å–æ¶ˆè´¹è€…ç»„çŠ¶æ€
        status = await self.consumer_group.get_consumer_status()
        logger.info(
            f"ğŸ“Š æ¶ˆè´¹è€…ç»„çŠ¶æ€: {json.dumps(status, indent=2, ensure_ascii=False)}")

        # åœæ­¢æ¶ˆè´¹è€…ç»„
        await self.consumer_group.stop()

    async def test_fault_tolerance(self):
        """æµ‹è¯•æ•…éšœæ¢å¤"""
        logger.info("ğŸ§ª æµ‹è¯•æ•…éšœæ¢å¤...")

        # åˆ›å»ºè‡ªå®šä¹‰å¤„ç†å™¨ï¼Œæ¨¡æ‹Ÿæ•…éšœ
        async def faulty_handler(job_id: str, event_data: dict):
            if event_data.get("message") == "crash":
                raise Exception("æ¨¡æ‹Ÿæ•…éšœ")
            logger.info(f"âœ… æ­£å¸¸å¤„ç†: {job_id} -> {event_data.get('event_type')}")

        # åˆ›å»ºæµ‹è¯•æ¶ˆè´¹è€…ç»„
        test_group = RedisStreamConsumerGroup(self.redis_url,
                                              "fault_test_group", 2)
        test_group.register_handler("test_event", faulty_handler)

        stream_name = "job_events:fault_test_job"
        await test_group.start(stream_name)

        # å‘å¸ƒæ­£å¸¸æ¶ˆæ¯
        await self.publisher.publish_event(
            "fault_test_job", {
                "event_type": "test_event",
                "message": "normal",
                "timestamp": datetime.now().isoformat()
            })

        # å‘å¸ƒæ•…éšœæ¶ˆæ¯
        await self.publisher.publish_event(
            "fault_test_job", {
                "event_type": "test_event",
                "message": "crash",
                "timestamp": datetime.now().isoformat()
            })

        # å‘å¸ƒæ›´å¤šæ­£å¸¸æ¶ˆæ¯
        for i in range(3):
            await self.publisher.publish_event(
                "fault_test_job", {
                    "event_type": "test_event",
                    "message": f"normal_{i}",
                    "timestamp": datetime.now().isoformat()
                })
            await asyncio.sleep(0.1)

        # ç­‰å¾…å¤„ç†
        await asyncio.sleep(2)

        # åœæ­¢æµ‹è¯•ç»„
        await test_group.stop()

    async def test_load_balancing(self):
        """æµ‹è¯•è´Ÿè½½å‡è¡¡"""
        logger.info("ğŸ§ª æµ‹è¯•è´Ÿè½½å‡è¡¡...")

        # åˆ›å»ºå¤šä¸ªæ¶ˆè´¹è€…ç»„
        groups = []
        for i in range(3):
            group = RedisStreamConsumerGroup(self.redis_url, f"lb_group_{i}",
                                             2)

            # æ³¨å†Œå¤„ç†å™¨ï¼Œè®°å½•å¤„ç†è€…
            async def create_handler(group_id: int):

                async def handler(job_id: str, event_data: dict):
                    logger.info(
                        f"ğŸ“¨ ç»„ {group_id} å¤„ç†: {job_id} -> {event_data.get('event_type')}"
                    )

                return handler

            group.register_handler("test_event", await create_handler(i))
            groups.append(group)

        # å¯åŠ¨æ‰€æœ‰ç»„
        stream_name = "job_events:lb_test_job"
        for group in groups:
            await group.start(stream_name)

        # å‘å¸ƒå¤§é‡æ¶ˆæ¯
        logger.info("ğŸ“¤ å‘å¸ƒæµ‹è¯•æ¶ˆæ¯...")
        for i in range(20):
            await self.publisher.publish_event(
                "lb_test_job", {
                    "event_type": "test_event",
                    "message": f"message_{i}",
                    "timestamp": datetime.now().isoformat()
                })
            await asyncio.sleep(0.05)

        # ç­‰å¾…å¤„ç†
        await asyncio.sleep(3)

        # è·å–æ‰€æœ‰ç»„çš„çŠ¶æ€
        for i, group in enumerate(groups):
            status = await group.get_consumer_status()
            logger.info(f"ğŸ“Š ç»„ {i} çŠ¶æ€: {status['consumer_count']} ä¸ªæ¶ˆè´¹è€…")

        # åœæ­¢æ‰€æœ‰ç»„
        for group in groups:
            await group.stop()

    async def test_real_events(self):
        """æµ‹è¯•çœŸå®äº‹ä»¶"""
        logger.info("ğŸ§ª æµ‹è¯•çœŸå®äº‹ä»¶...")

        # åˆ›å»ºæ¶ˆè´¹è€…ç»„ï¼Œå¤„ç†çœŸå®äº‹ä»¶
        real_group = create_default_consumer_group(self.redis_url,
                                                   "real_events_group")
        stream_name = "job_events:real_test_job"
        await real_group.start(stream_name)

        # å‘å¸ƒçœŸå®äº‹ä»¶åºåˆ—
        events = [("task_started", {
            "task_type": "outline_generation"
        }),
                  ("task_progress", {
                      "task_type": "outline_generation",
                      "progress": "å¼€å§‹ç ”ç©¶ä¸»é¢˜"
                  }),
                  ("task_progress", {
                      "task_type": "outline_generation",
                      "progress": "æ”¶é›†ç›¸å…³èµ„æ–™"
                  }),
                  ("task_progress", {
                      "task_type": "outline_generation",
                      "progress": "ç”Ÿæˆå¤§çº²ç»“æ„"
                  }),
                  ("outline_generated", {
                      "outline": {
                          "title": "æµ‹è¯•å¤§çº²",
                          "nodes": []
                      }
                  }), ("task_started", {
                      "task_type": "document_generation"
                  }),
                  ("task_progress", {
                      "task_type": "document_generation",
                      "progress": "å¼€å§‹æ–‡æ¡£ç”Ÿæˆ"
                  }),
                  ("task_progress", {
                      "task_type": "document_generation",
                      "progress": "ç¼–å†™ç« èŠ‚å†…å®¹"
                  }),
                  ("document_generated", {
                      "document": {
                          "title": "æµ‹è¯•æ–‡æ¡£",
                          "content": "..."
                      }
                  }), ("task_completed", {
                      "task_type": "document_generation"
                  })]

        for event_type, event_data in events:
            await self.publisher.publish_event(
                "real_test_job", {
                    "event_type": event_type,
                    **event_data, "timestamp": datetime.now().isoformat()
                })
            await asyncio.sleep(0.2)

        # ç­‰å¾…å¤„ç†
        await asyncio.sleep(3)

        # åœæ­¢ç»„
        await real_group.stop()

    async def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        logger.info("ğŸš€ å¼€å§‹ Redis Stream æ¶ˆè´¹è€…ç»„æµ‹è¯•")

        try:
            await self.setup()

            # è¿è¡Œå„ç§æµ‹è¯•
            await self.test_single_consumer()
            await asyncio.sleep(1)

            await self.test_consumer_group()
            await asyncio.sleep(1)

            await self.test_fault_tolerance()
            await asyncio.sleep(1)

            await self.test_load_balancing()
            await asyncio.sleep(1)

            await self.test_real_events()

            logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")

        except Exception as e:
            logger.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        finally:
            if self.consumer_group:
                await self.consumer_group.stop()


async def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®æ—¥å¿—
    logger.add("logs/redis_stream_test.log", rotation="1 day", level="INFO")

    tester = RedisStreamTester()
    await tester.run_all_tests()


if __name__ == "__main__":
    asyncio.run(main())
