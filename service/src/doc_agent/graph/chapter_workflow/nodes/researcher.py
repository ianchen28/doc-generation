"""
ç ”ç©¶èŠ‚ç‚¹æ¨¡å—

è´Ÿè´£æ‰§è¡Œæœç´¢å’Œæ”¶é›†ä¿¡æ¯
"""

import json
from typing import Any

from doc_agent.core.logging_config import get_logger

logger = get_logger(__name__)

from doc_agent.core.config import settings
from doc_agent.graph.common import merge_sources_with_deduplication
from doc_agent.graph.common import parse_es_search_results as _parse_es_search_results
from doc_agent.graph.common import parse_web_search_results as _parse_web_search_results
from doc_agent.graph.state import ResearchState
from doc_agent.llm_clients.providers import EmbeddingClient
from doc_agent.tools.es_search import ESSearchTool
from doc_agent.tools.es_service import ESSearchResult
from doc_agent.tools.reranker import RerankedSearchResult, RerankerTool
from doc_agent.tools.web_search import WebSearchTool
from doc_agent.utils.search_utils import format_search_results, search_and_rerank
from doc_agent.graph.callbacks import publish_event, safe_serialize


def researcher_node(state: ResearchState,
                    web_search_tool: WebSearchTool) -> dict[str, Any]:
    """å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨ async_researcher_node"""
    raise NotImplementedError("è¯·ä½¿ç”¨ async_researcher_node")


async def async_researcher_node(
        state: ResearchState,
        web_search_tool: WebSearchTool,
        es_search_tool: ESSearchTool,
        reranker_tool: RerankerTool = None) -> dict[str, Any]:
    """
    å¼‚æ­¥èŠ‚ç‚¹2: æ‰§è¡Œæœç´¢ç ”ç©¶
    ä»çŠ¶æ€ä¸­è·å– search_queriesï¼Œä½¿ç”¨æœç´¢å·¥å…·æ”¶é›†ç›¸å…³ä¿¡æ¯
    ä¼˜å…ˆä½¿ç”¨å‘é‡æ£€ç´¢ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ°æ–‡æœ¬æœç´¢
    ä½¿ç”¨é‡æ’åºå·¥å…·å¯¹æœç´¢ç»“æœè¿›è¡Œä¼˜åŒ–

    Args:
        state: ç ”ç©¶çŠ¶æ€ï¼ŒåŒ…å« search_queries
        web_search_tool: ç½‘ç»œæœç´¢å·¥å…·
        es_search_tool: Elasticsearchæœç´¢å·¥å…·
        reranker_tool: é‡æ’åºå·¥å…·ï¼ˆå¯é€‰ï¼‰

    Returns:
        dict: åŒ…å« gathered_sources çš„å­—å…¸ï¼ŒåŒ…å« Source å¯¹è±¡åˆ—è¡¨
    """

    search_queries = state.get("search_queries", [])
    job_id = state.get("job_id", "")
    is_online = state.get("is_online", True)
    is_es_search = state["is_es_search"]
    ai_demo = state.get("ai_demo", False)

    logger.info(
        f"å½“å‰é‡è¯•æ¬¡æ•° <debug> {state.get('researcher_retry_count', 0)} </debug>")

    if not search_queries:
        logger.warning("âŒ æ²¡æœ‰æœç´¢æŸ¥è¯¢ï¼Œè¿”å›é»˜è®¤æ¶ˆæ¯")
        return {"gathered_sources": []}

    # è·å–å¤æ‚åº¦é…ç½®
    complexity_config = settings.get_complexity_config()
    logger.info(f"ğŸ”§ ä½¿ç”¨å¤æ‚åº¦çº§åˆ«: {complexity_config['level']}")

    all_sources = []  # å­˜å‚¨æ‰€æœ‰ Source å¯¹è±¡
    source_id_counter = state.get("current_citation_index", 1)

    # è·å–ç°æœ‰çš„ä¿¡æºåˆ—è¡¨ï¼ˆä»çŠ¶æ€ä¸­è·å–ï¼‰
    existing_sources = state.get("gathered_sources", [])

    # è·å–embeddingé…ç½®
    embedding_config = settings.supported_models.get("gte_qwen")
    embedding_client = None
    if embedding_config:
        try:
            embedding_client = EmbeddingClient(
                base_url=embedding_config.url,
                api_key=embedding_config.api_key)
            logger.info("âœ… Embeddingå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸  Embeddingå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            embedding_client = None
    else:
        logger.warning("âŒ æœªæ‰¾åˆ° embedding é…ç½®")

    # æ ¹æ®å¤æ‚åº¦é…ç½®è·å–æ–‡æ¡£é…ç½®å‚æ•°
    initial_top_k = complexity_config.get('vector_recall_size', 10)
    final_top_k = complexity_config.get('rerank_size', 5)

    # åº”ç”¨åŸºäºå¤æ‚åº¦çš„æŸ¥è¯¢æ•°é‡é™åˆ¶
    max_queries = complexity_config.get(
        'chapter_search_queries', complexity_config.get('max_queries', 5))
    if len(search_queries) > max_queries:
        logger.info(f"ğŸ”§ é™åˆ¶æœç´¢æŸ¥è¯¢æ•°é‡ä» {len(search_queries)} åˆ° {max_queries}")
        search_queries = search_queries[:max_queries]

    publish_event(
        job_id, "ä¿¡æ¯æ”¶é›†", "document_generation", "RUNNING", {
            "search_queries": search_queries,
            "description": f"å¼€å§‹ä¿¡æ¯æ”¶é›†ï¼Œå…±éœ€æœç´¢{len(search_queries)}ä¸ªæŸ¥è¯¢"
        })
    user_data_reference_files = state.get("user_data_reference_files", [])
    user_style_guide_content = state.get("user_style_guide_content", [])
    user_requirements_content = state.get("user_requirements_content", [])

    # æ‰§è¡Œæœç´¢
    for i, query in enumerate(search_queries, 1):
        # ç”Ÿæˆå‘é‡
        query_vector = await _get_embedding_vector(query, embedding_client)

        logger.info(f"æ‰§è¡Œæœç´¢æŸ¥è¯¢ {i}/{len(search_queries)}: {query}")
        # ============================
        # ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶æœç´¢
        # ============================
        user_data_raw_results: list[RerankedSearchResult] = []
        user_style_raw_results: list[RerankedSearchResult] = []
        user_requirement_raw_results: list[RerankedSearchResult] = []
        user_str_results = ""

        # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·ä¸Šä¼ çš„æ–‡æ¡£
        has_user_documents = (user_data_reference_files
                              or user_style_guide_content
                              or user_requirements_content)

        if has_user_documents:
            logger.info(
                f"ğŸ” åœ¨ç”¨æˆ·ä¸Šä¼ æ–‡æ¡£èŒƒå›´å†…æœç´¢ï¼Œå‚è€ƒæ–‡æ¡£IDæ•°é‡: {len(user_data_reference_files) if user_data_reference_files else 0}"
            )
            logger.info(
                f"é£æ ¼æŒ‡å—IDæ•°é‡: {len(user_style_guide_content) if user_style_guide_content else 0}"
            )
            logger.info(
                f"éœ€æ±‚æ–‡æ¡£IDæ•°é‡: {len(user_requirements_content) if user_requirements_content else 0}"
            )

            user_data_es_results = []
            user_style_es_results = []
            user_requirement_es_results = []
            try:
                # åœ¨æŒ‡å®šæ–‡æ¡£èŒƒå›´å†…æ‰§è¡ŒESæœç´¢
                if user_data_reference_files:
                    logger.info(
                        f"ğŸ” æœç´¢ç”¨æˆ·å‚è€ƒæ–‡æ¡£ï¼Œæ–‡æ¡£ID: {user_data_reference_files[:3]}...")
                    user_data_es_results = await es_search_tool.search_within_documents(
                        query=query,
                        query_vector=query_vector,
                        file_tokens=user_data_reference_files,  # å®é™…ä¸Šæ˜¯doc_idåˆ—è¡¨
                        top_k=initial_top_k,
                        min_score=0.0)  # ä¸´æ—¶è®¾ç½®ä¸º0ï¼Œç¡®ä¿æœ‰å†…å®¹è¿”å›
                    logger.info(
                        f"ğŸ” ç”¨æˆ·å‚è€ƒæ–‡æ¡£æœç´¢ç»“æœæ•°é‡: {len(user_data_es_results) if user_data_es_results else 0}"
                    )

                if user_style_guide_content:
                    logger.info(
                        f"ğŸ” æœç´¢ç”¨æˆ·é£æ ¼æŒ‡å—ï¼Œæ–‡æ¡£ID: {user_style_guide_content[:3]}...")
                    user_style_es_results = await es_search_tool.search_within_documents(
                        query=query,
                        query_vector=query_vector,
                        file_tokens=user_style_guide_content,  # å®é™…ä¸Šæ˜¯doc_idåˆ—è¡¨
                        top_k=initial_top_k,
                        min_score=0.0)  # ä¸´æ—¶è®¾ç½®ä¸º0ï¼Œç¡®ä¿æœ‰å†…å®¹è¿”å›
                    logger.info(
                        f"ğŸ” ç”¨æˆ·é£æ ¼æŒ‡å—æœç´¢ç»“æœæ•°é‡: {len(user_style_es_results) if user_style_es_results else 0}"
                    )

                if user_requirements_content:
                    logger.info(
                        f"ğŸ” æœç´¢ç”¨æˆ·éœ€æ±‚æ–‡æ¡£ï¼Œæ–‡æ¡£ID: {user_requirements_content[:3]}...")
                    user_requirement_es_results = await es_search_tool.search_within_documents(
                        query=query,
                        query_vector=query_vector,
                        file_tokens=user_requirements_content,  # å®é™…ä¸Šæ˜¯doc_idåˆ—è¡¨
                        top_k=initial_top_k,
                        min_score=0.0)  # ä¸´æ—¶è®¾ç½®ä¸º0ï¼Œç¡®ä¿æœ‰å†…å®¹è¿”å›
                    logger.info(
                        f"ğŸ” ç”¨æˆ·éœ€æ±‚æ–‡æ¡£æœç´¢ç»“æœæ•°é‡: {len(user_requirement_es_results) if user_requirement_es_results else 0}"
                    )

                # å¯¹ç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœè¿›è¡Œé‡æ’åº
                if user_data_es_results and reranker_tool:
                    logger.info(
                        f"ğŸ”„ å¯¹ç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœè¿›è¡Œé‡æ’åºï¼ŒåŸå§‹ç»“æœæ•°: {len(user_data_es_results)}")

                    # è¿‡æ»¤æœ‰å†…å®¹çš„ç»“æœ
                    valid_user_data_results = []
                    for result in user_data_es_results:
                        # ç¡®ä¿å†…å®¹ä¸ä¸ºç©º
                        content = result.original_content or result.div_content or ""
                        if content.strip():  # åªæ·»åŠ æœ‰å†…å®¹çš„ç»“æœ
                            valid_user_data_results.append(result)

                    logger.info(
                        f"ğŸ”„ æœ‰æ•ˆç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœæ•°: {len(valid_user_data_results)}")

                    # æ‰§è¡Œé‡æ’åº
                    reranked_user_results = reranker_tool.rerank_search_results(
                        query=query,
                        search_results=valid_user_data_results,
                        top_k=final_top_k)

                    # é‡æ’åºç»“æœå·²ç»æ˜¯RerankedSearchResultæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                    user_data_raw_results.extend(reranked_user_results)

                    logger.info(
                        f"âœ… ç”¨æˆ·æ–‡æ¡£é‡æ’åºå®Œæˆï¼Œç»“æœæ•°: {len(user_data_raw_results)}")

                    # style é‡æ’åº
                    if user_style_es_results and reranker_tool:
                        logger.info(
                            f"ğŸ”„ å¯¹ç”¨æˆ·é£æ ¼æŒ‡å—æœç´¢ç»“æœè¿›è¡Œé‡æ’åºï¼ŒåŸå§‹ç»“æœæ•°: {len(user_style_es_results)}"
                        )

                        # æ‰§è¡Œé‡æ’åº
                        reranked_user_style_results = reranker_tool.rerank_search_results(
                            query=query,
                            search_results=user_style_es_results,
                            top_k=final_top_k)

                        # é‡æ’åºç»“æœå·²ç»æ˜¯RerankedSearchResultæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                        user_style_raw_results.extend(
                            reranked_user_style_results)

                    # requirement é‡æ’åº
                    if user_requirement_es_results and reranker_tool:
                        logger.info(
                            f"ğŸ”„ å¯¹ç”¨æˆ·éœ€æ±‚æœç´¢ç»“æœè¿›è¡Œé‡æ’åºï¼ŒåŸå§‹ç»“æœæ•°: {len(user_requirement_es_results)}"
                        )

                        # æ‰§è¡Œé‡æ’åº
                        reranked_user_requirement_results = reranker_tool.rerank_search_results(
                            query=query,
                            search_results=user_requirement_es_results,
                            top_k=final_top_k)
                        logger.info(
                            f"ç”¨æˆ·è¦æ±‚å†…å®¹ï¼šé‡æ’åºç»“æœ: {reranked_user_requirement_results}"
                        )

                        # é‡æ’åºç»“æœå·²ç»æ˜¯RerankedSearchResultæ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                        user_requirement_raw_results.extend(
                            reranked_user_requirement_results)
                else:
                    # å¦‚æœæ²¡æœ‰é‡æ’åºå·¥å…·ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹ç»“æœ
                    for result in user_data_es_results:
                        user_data_raw_results.append(
                            RerankedSearchResult(
                                id=result.id,
                                doc_id=result.doc_id,
                                index=result.index,
                                domain_id=result.domain_id,
                                doc_from=result.doc_from,
                                original_content=result.original_content
                                or result.div_content,
                                score=result.score,
                                metadata={
                                    'source': result.source,
                                    'doc_id': result.doc_id,
                                    'file_token': result.file_token,
                                    'alias_name': result.alias_name
                                }))

                    # å¤„ç†ç”¨æˆ·é£æ ¼æŒ‡å—ç»“æœ
                    for result in user_style_es_results:
                        user_style_raw_results.append(
                            RerankedSearchResult(
                                id=result.id,
                                doc_id=result.doc_id,
                                index=result.index,
                                domain_id=result.domain_id,
                                doc_from=result.doc_from,
                                original_content=result.original_content
                                or result.div_content,
                                score=result.score,
                                metadata={
                                    'source': result.source,
                                    'doc_id': result.doc_id,
                                    'file_token': result.file_token,
                                    'alias_name': result.alias_name
                                }))

                    # å¤„ç†ç”¨æˆ·éœ€æ±‚æ–‡æ¡£ç»“æœ
                    for result in user_requirement_es_results:
                        user_requirement_raw_results.append(
                            RerankedSearchResult(
                                id=result.id,
                                doc_id=result.doc_id,
                                index=result.index,
                                domain_id=result.domain_id,
                                doc_from=result.doc_from,
                                original_content=result.original_content
                                or result.div_content,
                                score=result.score,
                                metadata={
                                    'source': result.source,
                                    'doc_id': result.doc_id,
                                    'file_token': result.file_token,
                                    'alias_name': result.alias_name
                                }))

                    logger.info(
                        f"âœ… ç”¨æˆ·æ–‡æ¡£æœç´¢å®Œæˆï¼Œç»“æœæ•°: {len(user_data_raw_results)}")
                    logger.info(
                        f"âœ… ç”¨æˆ·é£æ ¼æŒ‡å—æœç´¢å®Œæˆï¼Œç»“æœæ•°: {len(user_style_raw_results)}")
                    logger.info(
                        f"âœ… ç”¨æˆ·éœ€æ±‚æ–‡æ¡£æœç´¢å®Œæˆï¼Œç»“æœæ•°: {len(user_requirement_raw_results)}"
                    )

                # æ ¼å¼åŒ–ç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœ
                user_results_combined = []
                if user_data_raw_results:
                    user_results_combined.extend(user_data_raw_results)
                if user_style_raw_results:
                    user_results_combined.extend(user_style_raw_results)
                if user_requirement_raw_results:
                    user_results_combined.extend(user_requirement_raw_results)

                if user_results_combined:
                    user_str_results = format_search_results(
                        user_results_combined, query)
                    logger.info(
                        f"ğŸ“ ç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœæ ¼å¼åŒ–å®Œæˆï¼Œæ€»ç»“æœæ•°: {len(user_results_combined)}ï¼Œæ ¼å¼åŒ–é•¿åº¦: {len(user_str_results)}"
                    )
                else:
                    logger.warning("âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœ")

            except Exception as e:
                logger.error(f"âŒ ç”¨æˆ·æ–‡æ¡£æœç´¢å¤±è´¥: {str(e)}")
                user_data_raw_results = []
                user_str_results = ""

        # ============================
        # ESæœç´¢
        # ============================
        es_raw_results: list[RerankedSearchResult] = []
        es_str_results = ""
        if is_es_search:
            try:
                if query_vector and len(query_vector) == 1536:
                    logger.debug(
                        f"âœ… å‘é‡ç»´åº¦: {len(query_vector)}ï¼Œå‰5: {query_vector[:5]}")
                    # ä½¿ç”¨æ–°çš„æœç´¢å’Œé‡æ’åºåŠŸèƒ½
                    search_query = query if query.strip() else "ç›¸å…³æ–‡æ¡£"

                    _, reranked_es_results, formatted_es_results = await search_and_rerank(
                        es_search_tool=es_search_tool,
                        query=search_query,
                        query_vector=query_vector,
                        reranker_tool=reranker_tool,
                        initial_top_k=initial_top_k,
                        final_top_k=final_top_k,
                        config={
                            'min_score':
                            complexity_config.get('min_score', 0.3)
                        },
                        index="*" if not ai_demo else "ai_demo")
                    # æ·»åŠ æ–°çš„ç»“æœ
                    es_raw_results.extend(reranked_es_results)
                    es_str_results = formatted_es_results
                    logger.info(
                        f"âœ… å‘é‡æ£€ç´¢+é‡æ’åºæ‰§è¡ŒæˆåŠŸï¼Œç»“æœé•¿åº¦: {len(formatted_es_results)}")
                    logger.info(f"ğŸ” å‘é‡æ£€ç´¢+é‡æ’åºç»“æœ: {reranked_es_results}")
                else:
                    # æŠ¥é”™è¿”å›
                    raise ValueError("å‘é‡ç»´åº¦ä¸æ­£ç¡®")
            except Exception as e:
                logger.error(f"âŒ å‘é‡æ£€ç´¢å¼‚å¸¸: {str(e)}ï¼ è¯·æ£€æŸ¥embeddingå®¢æˆ·ç«¯é…ç½®")
                raise e

        # ============================
        # ç½‘ç»œæœç´¢
        # ============================
        web_raw_results: list[RerankedSearchResult] = []
        web_str_results = ""
        if is_online:
            try:
                # ä½¿ç”¨å¼‚æ­¥æœç´¢æ–¹æ³•
                web_raw_results, web_str_results = await web_search_tool.search_async(
                    query)
                if "æ¨¡æ‹Ÿ" in web_str_results or "mock" in web_str_results.lower(
                ):
                    logger.info(f"ç½‘ç»œæœç´¢è¿”å›æ¨¡æ‹Ÿç»“æœï¼Œè·³è¿‡: {query}")
                    web_str_results = ""
                    web_raw_results = []
                if "æœç´¢å¤±è´¥" in web_str_results:
                    logger.error(f"ç½‘ç»œæœç´¢å¤±è´¥: {web_str_results}")
                    web_str_results = ""
                    web_raw_results = []
            except Exception as e:
                logger.error(f"ç½‘ç»œæœç´¢å¤±è´¥: {str(e)}")
                web_str_results = ""

        # å¤„ç†ESæœç´¢ç»“æœ
        logger.info(f"ğŸ” ESæœç´¢ç»“æœ: {es_raw_results}")
        es_sources = []  # åˆå§‹åŒ– es_sources å˜é‡
        if es_raw_results:
            try:
                # è§£æESæœç´¢ç»“æœï¼Œåˆ›å»º Source å¯¹è±¡
                es_sources = _parse_es_search_results(es_raw_results, query,
                                                      source_id_counter)

                all_sources.extend(es_sources)
                source_id_counter += len(es_sources)
                logger.info(f"âœ… ä»ESæœç´¢ä¸­æå–åˆ° {len(es_sources)} ä¸ªæº")
            except Exception as e:
                logger.error(f"âŒ è§£æESæœç´¢ç»“æœå¤±è´¥: {str(e)}")
        logger.info(f"ğŸ” ESæœç´¢ç»“æœè§£æå: {es_sources}")

        # å¤„ç†ç½‘ç»œæœç´¢ç»“æœ
        web_sources = []  # åˆå§‹åŒ– web_sources å˜é‡
        if web_raw_results:
            try:
                # è§£æç½‘ç»œæœç´¢ç»“æœï¼Œåˆ›å»º Source å¯¹è±¡
                web_sources = _parse_web_search_results(
                    web_raw_results, query, source_id_counter)

                all_sources.extend(web_sources)
                source_id_counter += len(web_sources)
                logger.info(f"âœ… ä»ç½‘ç»œæœç´¢ä¸­æå–åˆ° {len(web_sources)} ä¸ªæº")
            except Exception as e:
                logger.error(f"âŒ è§£æç½‘ç»œæœç´¢ç»“æœå¤±è´¥: {str(e)}")

        # ============================
        # å¤„ç†ç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœ
        # ============================
        user_data_sources = []
        user_requirement_sources = []
        user_style_sources = []

        if user_data_raw_results:
            try:
                # è§£æç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœï¼Œåˆ›å»º Source å¯¹è±¡
                # åªæœ‰ç”¨æˆ·å‚è€ƒæ–‡æ¡£ä¼šè¿›å…¥ gathered_sourcesï¼ˆå‚è€ƒæ–‡çŒ®ï¼‰
                user_data_sources = _parse_es_search_results(
                    user_data_raw_results, query, source_id_counter)
                source_id_counter += len(user_data_sources)
            except Exception as e:
                logger.error(f"âŒ è§£æç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœå¤±è´¥: {str(e)}")

        if user_requirement_raw_results:
            try:
                # ç”¨æˆ·éœ€æ±‚æ–‡æ¡£å’Œé£æ ¼æŒ‡å—å•ç‹¬å¤„ç†ï¼Œä¸è¿›å…¥å‚è€ƒæ–‡çŒ®ï¼Œä½¿ç”¨ç‹¬ç«‹çš„IDåºåˆ—
                user_requirement_sources = _parse_es_search_results(
                    user_requirement_raw_results, query, 1000)  # ä½¿ç”¨1000å¼€å§‹çš„IDåºåˆ—

            except Exception as e:
                logger.error(f"âŒ è§£æç”¨æˆ·éœ€æ±‚æ–‡æ¡£æœç´¢ç»“æœå¤±è´¥: {str(e)}")

        if user_style_raw_results:
            try:
                # è§£æç”¨æˆ·é£æ ¼æŒ‡å—æœç´¢ç»“æœï¼Œåˆ›å»º Source å¯¹è±¡
                user_style_sources = _parse_es_search_results(
                    user_style_raw_results, query, 2000)  # ä½¿ç”¨2000å¼€å§‹çš„IDåºåˆ—

            except Exception as e:
                logger.error(f"âŒ è§£æç”¨æˆ·é£æ ¼æŒ‡å—æœç´¢ç»“æœå¤±è´¥: {str(e)}")

        logger.info(f"ğŸ” ç”¨æˆ·è¦æ±‚å†…å®¹: {user_requirement_sources}")
        logger.info(f"ğŸ” ç”¨æˆ·é£æ ¼æŒ‡å—å†…å®¹: {user_style_sources}")
        logger.info(f"ğŸ” ç”¨æˆ·å‚è€ƒæ–‡æ¡£å†…å®¹: {user_data_sources}")

        # åªæœ‰å‚è€ƒæ–‡æ¡£è¿›å…¥ gathered_sources
        all_sources.extend(user_data_sources)
        logger.info(f"âœ… ä»ç”¨æˆ·æ–‡æ¡£æœç´¢ä¸­æå–åˆ° {len(user_data_sources)} ä¸ªå‚è€ƒæ–‡æ¡£æº")
        logger.info(f"âœ… ç”¨æˆ·éœ€æ±‚æ–‡æ¡£æ•°é‡: {len(user_requirement_sources)} ä¸ª")
        logger.info(f"âœ… ç”¨æˆ·é£æ ¼æŒ‡å—æ•°é‡: {len(user_style_sources)} ä¸ª")

    # è¿”å›ç»“æ„åŒ–çš„æºåˆ—è¡¨
    old_source_count = len(existing_sources)
    new_source_count = len(all_sources)
    added_source_count = new_source_count - old_source_count
    logger.info(
        f"âœ… ä¿¡æºæ•°ï¼š{old_source_count} -- +{new_source_count} --> {added_source_count}"
    )
    for i, source in enumerate(all_sources[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ªæºä½œä¸ºé¢„è§ˆ
        logger.debug(
            f"  {i}. [{source.id}] {source.title} ({source.source_type})")

    # ğŸ”§ æ–°å¢ï¼šæ›´æ–°é‡è¯•è®¡æ•°å™¨
    current_retry_count = state.get("researcher_retry_count", 0)
    new_retry_count = current_retry_count + 1
    logger.info(f"ğŸ“Š æ›´æ–°é‡è¯•è®¡æ•°å™¨: {current_retry_count} -> {new_retry_count}")

    publish_event(
        job_id, "ä¿¡æ¯æ”¶é›†", "document_generation", "SUCCESS", {
            "web_sources": [safe_serialize(source) for source in web_sources],
            "es_sources": [safe_serialize(source) for source in es_sources],
            "user_data_reference_sources":
            [safe_serialize(source) for source in user_data_sources],
            "user_requirement_sources":
            [safe_serialize(source) for source in user_requirement_sources],
            "user_style_guide_sources":
            [safe_serialize(source) for source in user_style_sources],
            "description":
            f"ä¿¡æ¯æ”¶é›†å®Œæˆï¼Œæœç´¢åˆ°{len(all_sources)}ä¸ªä¿¡æ¯æºï¼Œå…¶ä¸­ç½‘ç»œæœç´¢ç»“æœ {len(web_sources)} ä¸ªï¼ŒESæœç´¢ç»“æœ {len(es_sources)} ä¸ªï¼Œç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœ {len(user_data_sources)} ä¸ª"
        })

    logger.info(
        f"ğŸ” ä¿¡æ¯æ”¶é›†å®Œæˆï¼Œæœç´¢åˆ°{len(all_sources)}ä¸ªä¿¡æ¯æºï¼Œå…¶ä¸­ç½‘ç»œæœç´¢ç»“æœ {len(web_sources)} ä¸ªï¼ŒESæœç´¢ç»“æœ {len(es_sources)} ä¸ªï¼Œç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœ {len(user_data_sources)} ä¸ª"
    )
    if es_raw_results:
        logger.info(f"ESæœç´¢ç»“æœç¤ºä¾‹ï¼š{es_raw_results[0]}")
    if user_data_sources:
        logger.info(f"ç”¨æˆ·æ–‡æ¡£æœç´¢ç»“æœç¤ºä¾‹ï¼š{user_data_sources[0]}")

    logger.info(f"ğŸ” ç”¨æˆ·è¦æ±‚å†…å®¹to state: {user_requirement_sources}")
    logger.info(f"ğŸ” æ ·å¼æŒ‡å—å†…å®¹to state: {user_style_sources}")
    logger.info(f"ğŸ” å‚è€ƒæ–‡æ¡£å†…å®¹to state: {user_data_sources}")

    return {
        "gathered_sources": all_sources,
        "researcher_retry_count": new_retry_count,
        "user_requirement_sources": user_requirement_sources,
        "user_style_guide_sources": user_style_sources,
        "user_data_reference_sources": user_data_sources,
        "is_es_search": is_es_search,
        "is_online": is_online,
        "ai_demo": ai_demo,
    }


async def _get_embedding_vector(
        query: str, embedding_client: EmbeddingClient) -> list[float]:
    embedding_response = embedding_client.invoke(query)
    embedding_data = json.loads(embedding_response)
    if isinstance(embedding_data, list):
        if len(embedding_data) > 0 and isinstance(embedding_data[0], list):
            query_vector = embedding_data[0]
        else:
            query_vector = embedding_data
    elif isinstance(embedding_data, dict) and 'data' in embedding_data:
        query_vector = embedding_data['data']
    else:
        logger.warning(f"âš ï¸  æ— æ³•è§£æembeddingå“åº”æ ¼å¼: {type(embedding_data)}")
        query_vector = None
    return query_vector
