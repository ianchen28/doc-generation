# service/examples/test_decoupled_workflow_pro.py

import asyncio
import json
import pprint
import sys
import uuid
from datetime import datetime
from pathlib import Path

from doc_agent.core.logger import logger
# --- å¯¼å…¥æ ¸å¿ƒç»„ä»¶ ---
from doc_agent.core.config import settings
from doc_agent.core.logging_config import setup_logging

# --- ç«‹å³è®¾ç½®æ—¥å¿—é…ç½®ï¼Œé¿å…åç»­åˆå§‹åŒ–æ—¶çš„æ ¼å¼é”™è¯¯ ---
setup_logging(settings)

from doc_agent.core.container import get_container
from doc_agent.graph.state import ResearchState

# --- æ¨¡æ‹Ÿçš„ä¸Šä¼ æ–‡ä»¶å†…å®¹ (ä¿æŒä¸å˜) ---
STYLE_GUIDE_CONTENT = """
åŒå¿—ä»¬ï¼Œæœ‹å‹ä»¬ï¼ä»Šå¤©æˆ‘ä»¬æ±‡èšä¸€å ‚ï¼Œæ ¸å¿ƒè®®é¢˜æ˜¯åˆ›æ–°ã€‚åˆ›æ–°æ˜¯å¼•é¢†å‘å±•çš„ç¬¬ä¸€åŠ¨åŠ›ï¼Œæ˜¯å»ºè®¾ç°ä»£åŒ–ç»æµä½“ç³»çš„æˆ˜ç•¥æ”¯æ’‘ã€‚æˆ‘ä»¬å¿…é¡»æŠŠåˆ›æ–°æ‘†åœ¨å›½å®¶å‘å±•å…¨å±€çš„æ ¸å¿ƒä½ç½®ã€‚
"""
REQUIREMENTS_CONTENT = """
- æŠ¥å‘Šå¿…é¡»è¦å¼•ç”¨ç™½é¹¤æ»©æ°´ç”µç«™çš„ç›¸å…³ç»éªŒä½œä¸ºä¾‹å­ã€‚
- å¿…é¡»åŒ…å«ä¸€ä¸ªå…³äºä¸­å›½æ°´ç”µç«™æœªæ¥å‘å±•è¶‹åŠ¿çš„ç« èŠ‚ã€‚
- ç»“è®ºéƒ¨åˆ†å¿…é¡»ä¸ºä¸åŒè§„æ¨¡çš„æ°´ç”µç«™æ ä¾›æ˜ç¡®çš„æŠ€æœ¯é€‰å‹å»ºè®®ã€‚
"""


async def run_stage_one_outline_generation(
        initial_state: ResearchState) -> dict:
    """æ‰§è¡Œç¬¬ä¸€é˜¶æ®µï¼šå¤§çº²ç”Ÿæˆå·¥ä½œæµ"""
    logger.info("ğŸš€ğŸš€ğŸš€ STAGE 1: Starting Outline Generation Workflow ğŸš€ğŸš€ğŸš€")
    outline_result = None
    container = get_container()
    try:
        async for step_output in container.outline_graph.astream(
                initial_state):
            node_name = list(step_output.keys())[0]
            logger.info(f"âœ… [Stage 1] Finished step: [ {node_name} ]")
            outline_result = list(step_output.values())[0]
    except Exception as e:
        logger.error(f"âŒ [Stage 1] Error during outline generation: {e}",
                     exception=e)
        return None

    logger.success("âœ…âœ…âœ… STAGE 1: Outline Generation Complete! âœ…âœ…âœ…\n")

    # æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰æ•ˆ
    if outline_result is None:
        logger.error("âŒ [Stage 1] outline_result is None")
        return None

    document_outline = outline_result.get("document_outline")
    if document_outline is None:
        logger.error("âŒ [Stage 1] document_outline is None in outline_result")
        logger.debug(
            f"ğŸ“„ outline_result keys: {list(outline_result.keys()) if outline_result else 'None'}"
        )
        return None

    logger.info(f"âœ… [Stage 1] Successfully extracted document_outline")
    return document_outline


async def run_stage_two_document_generation(
        initial_state: ResearchState) -> dict:
    logger.info("ğŸš€ğŸš€ğŸš€ STAGE 2: Starting Document Generation Workflow ğŸš€ğŸš€ğŸš€")
    final_result_state = None
    container = get_container()
    try:
        async_stream = container.document_graph.astream(initial_state)
        async for step_output in async_stream:
            node_name = list(step_output.keys())[0]
            logger.info(f"âœ… [Stage 2] Finished step: [ {node_name} ]")
            step_result = list(step_output.values())[0]

            # æ£€æŸ¥æ­¥éª¤ç»“æœæ˜¯å¦æœ‰æ•ˆ
            if step_result is not None:
                final_result_state = step_result
                logger.debug(f"ğŸ“Š æ­¥éª¤ {node_name} è¿”å›æœ‰æ•ˆç»“æœ")
            else:
                logger.warning(f"âš ï¸  æ­¥éª¤ {node_name} è¿”å› None")

    except Exception as e:
        logger.error(f"âŒ [Stage 2] Error during document generation: {e}",
                     exception=e)
        return None

    # å¦‚æœæœ€ç»ˆçŠ¶æ€ä¸ºNoneï¼Œå°è¯•ä½¿ç”¨åˆå§‹çŠ¶æ€
    if final_result_state is None:
        logger.warning("âš ï¸  æœ€ç»ˆçŠ¶æ€ä¸ºNoneï¼Œä½¿ç”¨åˆå§‹çŠ¶æ€")
        final_result_state = initial_state

    logger.success("âœ…âœ…âœ… STAGE 2: Document Generation Complete! âœ…âœ…âœ…\n")
    return final_result_state


async def main():
    """
    ä¸»æ‰§è¡Œå‡½æ•°ï¼Œä¸²è”ä¸¤ä¸ªç‹¬ç«‹çš„æµ‹è¯•é˜¶æ®µï¼Œå¹¶ä¿å­˜æ‰€æœ‰äº§å‡ºã€‚
    """
    # --- 1. ã€æ–°å¢ã€‘è®¾ç½®è¾“å‡ºè·¯å¾„å’Œæ—¥å¿— ---
    run_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = Path("output")
    output_dir.mkdir(exist_ok=True)

    log_file_path = output_dir / f"workflow_test_{run_timestamp}.log"

    # é…ç½®æ—¥å¿—åŒæ—¶è¾“å‡ºåˆ°æ–‡ä»¶å’Œæ§åˆ¶å°
    # ç§»é™¤é»˜è®¤å¤„ç†å™¨
    logger.remove()

    # æ·»åŠ æ§åˆ¶å°è¾“å‡º
    logger.add(
        sys.stdout,
        format=
        "<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> | <level>{message}</level>",
        level="INFO",
        colorize=True)

    # æ·»åŠ æ–‡ä»¶è¾“å‡º
    logger.add(
        log_file_path,
        format=
        "{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} | {message}",
        level="DEBUG",
        rotation="10 MB",
        retention="7 days")

    # --- 1.5. ã€æ–°å¢ã€‘ç”Ÿæˆ run_id å¹¶ç»‘å®šåˆ°æ—¥å¿—ä¸Šä¸‹æ–‡ ---
    run_id = f"run-{uuid.uuid4().hex[:8]}"
    logger.info(
        f"ğŸ“ All outputs for this run will be saved with timestamp: {run_timestamp}"
    )
    logger.info(f"ğŸ†” Generated run_id: {run_id}")

    # ç»‘å®š run_id åˆ°æ—¥å¿—ä¸Šä¸‹æ–‡
    with logger.contextualize(run_id=run_id):
        logger.info("ğŸš€ Starting decoupled workflow test with context tracking")

        # --- 2. å‡†å¤‡ç¬¬ä¸€é˜¶æ®µçš„è¾“å…¥ (ä¿®æ­£ï¼šæ·»åŠ æ‰€æœ‰å¿…éœ€å­—æ®µ) ---
        topic = "è°ƒç ”ä¸€ä¸‹æ°´ç”µç«™å»ºé€ è¿‡ç¨‹ä¸­å¯èƒ½å‡ºç°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ"
        stage_one_input_state = ResearchState(
            # æ—¥å¿—è¿½è¸ª ID
            run_id=run_id,

            # ç ”ç©¶ä¸»é¢˜
            topic=topic,

            # æ–‡æ¡£æ ·å¼å’Œéœ€æ±‚æŒ‡å—
            style_guide_content=STYLE_GUIDE_CONTENT,
            requirements_content=REQUIREMENTS_CONTENT,

            # ç¬¬ä¸€å±‚: ä¸Šå±‚ç ”ç©¶çš„åˆå§‹ç ”ç©¶ç»“æœ
            initial_sources=[],

            # æ–‡æ¡£ç»“æ„
            document_outline={},

            # ç« èŠ‚å¤„ç†
            chapters_to_process=[],
            current_chapter_index=0,

            # ä¸Šä¸‹æ–‡ç§¯ç´¯ - ä¿æŒè¿è´¯æ€§
            completed_chapters=[],

            # æœ€ç»ˆè¾“å‡º
            final_document="",

            # ç« èŠ‚çº§ç ”ç©¶çŠ¶æ€
            research_plan="",
            search_queries=[],
            gathered_sources=[],

            # æºè¿½è¸ª
            sources=[],
            all_sources=[],
            current_citation_index=1,

            # å…¨å±€å¼•ç”¨æºè¿½è¸ª - ç”¨äºæœ€ç»ˆå‚è€ƒæ–‡çŒ®
            cited_sources=[],
            cited_sources_in_chapter=[],

            # å¯¹è¯å†å²
            messages=[],
        )

        # --- 3. æ‰§è¡Œç¬¬ä¸€é˜¶æ®µ (ä¿æŒä¸å˜) ---
        generated_outline = await run_stage_one_outline_generation(
            stage_one_input_state)
        if not generated_outline:
            logger.error("âŒ Aborting test due to failure in Stage 1.")
            return

        logger.info("ğŸ“‹ Generated Outline for Stage 2:")
        pprint.pprint(generated_outline)
        print("-" * 80)

        # --- 3.5. ã€æ–°å¢ã€‘éªŒè¯å¤§çº²ç»“æ„ ---
        logger.info("ğŸ” Validating generated outline structure...")
        if generated_outline and isinstance(generated_outline, dict):
            chapters = generated_outline.get('chapters', [])
            logger.info(f"ğŸ“Š Outline contains {len(chapters)} chapters")

            for i, chapter in enumerate(chapters):
                chapter_title = chapter.get('chapter_title', f'Chapter {i+1}')
                sub_sections = chapter.get('sub_sections', [])
                logger.info(
                    f"  ğŸ“– Chapter {i+1}: {chapter_title} ({len(sub_sections)} sub-sections)"
                )

                for j, sub_section in enumerate(sub_sections):
                    sub_title = sub_section.get('section_title',
                                                f'Sub-section {j+1}')
                    key_points = sub_section.get('key_points', [])
                    logger.info(
                        f"    ğŸ“ {i+1}.{j+1}: {sub_title} ({len(key_points)} key points)"
                    )
        else:
            logger.warning("âš ï¸  Generated outline is invalid or empty")

        # --- 4. å‡†å¤‡ç¬¬äºŒé˜¶æ®µçš„è¾“å…¥ (ä¿®æ­£ï¼šæ·»åŠ æ‰€æœ‰å¿…éœ€å­—æ®µ) ---
        stage_two_input_state = ResearchState(
            # æ—¥å¿—è¿½è¸ª ID
            run_id=run_id,

            # ç ”ç©¶ä¸»é¢˜
            topic=topic,

            # æ–‡æ¡£æ ·å¼å’Œéœ€æ±‚æŒ‡å—
            style_guide_content=STYLE_GUIDE_CONTENT,
            requirements_content="",

            # ç¬¬ä¸€å±‚: ä¸Šå±‚ç ”ç©¶çš„åˆå§‹ç ”ç©¶ç»“æœ
            initial_sources=[],

            # æ–‡æ¡£ç»“æ„
            document_outline=generated_outline,

            # ç« èŠ‚å¤„ç†
            chapters_to_process=[],
            current_chapter_index=0,

            # ä¸Šä¸‹æ–‡ç§¯ç´¯ - ä¿æŒè¿è´¯æ€§
            completed_chapters=[],

            # æœ€ç»ˆè¾“å‡º
            final_document="",

            # ç« èŠ‚çº§ç ”ç©¶çŠ¶æ€
            research_plan="",
            search_queries=[],
            gathered_sources=[],

            # æºè¿½è¸ª
            sources=[],
            all_sources=[],
            current_citation_index=1,

            # å…¨å±€å¼•ç”¨æºè¿½è¸ª - ç”¨äºæœ€ç»ˆå‚è€ƒæ–‡çŒ®
            cited_sources=[],
            cited_sources_in_chapter=[],

            # å¯¹è¯å†å²
            messages=[],
        )

        # --- 5. æ‰§è¡Œç¬¬äºŒé˜¶æ®µ ---
        final_state = await run_stage_two_document_generation(
            stage_two_input_state)

        if not final_state:
            logger.error("Aborting test due to failure in Stage 2.")
            return

        # --- 6. ã€æ–°å¢ã€‘ä¿å­˜æ‰€æœ‰äº§å‡ºæ–‡ä»¶ ---
        logger.info("ğŸ’¾ Saving all workflow outputs...")

        # ä¿å­˜æœ€ç»ˆçŠ¶æ€
        state_file_path = output_dir / f"workflow_state_{run_timestamp}.json"
        try:
            with open(state_file_path, 'w', encoding='utf-8') as f:
                serializable_state = dict(final_state)
                json.dump(serializable_state, f, ensure_ascii=False, indent=4)
            logger.success(
                f"   - Full final state saved to: {state_file_path}")
        except Exception as e:
            logger.error(f"   - Failed to save state file: {e}")

        # ä¿å­˜å¤§çº²æ–‡ä»¶
        outline_file_path = output_dir / f"generated_outline_{run_timestamp}.json"
        try:
            with open(outline_file_path, 'w', encoding='utf-8') as f:
                json.dump(generated_outline, f, ensure_ascii=False, indent=4)
            logger.success(
                f"   - Generated outline saved to: {outline_file_path}")
        except Exception as e:
            logger.error(f"   - Failed to save outline file: {e}")

        # ä¿å­˜æœ€ç»ˆæ–‡æ¡£
        document_file_path = output_dir / f"final_document_{run_timestamp}.md"
        final_document_content = final_state.get("final_document", "")
        try:
            with open(document_file_path, 'w', encoding='utf-8') as f:
                f.write(final_document_content)
            logger.success(
                f"   - Final document saved to: {document_file_path}")
        except Exception as e:
            logger.error(f"   - Failed to save document file: {e}")

        # --- 7. æ‰“å°æœ€ç»ˆæ€»ç»“ ---
        print("\n\n" + "=" * 80)
        logger.success("ğŸ‰ End-to-End Test with Output Saving COMPLETED! ğŸ‰")
        print("=" * 80)
        print("ğŸ“ Output files:")
        print(f"  - ğŸ“ Log: {log_file_path}")
        print(f"  - ğŸ“Š State: {state_file_path}")
        print(f"  - ğŸ“‹ Outline: {outline_file_path}")
        print(f"  - ğŸ“„ Document: {document_file_path}")
        print("=" * 80)


if __name__ == "__main__":
    asyncio.run(main())
