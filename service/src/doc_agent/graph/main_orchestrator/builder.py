# service/src/doc_agent/graph/main_orchestrator/builder.py
import pprint

from langgraph.graph import END, StateGraph

from doc_agent.core.logger import logger
from doc_agent.graph.main_orchestrator.nodes import (bibliography_node,
                                                     fusion_editor_node,
                                                     initial_research_node,
                                                     outline_generation_node,
                                                     split_chapters_node)
from doc_agent.graph.state import ResearchState
from doc_agent.llm_clients import get_llm_client


def create_chapter_processing_node(chapter_workflow_graph):
    """
    åˆ›å»ºç« èŠ‚å¤„ç†èŠ‚ç‚¹çš„å·¥å‚å‡½æ•°
    
    Args:
        chapter_workflow_graph: ç¼–è¯‘åçš„ç« èŠ‚å·¥ä½œæµå›¾
        
    Returns:
        ç« èŠ‚å¤„ç†èŠ‚ç‚¹å‡½æ•°
    """

    async def chapter_processing_node(state: ResearchState) -> dict:
        """
        ç« èŠ‚å¤„ç†èŠ‚ç‚¹
        
        è°ƒç”¨ç« èŠ‚å­å·¥ä½œæµå¤„ç†å½“å‰ç« èŠ‚ï¼Œå¹¶æ›´æ–°çŠ¶æ€
        
        Args:
            state: ç ”ç©¶çŠ¶æ€
            
        Returns:
            dict: æ›´æ–°åçš„çŠ¶æ€å­—æ®µ
        """
        # è·å–å½“å‰çŠ¶æ€ä¿¡æ¯
        current_chapter_index = state.get("current_chapter_index", 0)
        chapters_to_process = state.get("chapters_to_process", [])
        completed_chapters = state.get("completed_chapters", [])
        topic = state.get("topic", "")

        # éªŒè¯ç´¢å¼•
        if current_chapter_index >= len(chapters_to_process):
            raise ValueError(f"ç« èŠ‚ç´¢å¼• {current_chapter_index} è¶…å‡ºèŒƒå›´")

        # è·å–å½“å‰ç« èŠ‚
        current_chapter = chapters_to_process[current_chapter_index]
        chapter_title = current_chapter.get("chapter_title", "")

        logger.info(
            f"\nğŸ“– å¼€å§‹å¤„ç†ç¬¬ {current_chapter_index + 1}/{len(chapters_to_process)} ç« : {chapter_title}"
        )

        # å‡†å¤‡å­å·¥ä½œæµçš„è¾“å…¥çŠ¶æ€
        # å…³é”®ï¼šä¼ é€’å·²å®Œæˆç« èŠ‚çš„å†…å®¹ä»¥ä¿æŒè¿è´¯æ€§
        # å°†æ–°çš„ completed_chapters ç»“æ„è½¬æ¢ä¸ºæ—§çš„ completed_chapters_content æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
        completed_chapters_content = []
        for chapter in completed_chapters:
            if isinstance(chapter, dict):
                completed_chapters_content.append(chapter.get("content", ""))
            else:
                completed_chapters_content.append(str(chapter))
        current_citation_index = state.get('current_citation_index', 0)

        chapter_workflow_input = {
            "job_id":
            state.get("job_id", ""),
            "topic":
            topic,
            "is_online":
            state.get("is_online", True),
            "user_data_reference_files":
            state.get("user_data_reference_files", []),
            "user_style_guide_content":
            state.get("user_style_guide_content", []),
            "user_requirements_content":
            state.get("user_requirements_content", []),
            "current_chapter_index":
            current_chapter_index,
            "chapters_to_process":
            chapters_to_process,
            "completed_chapters_content":
            completed_chapters_content,  # å…³é”®ï¼šä¼ é€’ä¸Šä¸‹æ–‡
            "search_queries": [],  # åˆå§‹åŒ–æœç´¢æŸ¥è¯¢ï¼ŒplannerèŠ‚ç‚¹ä¼šç”Ÿæˆ
            "research_plan":
            "",  # åˆå§‹åŒ–ç ”ç©¶è®¡åˆ’ï¼ŒplannerèŠ‚ç‚¹ä¼šç”Ÿæˆ
            "gathered_sources": [],  # åˆå§‹åŒ–æ”¶é›†çš„æºæ•°æ®ï¼ŒresearcherèŠ‚ç‚¹ä¼šå¡«å……
            "gathered_data":
            "",  # ä¿æŒå‘åå…¼å®¹
            "messages": [],  # æ–°çš„æ¶ˆæ¯å†å²
            # ä¼ é€’é£æ ¼æŒ‡å—å’Œéœ€æ±‚æ–‡æ¡£åˆ°ç« èŠ‚å·¥ä½œæµ
            "current_citation_index":
            current_citation_index,
            "style_guide_content":
            state.get("style_guide_content"),
            "requirements_content":
            state.get("requirements_content"),
            # ä¼ é€’å®Œæ•´çš„å¤§çº²ä¿¡æ¯ï¼ŒåŒ…æ‹¬å­èŠ‚ç»“æ„
            "document_outline":
            state.get("document_outline", {}),
            # ä¼ é€’å½“å‰ç« èŠ‚çš„å­èŠ‚ä¿¡æ¯
            "current_chapter_sub_sections":
            current_chapter.get("sub_sections", []) if current_chapter else [],
            "is_es_search":
            state.get("is_es_search", False),
            "ai_demo":
            state.get("ai_demo", False)
        }

        logger.debug(
            f"Chapter workflow input state:\n{pprint.pformat(chapter_workflow_input)}"
        )

        try:
            # è°ƒç”¨ç« èŠ‚å·¥ä½œæµ
            logger.info(f"ğŸ”„ è°ƒç”¨ç« èŠ‚å·¥ä½œæµå¤„ç†: {chapter_title}")
            chapter_result = await chapter_workflow_graph.ainvoke(
                chapter_workflow_input)

            # è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            logger.info(f"ğŸ“Š ç« èŠ‚å·¥ä½œæµè¾“å‡ºé”®: {list(chapter_result.keys())}")
            logger.info(f"ğŸ“Š ç« èŠ‚å·¥ä½œæµå®Œæ•´è¾“å‡º: {chapter_result}")

            # æ£€æŸ¥å…³é”®å­—æ®µæ˜¯å¦å­˜åœ¨
            if "final_document" in chapter_result:
                logger.info(
                    f"âœ… æ‰¾åˆ° final_documentï¼Œé•¿åº¦: {len(chapter_result['final_document'])}"
                )
            else:
                logger.warning("âš ï¸  æœªæ‰¾åˆ° final_document å­—æ®µ")

            if "cited_sources_in_chapter" in chapter_result:
                cited_sources = chapter_result["cited_sources_in_chapter"]
                logger.info(
                    f"âœ… æ‰¾åˆ° cited_sources_in_chapterï¼Œæ•°é‡: {len(cited_sources)}")
                if cited_sources:
                    logger.info(
                        f"ğŸ“š å¼•ç”¨æºç¤ºä¾‹: {cited_sources[0].title if hasattr(cited_sources[0], 'title') else 'æ— æ ‡é¢˜'}"
                    )
            else:
                logger.warning("âš ï¸  æœªæ‰¾åˆ° cited_sources_in_chapter å­—æ®µ")

            cited_sources_in_chapter = chapter_result.get(
                "cited_sources_in_chapter", [])

            # å®‰å…¨åœ°è®¡ç®—æœ€å¤§å¼•ç”¨ç´¢å¼•
            if cited_sources_in_chapter and len(cited_sources_in_chapter) > 0:
                max_citation_index = max(
                    [source.id for source in cited_sources_in_chapter])
            else:
                max_citation_index = 0  # å¦‚æœæ²¡æœ‰å¼•ç”¨æºï¼Œä½¿ç”¨é»˜è®¤å€¼

            # ä»ç»“æœä¸­æå–ç« èŠ‚å†…å®¹å’Œå¼•ç”¨æº
            chapter_content = chapter_result.get("final_document", "")
            state["all_sources"].extend(cited_sources_in_chapter)

            if not chapter_content:
                logger.warning("âš ï¸  ç« èŠ‚å·¥ä½œæµæœªè¿”å›å†…å®¹ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹")
                chapter_content = f"## {chapter_title}\n\nç« èŠ‚å†…å®¹ç”Ÿæˆå¤±è´¥ã€‚"

            logger.info(f"âœ… ç« èŠ‚å¤„ç†å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(chapter_content)} å­—ç¬¦")
            logger.info(
                f"ğŸ“š ç« èŠ‚å¼•ç”¨æºæ•°é‡: {len(chapter_result.get('cited_sources_in_chapter', []))}"
            )

            # ç”Ÿæˆç« èŠ‚æ‘˜è¦
            logger.info(f"ğŸ“ å¼€å§‹ç”Ÿæˆç« èŠ‚æ‘˜è¦: {chapter_title}")
            try:
                # è·å– LLM å®¢æˆ·ç«¯
                llm_client = get_llm_client()

                # åˆ›å»ºæ‘˜è¦æç¤º
                summary_prompt = f"""è¯·ä¸ºä»¥ä¸‹ç« èŠ‚å†…å®¹ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼Œæ§åˆ¶åœ¨200å­—ä»¥å†…ï¼š

ç« èŠ‚æ ‡é¢˜ï¼š{chapter_title}

ç« èŠ‚å†…å®¹ï¼š
{chapter_content}

è¯·ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æ‘˜è¦ï¼Œçªå‡ºç« èŠ‚çš„ä¸»è¦è§‚ç‚¹å’Œå…³é”®ä¿¡æ¯ï¼š"""

                # è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
                current_chapter_summary = llm_client.invoke(summary_prompt,
                                                            temperature=0.3,
                                                            max_tokens=300)

                logger.info(
                    f"âœ… ç« èŠ‚æ‘˜è¦ç”Ÿæˆå®Œæˆï¼Œé•¿åº¦: {len(current_chapter_summary)} å­—ç¬¦")

            except Exception as e:
                logger.warning(f"âš ï¸  ç« èŠ‚æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}")
                current_chapter_summary = f"ç« èŠ‚æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}"

            # æ›´æ–°ç« èŠ‚ç´¢å¼•
            state['current_citation_index'] = max_citation_index

            # åˆ›å»ºæ–°å®Œæˆçš„ç« èŠ‚å­—å…¸
            newly_completed_chapter = {
                "title": chapter_title,
                "content": chapter_content,
                "summary": current_chapter_summary
            }

            # è·å–ç°æœ‰çš„å·²å®Œæˆç« èŠ‚åˆ—è¡¨
            completed_chapters = state.get("completed_chapters", [])
            updated_completed_chapters = completed_chapters.copy()
            updated_completed_chapters.append(newly_completed_chapter)

            # æ›´æ–° completed_chapters_content ä»¥ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§
            completed_chapters_content = state.get(
                "completed_chapters_content", [])
            updated_completed_chapters_content = completed_chapters_content.copy(
            )
            updated_completed_chapters_content.append(chapter_content)

            # æ›´æ–° writer_steps è®¡æ•°å™¨
            current_writer_steps = state.get("writer_steps", 0)
            updated_writer_steps = current_writer_steps + 1

            logger.info(
                f"ğŸ“Š è¿›åº¦: {state['current_chapter_index']}/{len(chapters_to_process)} ç« èŠ‚å·²å®Œæˆ"
            )
            logger.info(f"ğŸ“š å…¨å±€å¼•ç”¨æºæ€»æ•°: {len(state['all_sources'])}")
            logger.info(f"âœï¸  Writeræ­¥éª¤è®¡æ•°: {updated_writer_steps}")
            logger.info(
                f"ğŸ“ å·²å®Œæˆç« èŠ‚å†…å®¹æ•°é‡: {len(updated_completed_chapters_content)}")

            return {
                "completed_chapters": updated_completed_chapters,
                "completed_chapters_content":
                updated_completed_chapters_content,
                "current_citation_index": state['current_citation_index'],
                "current_chapter_index":
                state['current_chapter_index'] + 1,  # ğŸ”§ ä¿®å¤ï¼šé€’å¢ç« èŠ‚ç´¢å¼•
                "cited_sources": state["all_sources"],
                "writer_steps": updated_writer_steps
            }

        except Exception as e:
            logger.error(f"âŒ ç« èŠ‚å¤„ç†å¤±è´¥: {str(e)}")
            # å¤±è´¥æ—¶ä»ç„¶æ¨è¿›ç´¢å¼•ï¼Œé¿å…æ— é™å¾ªç¯
            # æ›´æ–° writer_steps è®¡æ•°å™¨ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè®¡æ•°ï¼‰
            current_writer_steps = state.get("writer_steps", 0)
            updated_writer_steps = current_writer_steps + 1

            # åˆ›å»ºå¤±è´¥ç« èŠ‚çš„å­—å…¸
            failed_chapter = {
                "title": chapter_title,
                "content": f"## {chapter_title}\n\nç« èŠ‚å¤„ç†å¤±è´¥: {str(e)}",
                "summary": f"ç« èŠ‚å¤„ç†å¤±è´¥: {str(e)}"
            }

            # è·å–ç°æœ‰çš„å·²å®Œæˆç« èŠ‚åˆ—è¡¨
            completed_chapters = state.get("completed_chapters", [])
            updated_completed_chapters = completed_chapters.copy()
            updated_completed_chapters.append(failed_chapter)

            # æ›´æ–° completed_chapters_content ä»¥ä¿æŒä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼ˆå³ä½¿å¤±è´¥ä¹Ÿè¦æ·»åŠ å†…å®¹ï¼‰
            completed_chapters_content = state.get(
                "completed_chapters_content", [])
            updated_completed_chapters_content = completed_chapters_content.copy(
            )
            updated_completed_chapters_content.append(
                failed_chapter["content"])

            return {
                "completed_chapters": updated_completed_chapters,
                "completed_chapters_content":
                updated_completed_chapters_content,
                "current_citation_index": state['current_citation_index'],
                "current_chapter_index":
                state['current_chapter_index'] + 1,  # ğŸ”§ ä¿®å¤ï¼šå¤±è´¥æ—¶ä¹Ÿè¦é€’å¢ç´¢å¼•
                "cited_sources": state["all_sources"],
                "writer_steps": updated_writer_steps
            }

    return chapter_processing_node


def chapter_decision_function(state: ResearchState) -> str:
    """
    å†³ç­–å‡½æ•°ï¼šåˆ¤æ–­æ˜¯å¦è¿˜æœ‰ç« èŠ‚éœ€è¦å¤„ç†
    
    Args:
        state: ç ”ç©¶çŠ¶æ€
        
    Returns:
        str: "process_chapter" æˆ– "finalize_document"
    """
    current_chapter_index = state.get("current_chapter_index", 0)
    chapters_to_process = state.get("chapters_to_process", [])

    logger.info(
        f"\nğŸ¤” ç« èŠ‚å¤„ç†å†³ç­–: {current_chapter_index}/{len(chapters_to_process)}")

    if current_chapter_index < len(chapters_to_process):
        logger.info(f"â¡ï¸  ç»§ç»­å¤„ç†ç¬¬ {current_chapter_index + 1} ç« ")
        return "process_chapter"
    else:
        logger.info("âœ… æ‰€æœ‰ç« èŠ‚å·²å¤„ç†å®Œæˆ")
        return "finalize_document"


def finalize_document_node(state: ResearchState) -> dict:
    """
    æ–‡æ¡£æœ€ç»ˆåŒ–èŠ‚ç‚¹
    
    å°†æ‰€æœ‰ç« èŠ‚å†…å®¹åˆå¹¶ä¸ºæœ€ç»ˆæ–‡æ¡£ï¼Œå¹¶è¿›è¡Œæ ¼å¼æ¸…ç†
    
    Args:
        state: ç ”ç©¶çŠ¶æ€
        
    Returns:
        dict: åŒ…å« final_document çš„å­—å…¸
    """
    topic = state.get("topic", "")
    document_outline = state.get("document_outline", {})
    completed_chapters = state.get("completed_chapters", [])

    logger.info(f"\nğŸ“‘ å¼€å§‹ç”Ÿæˆæœ€ç»ˆæ–‡æ¡£")

    # è·å–æ–‡æ¡£æ ‡é¢˜å’Œæ‘˜è¦
    doc_title = document_outline.get("title", topic)
    doc_summary = document_outline.get("summary", "")

    # ä»æ–°çš„ completed_chapters ç»“æ„ä¸­æå–å†…å®¹
    completed_chapters_content = []
    logger.info(
        f"ğŸ“Š finalize_document_node: completed_chapters æ•°é‡: {len(completed_chapters)}"
    )

    for i, chapter in enumerate(completed_chapters):
        if isinstance(chapter, dict):
            content = chapter.get("content", "")
            title = chapter.get("title", f"ç¬¬{i+1}ç« ")
            logger.info(
                f"ğŸ“– finalize_document_node: ç¬¬{i+1}ç«  '{title}' å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦"
            )
            completed_chapters_content.append(content)
        else:
            logger.warning(
                f"âš ï¸ finalize_document_node: ç¬¬{i+1}ç« æ ¼å¼å¼‚å¸¸: {type(chapter)}")
            completed_chapters_content.append(str(chapter))

    # æ„å»ºæœ€ç»ˆæ–‡æ¡£
    final_document_parts = []

    # æ·»åŠ æ ‡é¢˜
    final_document_parts.append(f"# {doc_title}\n")

    # æ·»åŠ æ‘˜è¦
    if doc_summary:
        final_document_parts.append(f"## æ‘˜è¦\n\n{doc_summary}\n")

    # æ·»åŠ ç›®å½•
    final_document_parts.append("\n## ç›®å½•\n")
    chapters = document_outline.get("chapters", [])
    for i, chapter in enumerate(chapters):
        # å…¼å®¹æ–°æ—§æ ¼å¼
        chapter_title = chapter.get('title',
                                    chapter.get('chapter_title', f'ç¬¬{i+1}ç« '))
        chapter_number = chapter.get('number',
                                     chapter.get('chapter_number', i + 1))
        final_document_parts.append(f"{chapter_number}. {chapter_title}\n")

    final_document_parts.append("\n---\n")

    # æ·»åŠ æ‰€æœ‰ç« èŠ‚å†…å®¹ï¼ˆè¿›è¡Œæ ¼å¼æ¸…ç†ï¼‰
    for i, chapter_content in enumerate(completed_chapters_content):
        # è·å–ç« èŠ‚ä¿¡æ¯ç”¨äºæ ‡é¢˜ç¼–å·
        chapter_info = chapters[i] if i < len(chapters) else {}
        chapter_number = chapter_info.get(
            'number', chapter_info.get('chapter_number', i + 1))
        chapter_title = chapter_info.get(
            'title', chapter_info.get('chapter_title', f'ç¬¬{i+1}ç« '))

        cleaned_content = _clean_chapter_content(chapter_content,
                                                 chapter_number, chapter_title)
        final_document_parts.append(f"\n{cleaned_content}\n")
        final_document_parts.append("\n---\n")

    # å‚è€ƒæ–‡çŒ®å°†ç”± bibliography_node åœ¨åç»­æ­¥éª¤ä¸­æ·»åŠ 
    logger.info("ğŸ“š å‚è€ƒæ–‡çŒ®å°†åœ¨åç»­æ­¥éª¤ä¸­ç”± bibliography_node æ·»åŠ ")

    # åˆå¹¶ä¸ºæœ€ç»ˆæ–‡æ¡£
    final_document = "\n".join(final_document_parts)

    logger.info(f"âœ… æœ€ç»ˆæ–‡æ¡£ç”Ÿæˆå®Œæˆï¼Œæ€»é•¿åº¦: {len(final_document)} å­—ç¬¦")
    logger.info(f"ğŸ“– åŒ…å« {len(completed_chapters_content)} ä¸ªç« èŠ‚")

    # è·å– cited_sources å¹¶ä¼ é€’ç»™ä¸‹ä¸€ä¸ªèŠ‚ç‚¹
    cited_sources = state.get("cited_sources", [])
    logger.info(
        f"ğŸ“š finalize_document_node: ä¼ é€’ cited_sourcesï¼Œæ•°é‡: {len(cited_sources)}")

    return {"final_document": final_document, "cited_sources": cited_sources}


def _clean_chapter_content(content: str,
                           chapter_number: int = None,
                           chapter_title: str = "") -> str:
    """
    æ¸…ç†ç« èŠ‚å†…å®¹æ ¼å¼
    
    Args:
        content: åŸå§‹ç« èŠ‚å†…å®¹
        chapter_number: ç« èŠ‚ç¼–å·
        chapter_title: ç« èŠ‚æ ‡é¢˜
        
    Returns:
        str: æ¸…ç†åçš„å†…å®¹
    """
    if not content:
        return content

    # 1. ç§»é™¤ markdown ä»£ç å—æ ‡è®°
    # ç§»é™¤å¼€å¤´çš„ ```markdown æˆ– ``` æ ‡è®°
    content = content.strip()
    if content.startswith("```markdown"):
        content = content[11:]  # ç§»é™¤ ```markdown
    elif content.startswith("```"):
        content = content[3:]  # ç§»é™¤ ```

    # ç§»é™¤ç»“å°¾çš„ ``` æ ‡è®°
    if content.endswith("```"):
        content = content[:-3]

    # 2. è°ƒæ•´æ ‡é¢˜å±‚çº§
    lines = content.split('\n')
    cleaned_lines = []

    for line in lines:
        # å¤„ç†ç« èŠ‚æ ‡é¢˜ï¼šå°† ## ç« èŠ‚æ ‡é¢˜ è½¬æ¢ä¸º ## ç¼–å·. ç« èŠ‚æ ‡é¢˜
        if line.startswith('## ') and not line.startswith('### '):
            # è¿™æ˜¯ç« èŠ‚æ ‡é¢˜ï¼Œéœ€è¦æ·»åŠ ç¼–å·
            if chapter_number and chapter_title:
                # å¦‚æœæ ‡é¢˜å·²ç»åŒ…å«ç¼–å·ï¼Œä¿æŒä¸å˜
                if line.strip() == f"## {chapter_title}":
                    line = f"## {chapter_number}. {chapter_title}"
                else:
                    # å¦åˆ™ä½¿ç”¨æä¾›çš„ç¼–å·å’Œæ ‡é¢˜
                    line = f"## {chapter_number}. {chapter_title}"
            # ä¿æŒäºŒçº§æ ‡é¢˜å±‚çº§ä¸å˜

        # å¤„ç†å­èŠ‚æ ‡é¢˜ï¼šå°† ### å­èŠ‚æ ‡é¢˜ è½¬æ¢ä¸º ### ç¼–å·. å­èŠ‚æ ‡é¢˜
        elif line.startswith('### ') and not line.startswith('#### '):
            # è¿™æ˜¯å­èŠ‚æ ‡é¢˜ï¼Œä¿æŒä¸‰çº§æ ‡é¢˜å±‚çº§
            pass

        # å¤„ç†å­èŠ‚çš„å­èŠ‚æ ‡é¢˜ï¼šå°† #### å­èŠ‚æ ‡é¢˜ è½¬æ¢ä¸º #### ç¼–å·. å­èŠ‚æ ‡é¢˜
        elif line.startswith('#### ') and not line.startswith('##### '):
            # è¿™æ˜¯å­èŠ‚çš„å­èŠ‚æ ‡é¢˜ï¼Œä¿æŒå››çº§æ ‡é¢˜å±‚çº§
            pass

        cleaned_lines.append(line)

    # é‡æ–°ç»„åˆå†…å®¹
    cleaned_content = '\n'.join(cleaned_lines)

    # 3. ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
    # å°†è¿ç»­çš„ç©ºè¡Œå‹ç¼©ä¸ºæœ€å¤šä¸¤ä¸ªç©ºè¡Œ
    import re
    cleaned_content = re.sub(r'\n{3,}', '\n\n', cleaned_content)

    return cleaned_content.strip()


def build_main_orchestrator_graph(initial_research_node,
                                  outline_generation_node,
                                  split_chapters_node,
                                  chapter_workflow_graph,
                                  fusion_editor_node=None,
                                  finalize_document_node_func=None,
                                  bibliography_node_func=None):
    """
    æ„å»ºä¸»ç¼–æ’å™¨å›¾
    
    ä¸»å·¥ä½œæµç¨‹ï¼š
    1. åˆå§‹ç ”ç©¶ -> ç”Ÿæˆå¤§çº² -> æ‹†åˆ†ç« èŠ‚
    2. å¾ªç¯å¤„ç†æ¯ä¸ªç« èŠ‚ï¼ˆè°ƒç”¨ç« èŠ‚å­å·¥ä½œæµï¼‰
    3. æ‰€æœ‰ç« èŠ‚å®Œæˆåï¼Œè¿›å…¥èåˆç¼–è¾‘å™¨è¿›è¡Œæ¶¦è‰²
    4. èåˆç¼–è¾‘åï¼Œç”Ÿæˆæœ€ç»ˆæ–‡æ¡£
    5. ç”Ÿæˆå‚è€ƒæ–‡çŒ®
    
    Args:
        initial_research_node: å·²ç»‘å®šä¾èµ–çš„åˆå§‹ç ”ç©¶èŠ‚ç‚¹
        outline_generation_node: å·²ç»‘å®šä¾èµ–çš„å¤§çº²ç”ŸæˆèŠ‚ç‚¹
        split_chapters_node: ç« èŠ‚æ‹†åˆ†èŠ‚ç‚¹
        chapter_workflow_graph: ç¼–è¯‘åçš„ç« èŠ‚å·¥ä½œæµå›¾
        fusion_editor_node: å¯é€‰çš„èåˆç¼–è¾‘å™¨èŠ‚ç‚¹å‡½æ•°
        finalize_document_node_func: å¯é€‰çš„æ–‡æ¡£æœ€ç»ˆåŒ–èŠ‚ç‚¹å‡½æ•°
        bibliography_node_func: å¯é€‰çš„å‚è€ƒæ–‡çŒ®ç”ŸæˆèŠ‚ç‚¹å‡½æ•°
        
    Returns:
        CompiledGraph: ç¼–è¯‘åçš„ä¸»ç¼–æ’å™¨å›¾
    """
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(ResearchState)

    # åˆ›å»ºç« èŠ‚å¤„ç†èŠ‚ç‚¹
    chapter_processing_node = create_chapter_processing_node(
        chapter_workflow_graph)

    # ä½¿ç”¨æä¾›çš„æˆ–é»˜è®¤çš„æ–‡æ¡£æœ€ç»ˆåŒ–èŠ‚ç‚¹
    if finalize_document_node_func is None:
        finalize_document_node_func = finalize_document_node

    # ä½¿ç”¨æä¾›çš„æˆ–é»˜è®¤çš„èåˆç¼–è¾‘å™¨èŠ‚ç‚¹
    if fusion_editor_node is None:
        fusion_editor_node = fusion_editor_node

    # ä½¿ç”¨æä¾›çš„æˆ–é»˜è®¤çš„å‚è€ƒæ–‡çŒ®ç”ŸæˆèŠ‚ç‚¹
    if bibliography_node_func is None:
        bibliography_node_func = bibliography_node

    # æ³¨å†Œæ‰€æœ‰èŠ‚ç‚¹
    workflow.add_node("initial_research", initial_research_node)
    workflow.add_node("outline_generation", outline_generation_node)
    workflow.add_node("split_chapters", split_chapters_node)
    workflow.add_node("chapter_processing", chapter_processing_node)
    workflow.add_node("finalize_document", finalize_document_node_func)
    workflow.add_node("fusion_editor", fusion_editor_node)
    workflow.add_node("generate_bibliography", bibliography_node_func)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("initial_research")

    # æ·»åŠ é¡ºåºè¾¹
    workflow.add_edge("initial_research", "outline_generation")
    workflow.add_edge("outline_generation", "split_chapters")

    # ä» split_chapters åˆ°æ¡ä»¶å†³ç­–ç‚¹
    workflow.add_conditional_edges(
        "split_chapters", chapter_decision_function, {
            "process_chapter": "chapter_processing",
            "finalize_document": "finalize_document"
        })

    # ç« èŠ‚å¤„ç†å®Œæˆåï¼Œå›åˆ°æ¡ä»¶å†³ç­–ç‚¹ï¼ˆå½¢æˆå¾ªç¯ï¼‰
    workflow.add_conditional_edges(
        "chapter_processing",
        chapter_decision_function,
        {
            "process_chapter": "chapter_processing",  # ç»§ç»­å¤„ç†ä¸‹ä¸€ç« 
            "finalize_document": "fusion_editor"  # æ‰€æœ‰ç« èŠ‚å®Œæˆï¼Œè¿›å…¥èåˆç¼–è¾‘
        })

    # èåˆç¼–è¾‘åè¿›å…¥æ–‡æ¡£æœ€ç»ˆåŒ–
    workflow.add_edge("fusion_editor", "finalize_document")

    # æ–‡æ¡£æœ€ç»ˆåŒ–åè¿›å…¥å‚è€ƒæ–‡çŒ®ç”Ÿæˆ
    workflow.add_edge("finalize_document", "generate_bibliography")

    # å‚è€ƒæ–‡çŒ®ç”Ÿæˆåç»“æŸ
    workflow.add_edge("generate_bibliography", END)

    # ç¼–è¯‘å¹¶è¿”å›å›¾
    logger.info("ğŸ—ï¸  ä¸»ç¼–æ’å™¨å›¾æ„å»ºå®Œæˆ")
    return workflow.compile()


def build_outline_graph(initial_research_node, outline_generation_node):
    """
    æ„å»ºå¤§çº²ç”Ÿæˆå›¾
    
    æµç¨‹ï¼šentry -> initial_research_node -> outline_generation_node -> END
    
    Args:
        initial_research_node: å·²ç»‘å®šä¾èµ–çš„åˆå§‹ç ”ç©¶èŠ‚ç‚¹
        outline_generation_node: å·²ç»‘å®šä¾èµ–çš„å¤§çº²ç”ŸæˆèŠ‚ç‚¹
        
    Returns:
        CompiledGraph: ç¼–è¯‘åçš„å¤§çº²ç”Ÿæˆå›¾
    """
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(ResearchState)

    # æ³¨å†ŒèŠ‚ç‚¹
    workflow.add_node("initial_research", initial_research_node)
    workflow.add_node("outline_generation", outline_generation_node)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("initial_research")

    # æ·»åŠ é¡ºåºè¾¹
    workflow.add_edge("initial_research", "outline_generation")
    workflow.add_edge("outline_generation", END)

    # ç¼–è¯‘å¹¶è¿”å›å›¾
    logger.info("ğŸ—ï¸  å¤§çº²ç”Ÿæˆå›¾æ„å»ºå®Œæˆ")
    return workflow.compile()


def build_outline_loader_graph(outline_loader_node):
    """
    æ„å»ºå¤§çº²åŠ è½½å™¨å›¾
    
    æµç¨‹ï¼šentry -> outline_loader_node -> END
    
    Args:
        outline_loader_node: å·²ç»‘å®šä¾èµ–çš„å¤§çº²åŠ è½½å™¨èŠ‚ç‚¹
        
    Returns:
        CompiledGraph: ç¼–è¯‘åçš„å¤§çº²åŠ è½½å™¨å›¾
    """
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(ResearchState)

    # æ³¨å†ŒèŠ‚ç‚¹
    workflow.add_node("outline_loader", outline_loader_node)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("outline_loader")

    # æ·»åŠ é¡ºåºè¾¹
    workflow.add_edge("outline_loader", END)

    # ç¼–è¯‘å¹¶è¿”å›å›¾
    logger.info("ğŸ—ï¸  å¤§çº²åŠ è½½å™¨å›¾æ„å»ºå®Œæˆ")
    return workflow.compile()


def build_document_graph(chapter_workflow_graph,
                         split_chapters_node,
                         fusion_editor_node=None,
                         finalize_document_node_func=None,
                         bibliography_node_func=None):
    """
    æ„å»ºæ–‡æ¡£ç”Ÿæˆå›¾
    
    æµç¨‹ï¼šentry -> split_chapters_node -> (ç« èŠ‚å¤„ç†å¾ªç¯) -> fusion_editor_node -> finalize_document_node -> bibliography_node -> END
    
    Args:
        chapter_workflow_graph: ç¼–è¯‘åçš„ç« èŠ‚å·¥ä½œæµå›¾
        split_chapters_node: ç« èŠ‚æ‹†åˆ†èŠ‚ç‚¹
        fusion_editor_node: å¯é€‰çš„èåˆç¼–è¾‘å™¨èŠ‚ç‚¹å‡½æ•°
        finalize_document_node_func: å¯é€‰çš„æ–‡æ¡£æœ€ç»ˆåŒ–èŠ‚ç‚¹å‡½æ•°
        bibliography_node_func: å¯é€‰çš„å‚è€ƒæ–‡çŒ®ç”ŸæˆèŠ‚ç‚¹å‡½æ•°
        
    Returns:
        CompiledGraph: ç¼–è¯‘åçš„æ–‡æ¡£ç”Ÿæˆå›¾
    """
    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(ResearchState)

    # åˆ›å»ºç« èŠ‚å¤„ç†èŠ‚ç‚¹
    chapter_processing_node = create_chapter_processing_node(
        chapter_workflow_graph)

    # ä½¿ç”¨æä¾›çš„æˆ–é»˜è®¤çš„èŠ‚ç‚¹å‡½æ•°
    if fusion_editor_node is None:
        fusion_editor_node = fusion_editor_node

    if finalize_document_node_func is None:
        finalize_document_node_func = finalize_document_node

    if bibliography_node_func is None:
        bibliography_node_func = bibliography_node

    # æ³¨å†Œæ‰€æœ‰èŠ‚ç‚¹
    workflow.add_node("split_chapters", split_chapters_node)
    workflow.add_node("chapter_processing", chapter_processing_node)
    workflow.add_node("fusion_editor", fusion_editor_node)
    workflow.add_node("finalize_document", finalize_document_node_func)
    workflow.add_node("generate_bibliography", bibliography_node_func)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("split_chapters")

    # ä» split_chapters åˆ°æ¡ä»¶å†³ç­–ç‚¹
    workflow.add_conditional_edges(
        "split_chapters", chapter_decision_function, {
            "process_chapter": "chapter_processing",
            "finalize_document": "finalize_document"
        })

    # ç« èŠ‚å¤„ç†å®Œæˆåï¼Œå›åˆ°æ¡ä»¶å†³ç­–ç‚¹ï¼ˆå½¢æˆå¾ªç¯ï¼‰
    workflow.add_conditional_edges(
        "chapter_processing",
        chapter_decision_function,
        {
            "process_chapter": "chapter_processing",  # ç»§ç»­å¤„ç†ä¸‹ä¸€ç« 
            "finalize_document": "fusion_editor"  # æ‰€æœ‰ç« èŠ‚å®Œæˆï¼Œè¿›å…¥èåˆç¼–è¾‘
        })

    # èåˆç¼–è¾‘åè¿›å…¥æ–‡æ¡£æœ€ç»ˆåŒ–
    workflow.add_edge("fusion_editor", "finalize_document")

    # æœ€ç»ˆåŒ–åè¿›å…¥å‚è€ƒæ–‡çŒ®ç”Ÿæˆ
    workflow.add_edge("finalize_document", "generate_bibliography")

    # å‚è€ƒæ–‡çŒ®ç”Ÿæˆåç»“æŸ
    workflow.add_edge("generate_bibliography", END)

    # ç¼–è¯‘å¹¶è¿”å›å›¾
    logger.info("ğŸ—ï¸  æ–‡æ¡£ç”Ÿæˆå›¾æ„å»ºå®Œæˆ")
    return workflow.compile()
